We propose a semi-automatic tool, ter- might, that helps professional translators and terminologists identify technical terms and their translations. 
The tool makes use of part-of-speech tagging and word- alignment programs to extract candidate terms and their translations. 
Although the extraction programs are far from perfect, it isn't too hard for the user to filter out the wheat from the chaff. 
The extraction algorithms emphasize completeness. Alter- native proposals are likely to miss impor- tant but infrequent terms/translations
1 Introduction Parallel corpora have been shown to provide an extremely rich source of constraints for statistical analysis (e.g. , Brown et al. 1990; Gale & Church 1991; Gale et al. 1992; Church 1993; Brown et al. 1993; Dagan et al. 1993; Dagan & Church 1994; Fung & Church 1994; Wu & Xia 1994; Fung & McKeown 1994).
A simpler, related idea of penalizing distortion from some ideal matching pattern can be found in the statistical translation (Brown et al. 1990; Brown et al. 1993) and word alignment (Dagan et al. 1993; Dagan & Church 1994) models.
Several methods have been proposed with regard to acquiring various kinds of rules such as translation rules, grammar rules, dictionary entries and so on from bilingual corpora (Dagan et al. , 1991; Dagan and Church, 1994; Fung and Church, 1994; Tanaka, 1994; Yamada et al. , 1995).
Bilingual alignments have so far shown that they can play multiple roles in a wide range of linguistic applications, such as computer assisted translation (Isabelle et al. , 1993; Brown et al. , 1990), terminology (Dagan and Church, 1994) lexicography (Langlois, 1996; Klavans and Tzoukermann, 1995; Melamed, 1996), and cross-language information retrieval (Nie et al. , * This research was funded by the Canadian Department of Foreign Affairs and International Trade (http://~.dfait-maeci.gc.ca/), via the Agence de la francophonie (http://~
Related Works Generally speaking, approaches to MWE extraction proposed so far can be divided into three categories: a) statistical approaches based on frequency and co-occurrence affinity, b) knowledgebased or symbolic approaches using parsers, lexicons and language filters, and c) hybrid approaches combining different methods (Smadja 1993; Dagan and Church 1994; Daille 1995; McEnery et al. 1997; Wu 1997; Wermter et al. 1997; Michiels and Dufour 1998; Merkel and Andersson 2000; Piao and McEnery 2001; Sag et al. 2001a, 2001b; Biber et al. 2003).
On the one hand, the linguistically-based or rule-based approaches use linguistic information such as PoS tags, chunk information, etc. to filter out stop words and restrict candidate terms to predefined syntactic patterns (Ananiadou, 1994), (Dagan and Church, 1994).
Note that these problems are quite similar to the difficulties in translating technical terminology, which also is usually part of a particular technical sublanguage (Dagan and Church 1994).
In the case of word_align (Dagan, Church, and Gale 1993; Dagan and Church 1994), a penalty is imposed according to the deviation from an ideal matching, as constructed by linear interpolation?
(Justeson and Katz, 1995) and (Dagan and Church, 1994) use the frequency of occurrence of the candidate string as a measure of its likelihood to be a term.
The choice of the linguistic filter affects the precision and recall of the results: having a 'closed' filter, that is, a strict one regarding the part-of-speech sequencies it accepts, like the N + that (Dagan and Church, 1994) use, wilt improve the precision but have bad effect on the recall.
Most of the research has focused on bilingual terminology identification, either as parallel multiwords forms (e.g. the ChampoUion system (Smadja et a1.1996)), technical terminology (e.g. the Termight system (Dagan and Church, 1994) or broad-coverage translation lexicons (e.g. the SABLE system (Resnik and Melamed, 1997)).
