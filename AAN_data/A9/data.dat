Title:N03-1017		Conference:Human Language Technology Conference And Meeting Of The North American Association For Computational Linguistics		Author:Koehn, Philipp; Och, Franz Josef; Marcu, Daniel
We propose a new phrase-based translationmodel and decoding algorithm that enablesus to evaluate and compare several, previ-ously proposed phrase-based translation mod-els. Within our framework, we carry out alarge number of experiments to understand bet-ter and explain why phrase-based models out-perform word-based models. Our empirical re-sults, which hold for all examined languagepairs, suggest that the highest levels of perfor-mance can be obtained through relatively sim-ple means: heuristic learning of phrase trans-lations from word-based alignments and lexi-cal weighting of phrase translations. Surpris-ingly, learning phrases longer than three wordsand learning phrases from high-accuracy word-level alignment models does not have a strongimpact on performance. Learning only syntac-tically motivated phrases degrades the perfor-mance of our systems.

Title:W03-1001		Conference:Conference On Empirical Methods In Natural Language Processing		Author:Tillmann, Christoph
A word link extension algorithm similar to the one presented in this paper is given in (Koehn et al. , 2003).

Title:N04-4026		Conference:Human Language Technology Conference And Meeting Of The North American Association For Computational Linguistics - Short Papers		Author:Tillmann, Christoph
1 Introduction In recent years, phrase-based systems for statistical machine translation (Och et al. , 1999; Koehn et al. , 2003; Venugopal et al. , 2003) have delivered state-of-the-art performance on standard translation tasks.

Title:P04-1064		Conference:Annual Meeting Of The Association For Computational Linguistics		Author:Goutte, Cyril; Yamada, Kenji; Gaussier, Eric
It is important because a wordaligned corpus is typically used as a first step in order to identify phrases or templates in phrase-based Machine Translation (Och et al. , 1999), (Tillmann and Xia, 2003), (Koehn et al. , 2003, sec.

Title:N04-1033		Conference:Human Language Technology Conference And Meeting Of The North American Association For Computational Linguistics		Author:Zens, Richard; Ney, Hermann
In (Koehn et al. , 2003), various aspects of phrase-based systems are compared, e.g. the phrase extraction method, the underlying word alignment model, or the maximum phrase length.

Title:C04-1090		Conference:International Conference On Computational Linguistics		Author:Lin, Dekang
However, (Koehn et al 2003) found that it is actually harmful to restrict phrases to constituents in parse trees, because the restriction would cause the system to miss many reliable translations, such as the correspondence between there is in English and es gibt (it gives) in German.

Title:N04-1035		Conference:Human Language Technology Conference And Meeting Of The North American Association For Computational Linguistics		Author:Galley, Michel; Hopkins, Mark; Knight, Kevin; Marcu, Daniel
Along this line, (Koehn et al. , 2003) present convincing evidence that restricting phrasal translation to syntactic constituents yields poor translation performance the ability to translate nonconstituent phrases (such as there are, note that, and according to) turns out to be critical and pervasive. (self citation)

Title:P04-1060		Conference:Annual Meeting Of The Association For Computational Linguistics		Author:Kuhn, Jonas
(Koehn et al. , 2003) show that exploiting all contiguous word blocks in phrase-based alignment is better than focusing on syntactic constituents only.

Title:P04-1023		Conference:Annual Meeting Of The Association For Computational Linguistics		Author:Callison-Burch, Chris; Talbot, David; Osborne, Miles
The phrase-based decoder extracts phrases from the word alignments produced by GIZA++, and computes translation probabilities based on the frequency of one phrase being aligned with another (Koehn et al. , 2003).

Title:H05-1024		Conference:Human Language Technology Conference And Empirical Methods In Natural Language Processing		Author:Ayan, Necip Fazil; Dorr, Bonnie Jean; Monz, Christof
We computed precision, recall and error rate on the entire set for each data set.6 For an initial alignment, we used GIZA++ in both directions (E-to-F and F-to-E, where F is either Chinese (C) or Spanish (S)), and also two different combined alignments: intersection of E-to-F and F-to-E; and RA using a heuristic combination approach called grow-diag-final (Koehn et al. , 2003).

Title:H05-1024		Conference:Human Language Technology Conference And Empirical Methods In Natural Language Processing		Author:Ayan, Necip Fazil; Dorr, Bonnie Jean; Monz, Christof
The standard method to overcome this problem to use the model in both directions (interchanging the source and target languages) and applying heuristic-based combination techniques to produce a refined alignment (Och and Ney, 2000; Koehn et al. , 2003)henceforth referred to as RA. Several researchers have proposed algorithms for improving word alignment systems by injecting additional knowledge or combining different alignment models.

Title:H05-1024		Conference:Human Language Technology Conference And Empirical Methods In Natural Language Processing		Author:Ayan, Necip Fazil; Dorr, Bonnie Jean; Monz, Christof
For our experiments, we chose GIZA++ (Och and Ney, 2000) and the RA approach (Koehn et al. , 2003) the best known alignment combination technique as our initial aligners.1 4.2 TBL Templates Our templates consider consecutive words (of size 1, 2 or 3) in both languages.

Title:W05-0830		Conference:Workshop On Building And Using Parallel Texts		Author:Lioma, Christina; Ounis, Iadh
The inclusion of phrases longer than three words in translation resources has been avoided, as it has been shown not to have a strong impact on translation performance [Koehn et al. , 2003].

Title:W05-0830		Conference:Workshop On Building And Using Parallel Texts		Author:Lioma, Christina; Ounis, Iadh
Whereas language generation has benefited from syntax [Wu, 1997; Alshawi et al. , 2000], the performance of statistical phrase-based machine translation when relying solely on syntactic phrases has been reported to be poor [Koehn et al. , 2003].

Title:P05-1068		Conference:Annual Meeting Of The Association For Computational Linguistics		Author:Hwang, Young-Sook; Sasaki, Yutaka
Recently, various works have improved the quality of statistical machine translation systems by using phrase translation (Koehn et al. , 2003; Marcu et al. , 2002; Och et al. , 1999; Och and Ney, 2000; Zens et al. , 2004).

Title:P05-1069		Conference:Annual Meeting Of The Association For Computational Linguistics		Author:Tillmann, Christoph; Zhang, Tong
3.4 Lexical Weighting The lexical weight a27 a14a12a91 a29 a92a93a21 of the block a9 a72 a14a12a91 a19a86a92a93a21 is computed similarly to (Koehn et al. , 2003), but the lexical translation probability a27 a14a12a94 a29 a97a100a21 is derived from the block set itself rather than from a word alignment, resulting in a simplified training.

Title:P05-1069		Conference:Annual Meeting Of The Association For Computational Linguistics		Author:Tillmann, Christoph; Zhang, Tong
2 Block Orientation Bigrams This section describes a phrase-based model for SMT similar to the models presented in (Koehn et al. , 2003; Och et al. , 1999; Tillmann and Xia, 2003).

Title:P05-1069		Conference:Annual Meeting Of The Association For Computational Linguistics		Author:Tillmann, Christoph; Zhang, Tong
Two block sets are derived for each of the training sets using a phrase-pair selection algorithm similar to (Koehn et al. , 2003; Tillmann and Xia, 2003).

Title:P05-1069		Conference:Annual Meeting Of The Association For Computational Linguistics		Author:Tillmann, Christoph; Zhang, Tong
Lexical Weighting: (e) the lexical weight a27 a14a12a91 a29 a92a93a21 of the block a9 a72 a14a12a91 a19a86a92a93a21 is computed similarly to (Koehn et al. , 2003), details are given in Section 3.4.

Title:W05-0829		Conference:Workshop On Building And Using Parallel Texts		Author:Zhang, Ying; Vogel, Stephan
1 Introduction In recent years, various phrase translation approaches (Marcu and Wong, 2002; Och et al. , 1999; Koehn et al. , 2003) have been shown to outperform word-to-word translation models (Brown et al. , 1993).

Title:H05-1098		Conference:Human Language Technology Conference And Empirical Methods In Natural Language Processing		Author:Chiang, David; Lopez, Adam; Madnani, Nitin; Monz, Christof; Resnik, Philip; Subotin, Michael
The basic model uses the following features, analogous to Pharaohs default feature set: P( | ) and P( | ) the lexical weights Pw( | ) and Pw( | ) (Koehn et al. , 2003);1 a phrase penalty exp(1); a word penalty exp(l), where l is the number of terminals in .

Title:H05-1023		Conference:Human Language Technology Conference And Empirical Methods In Natural Language Processing		Author:Zhao, Bing; Ge, Niyu; Papineni, Kishore
1 Introduction Todays statistical machine translation systems rely on high quality phrase translation pairs to acquire state-of-the-art performance, see (Koehn et al. , 2003; Zens and Ney, 2004; Och and Ney, 2003).

Title:W05-0823		Conference:Workshop On Building And Using Parallel Texts		Author:Banches, Rafael E.; Crego, Josep M.; Gispert, Adri&agrave;; de; Lambert, Patrik; Mari&ntilde;o, Jos&eacute;e B.
1 Introduction During the last decade, statistical machine translation (SMT) systems have evolved from the original word-based approach (Brown et al. , 1993) into phrase-based translation systems (Koehn et al. , 2003).

Title:W05-0826		Conference:Workshop On Building And Using Parallel Texts		Author:Gim&eacute;nez, Jes&uacute;s; M&agrave;rquez, Llu&iacute;s
See (Och and Ney, 2000), (Yamada and Knight, 2001), (Koehn and Knight, 2002), (Koehn et al. , 2003), (Schafer and Yarowsky, 2003) and (Gildea, 2003).

Title:W05-0833		Conference:Workshop On Building And Using Parallel Texts		Author:Groves, Declan; Way, Andy
Accordingly, in this section we describe a set of experiments which extends the work of (Way and Gough, 2005) by evaluating the Marker-based EBMT system of (Gough & Way, 2004b) against a phrase-based SMT system built using the following components: Giza++, to extract the word-level correspondences; The Giza++ word alignments are then refined and used to extract phrasal alignments ((Och & Ney, 2003); or (Koehn et al. , 2003) for a more recent implementation); Probabilities of the extracted phrases are calculated from relative frequencies; The resulting phrase translation table is passed to the Pharaoh phrase-based SMT decoder which along with SRI language modelling toolkit5 performs translation.

Title:W05-0833		Conference:Workshop On Building And Using Parallel Texts		Author:Groves, Declan; Way, Andy
(Koehn et al. , 2003); (Och, 2003)).

Title:H05-1096		Conference:Human Language Technology Conference And Empirical Methods In Natural Language Processing		Author:Ueffing, Nicola; Ney, Hermann
Nowadays, most of the state-of-the-art SMT systems are based on bilingual phrases (Bertoldi et al. , 2004; Koehn et al. , 2003; Och and Ney, 2004; Tillmann, 2003; Vogel et al. , 2004; Zens and Ney, 2004).

Title:H05-1022		Conference:Human Language Technology Conference And Empirical Methods In Natural Language Processing		Author:Deng, Yonggang; Byrne, William
5 Phrase Pair Induction A common approach to phrase-based translation is to extract an inventory of phrase pairs (PPI) from bitext (Koehn et al. , 2003), For example, in the phraseextract algorithm (Och, 2002), a word alignment am1 is generated over the bitext, and all word subsequences ei2i1 and fj2j1 are found that satisfy : am1 : aj [i1,i2] iff j [j1,j2] .

Title:P05-1074		Conference:Annual Meeting Of The Association For Computational Linguistics		Author:Bannard, Colin; Callison-Burch, Chris
Our method for identifying paraphrases is an extension of recent work in phrase-based statistical machine translation (Koehn et al. , 2003).

Title:W05-0836		Conference:Workshop On Building And Using Parallel Texts		Author:Venugopal, Ashish; Zollmann, Andreas; Waibel, Alex
Under a phrase based translation model (Koehn et al. , 2003; Marcu and Wong, 2002), this distinction is important and will be discussed in more detail.

Title:W05-0836		Conference:Workshop On Building And Using Parallel Texts		Author:Venugopal, Ashish; Zollmann, Andreas; Waibel, Alex
For further information on these parameter settings, confer (Koehn et al. , 2003).

Title:W05-0836		Conference:Workshop On Building And Using Parallel Texts		Author:Venugopal, Ashish; Zollmann, Andreas; Waibel, Alex
The first system is the Pharaoh decoder provided by (Koehn et al. , 2003) for the shared data task.

Title:H05-1009		Conference:Human Language Technology Conference And Empirical Methods In Natural Language Processing		Author:Ayan, Necip Fazil; Dorr, Bonnie Jean; Monz, Christof
We computed precision, recall and error rate on the entire set of sentence pairs for each data set.5 To evaluate NeurAlign, we used GIZA++ in both directions (E-to-F and F-to-E, where F is either Chinese (C) or Spanish (S)) as input and a refined alignment approach (Och and Ney, 2000) that uses a heuristic combination method called grow-diagfinal (Koehn et al. , 2003) for comparison.

Title:P05-2016		Conference:Annual Meeting Of The Association For Computational Linguistics - Student Research Workshop		Author:Fox, Heidi J.
Statistical Phrase-based Translation (Koehn et al. , 2003): Here phrase-based means subsequence-based, as there is no guarantee that the phrases learned by the model will have any relation to what we would think of as syntactic phrases.

Title:P05-1066		Conference:Annual Meeting Of The Association For Computational Linguistics		Author:Collins, Michael John; Koehn, Philipp; Kucerova, Ivona
Results using the method show an improvement from 25.2% Bleu score to 26.8% Bleu score (a statistically significant improvement), using a phrase-based system (Koehn et al. , 2003) which has been shown in the past to be a highly competitive SMT system. (self citation)

Title:P05-1066		Conference:Annual Meeting Of The Association For Computational Linguistics		Author:Collins, Michael John; Koehn, Philipp; Kucerova, Ivona
1 Introduction Recent research on statistical machine translation (SMT) has lead to the development of phrasebased systems (Och et al. , 1999; Marcu and Wong, 2002; Koehn et al. , 2003). (self citation)

Title:P05-1066		Conference:Annual Meeting Of The Association For Computational Linguistics		Author:Collins, Michael John; Koehn, Philipp; Kucerova, Ivona
More recently, phrase-based models (Och et al. , 1999; Marcu and Wong, 2002; Koehn et al. , 2003) have been proposed as a highly successful alternative to the IBM models. (self citation)

Title:P05-1066		Conference:Annual Meeting Of The Association For Computational Linguistics		Author:Collins, Michael John; Koehn, Philipp; Kucerova, Ivona
Our baseline is the phrase-based MT system of (Koehn et al. , 2003). (self citation)

Title:P05-1066		Conference:Annual Meeting Of The Association For Computational Linguistics		Author:Collins, Michael John; Koehn, Philipp; Kucerova, Ivona
In experiments with the system of (Koehn et al. , 2003) we have found that in practice a large number of complete translations are completely monotonic (i.e. , have a0 skips), suggesting that the system has difficulty learning exactly what points in the translation should allow reordering. (self citation)

Title:P05-1066		Conference:Annual Meeting Of The Association For Computational Linguistics		Author:Collins, Michael John; Koehn, Philipp; Kucerova, Ivona
In this paper we use the phrase-based system of (Koehn et al. , 2003) as our underlying model. (self citation)

Title:P05-1033		Conference:Annual Meeting Of The Association For Computational Linguistics		Author:Chiang, David
We compared a baseline system, the state-of-the-art phrase-based system Pharaoh (Koehn et al. , 2003; Koehn, 2004a), against our system.

Title:P05-1033		Conference:Annual Meeting Of The Association For Computational Linguistics		Author:Chiang, David
To do this, we first identify initial phrase pairs using the same criterion as previous systems (Och and Ney, 2004; Koehn et al. , 2003): Definition 1.

Title:P05-1033		Conference:Annual Meeting Of The Association For Computational Linguistics		Author:Chiang, David
When we run a phrase-based system, Pharaoh (Koehn et al. , 2003; Koehn, 2004a), on this sentence (using the experimental setup described below), we get the following phrases with translations: (4) [Aozhou] [shi] [yu] [Bei Han] [you] [bangjiao]1 [de shaoshu guojia zhiyi] [Australia] [is] [dipl.

Title:P05-1033		Conference:Annual Meeting Of The Association For Computational Linguistics		Author:Chiang, David
For our experiments we used the following features, analogous to Pharaohs default feature set: P( | ) and P( | ), the latter of which is not found in the noisy-channel model, but has been previously found to be a helpful feature (Och and Ney, 2002); the lexical weights Pw( | ) and Pw( | ) (Koehn et al. , 2003), which estimate how well the words in translate the words in ;2 a phrase penalty exp(1), which allows the model to learn a preference for longer or shorter derivations, analogous to Koehns phrase penalty (Koehn, 2003).

Title:P05-1033		Conference:Annual Meeting Of The Association For Computational Linguistics		Author:Chiang, David
5.1 Baseline The baseline system we used for comparison was Pharaoh (Koehn et al. , 2003; Koehn, 2004a), as publicly distributed.

Title:P05-1033		Conference:Annual Meeting Of The Association For Computational Linguistics		Author:Chiang, David
Above the phrase level, these models typically have a simple distortion model that reorders phrases independently of their content (Och and Ney, 2004; Koehn et al. , 2003), or not at all (Zens and Ney, 2004; Kumar et al. , 2005).

Title:H05-1021		Conference:Human Language Technology Conference And Empirical Methods In Natural Language Processing		Author:Kumar, Shankar; Byrne, William
Phrase-pairs are then extracted from the word alignments (Koehn et al. , 2003).

Title:W06-1607		Conference:Conference On Empirical Methods In Natural Language Processing		Author:Foster, George; Kuhn, Roland; Johnson, Howard
Traditionally, maximum-likelihood estimation from relative frequencies is used to obtain conditional probabilities (Koehn et al. , 2003), eg, p(s|t) = c(s,t)/summationtexts c(s,t) (since the estimation problems for p(s|t) and p(t|s) are symmetrical, we will usually refer only to p(s|t) for brevity).

Title:W06-1607		Conference:Conference On Empirical Methods In Natural Language Processing		Author:Foster, George; Kuhn, Roland; Johnson, Howard
The features used in this study are: the length of t; a single-parameter distortion penalty on phrase reordering in a, as described in (Koehn et al. , 2003); phrase translation model probabilities; and trigram language model probabilities logp(t), using Kneser-Ney smoothing as implemented in the SRILM toolkit (Stolcke, 2002).

Title:W06-1607		Conference:Conference On Empirical Methods In Natural Language Processing		Author:Foster, George; Kuhn, Roland; Johnson, Howard
To derive the joint counts c(s,t) from which p(s|t) and p(t|s) are estimated, we use the phrase induction algorithm described in (Koehn et al. , 2003), with symmetrized word alignments generated using IBM model 2 (Brown et al. , 1993).

Title:W06-1607		Conference:Conference On Empirical Methods In Natural Language Processing		Author:Foster, George; Kuhn, Roland; Johnson, Howard
This is the traditional approach for glass-box smoothing (Koehn et al. , 2003; Zens and Ney, 2004).

Title:P06-1090		Conference:International Conference On Computational Linguistics And Annual Meeting Of The Association For Computational Linguistics		Author:Nagata, Masaaki; Saito, Kuniko; Yamamoto, Kazuhide; Ohashi, Kazuteru
(Koehn et al. , 2003) used the following distortion model, which simply penalizes nonmonotonic phrase alignments based on the word distance of successively translated source phrases with an appropriate value for the parameter a71, a36a51a4a39a38 a33 a40a52a42 a33a53a45 a32 a8 a10 a71a26a72a73a25a74 a45a62a75 a74a77a76a24a78 a45 a32 a72 (3) a79a17a80a82a81a84a83a85a15a86a88a87a70a89a91a90 languageis a means communication of MG RA RA b1 b2 b3 b4 Figure 1: Phrase alignment and reordering bi-1 bi fi-1 fi ei-1 ei bi-1 bi fi-1 fi ei-1 ei bi-1 bi fi-1 fi ei-1 ei bi-1 bi fi-1 fi ei-1 ei source target target source target target source source d=MA d=MG d=RA d=RG Figure 2: Four types of reordering patterns 3 The Global Phrase Reordering Model Figure 1 shows an example of Japanese-English phrase alignment that consists of four phrase pairs.

Title:P06-1090		Conference:International Conference On Computational Linguistics And Annual Meeting Of The Association For Computational Linguistics		Author:Nagata, Masaaki; Saito, Kuniko; Yamamoto, Kazuhide; Ohashi, Kazuteru
The translation model used in (Koehn et al. , 2003) is the product of translation probability a34a35a4 a29 a0 a33 a6 a29 a2 a33 a8 and distortion probability a36a37a4a39a38 a33a41a40a43a42a44a33a46a45 a32 a8, a3a5a4a35a29 a0 a30 a32 a6 a29 a2 a30 a32 a8 a10 a30 a47 a33a49a48 a32 a34a35a4 a29 a0a22a33 a6 a29 a2 a33a50a8 a36a51a4a39a38 a33 a40a52a42 a33a53a45 a32 a8 (1) where a38 a33 denotes the start position of the source phrase translated into the a54 -th target phrase, and a42 a33a53a45 a32 denotes the end position of the source phrase translated into the a4a53a54 a40a56a55 a8 -th target phrase.

Title:P06-1090		Conference:International Conference On Computational Linguistics And Annual Meeting Of The Association For Computational Linguistics		Author:Nagata, Masaaki; Saito, Kuniko; Yamamoto, Kazuhide; Ohashi, Kazuteru
a1 Graduated in March 2006 Standard phrase-based translation systems use a word distance-based reordering model in which non-monotonic phrase alignment is penalized based on the word distance between successively translated source phrases without considering the orientation of the phrase alignment or the identities of the source and target phrases (Koehn et al. , 2003; Och and Ney, 2004).

Title:P06-1090		Conference:International Conference On Computational Linguistics And Annual Meeting Of The Association For Computational Linguistics		Author:Nagata, Masaaki; Saito, Kuniko; Yamamoto, Kazuhide; Ohashi, Kazuteru
For comparison, we also implemented a different N-best phrase alignment method, where _ _ _ _ the_light_was_red _ _ _ the_light was_red _ _ the_light was red (1) (2) (3) Figure 4: N-best phrase alignments phrase pairs are extracted using the standard phrase extraction method described in (Koehn et al. , 2003).

Title:P06-1090		Conference:International Conference On Computational Linguistics And Annual Meeting Of The Association For Computational Linguistics		Author:Nagata, Masaaki; Saito, Kuniko; Yamamoto, Kazuhide; Ohashi, Kazuteru
Here, ppicker shows the accuracy when phrases are extracted by using the N-best phrase alignment method described in Section 4.1, while growdiag-final shows the accuracy when phrases are extracted using the standard phrase extraction algorithm described in (Koehn et al. , 2003).

Title:W06-3123		Conference:Workshop On Statistical Machine Translation		Author:Birch, Alexandra; Callison-Burch, Chris; Osborne, Miles; Koehn, Philipp
For the future, the joint model would benefit from lexical weighting like that used in the standard model (Koehn et al. , 2003). (self citation)

Title:W06-3123		Conference:Workshop On Statistical Machine Translation		Author:Birch, Alexandra; Callison-Burch, Chris; Osborne, Miles; Koehn, Philipp
On smaller data sets (Koehn et al. , 2003) the joint model shows performance comparable to the standard model, however the joint model does not reach the level of performance of the stan156 EN-ES ES-EN Joint 3-gram, dl4 20.51 26.64 5-gram, dl6 26.34 27.17 + lex. (self citation)

Title:W06-3123		Conference:Workshop On Statistical Machine Translation		Author:Birch, Alexandra; Callison-Burch, Chris; Osborne, Miles; Koehn, Philipp
154 2 Translation Models 2.1 Standard Phrase-based Model Most phrase-based translation models (Och, 2003; Koehn et al. , 2003; Vogel et al. , 2003) rely on a pre-existing set of word-based alignments from which they induce their parameters. (self citation)

Title:N06-1003		Conference:Human Language Technology Conference And Meeting Of The North American Association For Computational Linguistics		Author:Callison-Burch, Chris; Koehn, Philipp; Osborne, Miles
2 The Problem of Coverage in SMT Statistical machine translation made considerable advances in translation quality with the introduction of phrase-based translation (Marcu and Wong, 2002; Koehn et al. , 2003; Och and Ney, 2004). (self citation)

Title:W06-3119		Conference:Workshop On Statistical Machine Translation		Author:Zollmann, Andreas; Venugopal, Ashish
Baseline Pharaoh with phrases extracted from IBM Model 4 training with maximum phrase length 7 and extraction method diag-growthfinal (Koehn et al. , 2003a) Lex Phrase-decoder simulation: using only the initial lexical rules from the phrase table, all with LHS X, the Glue rule, and a binary reordering rule with its own reordering-feature XCat All nonterminals merged into a single X nonterminal: simulation of the system Hiero (Chiang, 2005).

Title:W06-3119		Conference:Workshop On Statistical Machine Translation		Author:Zollmann, Andreas; Venugopal, Ashish
The hierarchical translation operations introduced in these methods call for extensions to the traditional beam decoder (Koehn et al. , 2003a).

Title:W06-3119		Conference:Workshop On Statistical Machine Translation		Author:Zollmann, Andreas; Venugopal, Ashish
138 2 Rule Generation We start with phrase translations on the parallel training data using the techniques and implementation described in (Koehn et al. , 2003a).

Title:W06-3119		Conference:Workshop On Statistical Machine Translation		Author:Zollmann, Andreas; Venugopal, Ashish
We use the following features for our rules: sourceand target-conditioned neg-log lexical weights as described in (Koehn et al. , 2003b) neg-log relative frequencies: left-handside-conditioned, target-phrase-conditioned, source-phrase-conditioned Counters: n.o. rule applications, n.o. target words Flags: IsPurelyLexical (i.e. , contains only terminals), IsPurelyAbstract (i.e. , contains only nonterminals), IsXRule (i.e. , non-syntactical span), IsGlueRule 139 Penalties: rareness penalty exp(1 RuleFrequency); unbalancedness penalty |MeanTargetSourceRatio n.o. source words n.o. target words| 4 Parsing Our SynCFG rules are equivalent to a probabilistic context-free grammar and decoding is therefore an application of chart parsing.

Title:W06-3119		Conference:Workshop On Statistical Machine Translation		Author:Zollmann, Andreas; Venugopal, Ashish
5 Results We present results that compare our system against the baseline Pharaoh implementation (Koehn et al. , 2003a) and MER training scripts provided for this workshop.

Title:W06-3119		Conference:Workshop On Statistical Machine Translation		Author:Zollmann, Andreas; Venugopal, Ashish
1 Introduction Recent work in machine translation has evolved from the traditional word (Brown et al. , 1993) and phrase based (Koehn et al. , 2003a) models to include hierarchical phrase models (Chiang, 2005) and bilingual synchronous grammars (Melamed, 2004).

Title:W06-3102		Conference:Workshop On Statistical Machine Translation		Author:Durgar El-Kahlout, Ilknur; Oflazer, Kemal
Table 2: The set of tags used to mark explicit morphemes in English Tag Meaning JJR Adjective, comparative JJS Adjective, superlative NNS Noun, plural POS Possessive ending RBR Adverb, comparative RBS Adverb, superlative VB Verb, base form VBD Verb, past tense VBG Verb, gerund or present participle VBN Verb, past participle VBP Verb, non3rd person singular present VBZ Verb, 3rd person singular present Figure 2: Morpheme alignment between a Turkish and an English sentence 4 Experiments We proceeded with the following sequence of experiments: (1) Baseline: As a baseline system, we used a pure word-based approach and used Pharaoh Training tool (2004), to train on the 22,500 sentences, and decoded using Pharaoh (Koehn et al. , 2003) to obtain translations for a test set of 50 sentences.

Title:W06-1608		Conference:Conference On Empirical Methods In Natural Language Processing		Author:Quirk, Chris; Corston-Oliver, Simon H.
It has been shown that phrasal machine translation systems are not affected by the quality of the input word alignments (Koehn et al. , 2003).

Title:W06-1608		Conference:Conference On Empirical Methods In Natural Language Processing		Author:Quirk, Chris; Corston-Oliver, Simon H.
This dependency graph is partitioned into treelets; like (Koehn et al. , 2003), we assume a uniform probability distribution over all partitions.

Title:W06-1608		Conference:Conference On Empirical Methods In Natural Language Processing		Author:Quirk, Chris; Corston-Oliver, Simon H.
In Englishto-German, this result produces results very comparable to a phrasal SMT system (Koehn et al. , 2003) trained on the same data.

Title:W06-3112		Conference:Workshop On Statistical Machine Translation		Author:Owczarzak, Karolina; Groves, Declan; van Genabith, Josef; Way, Andy
Word alignment and phrase extraction We used the GIZA++ word alignment software 3 to produce initial word alignments for our miniature bilingual corpus consisting of the source French file and the English reference file, and the refined word alignment strategy of (Och and Ney, 2003; Koehn et al. , 2003; Tiedemann, 2004) to obtain improved word and phrase alignments.

Title:P06-2107		Conference:International Conference On Computational Linguistics And Annual Meeting Of The Association For Computational Linguistics - Poster Sessions		Author:Tom&aacute;s, Jes&uacute;s; Casacuberta, Francisco
The second one is heuristic and tries to use a wordaligned corpus (Zens et al. , 2002; Koehn et al. , 2003).

Title:N06-1002		Conference:Human Language Technology Conference And Meeting Of The North American Association For Computational Linguistics		Author:Quirk, Chris; Menezes, Arul
As an additional baseline, we compare against a phrasal SMT decoder, Pharaoh (Koehn et al. 2003).

Title:N06-1002		Conference:Human Language Technology Conference And Meeting Of The North American Association For Computational Linguistics		Author:Quirk, Chris; Menezes, Arul
We used the heuristic combination described in (Och and Ney 2003) and extracted phrasal translation pairs from this combined alignment as described in (Koehn et al. , 2003).

Title:P06-1091		Conference:International Conference On Computational Linguistics And Annual Meeting Of The Association For Computational Linguistics		Author:Tillmann, Christoph; Zhang, Tong
Word-based features are used as well, e.g. feature a75 a11a39a99a78a99a18a11 captures word-to-word translation de4On our test set, (Tillmann and Zhang, 2005) reports a BLEU score of a100a63a101a63a102a43a103 and (Ittycheriah and Roukos, 2005) reports a BLEU score of a104a89a103a63a102 a105 . pendencies similar to the use of Model a98 probabilities in (Koehn et al. , 2003).

Title:P06-1091		Conference:International Conference On Computational Linguistics And Annual Meeting Of The Association For Computational Linguistics		Author:Tillmann, Christoph; Zhang, Tong
The block set is generated using a phrase-pair selection algorithm similar to (Koehn et al. , 2003; Al-Onaizan et al. , 2004), which includes some heuristic filtering to mal statement here.

Title:W06-3122		Conference:Workshop On Statistical Machine Translation		Author:Olteanu, Marian; Suriyentrakorn, Pasin; Moldovan, Dan
It generates a vector of 5 numeric values for each phrase pair: phrase translation probability: ( f|e) = count( f, e) count(e),(e| f) = count( f, e) count( f) 2http://www.phramer.org/ Java-based open-source phrase based SMT system 3http://www.isi.edu/licensed-sw/carmel/ 4http://www.speech.sri.com/projects/srilm/ 5http://www.iccs.inf.ed.ac.uk/pkoehn/training.tgz 150 lexical weighting (Koehn et al. , 2003): lex( f|e,a) = nproductdisplay i=1 1 |{j|(i, j) a}| summationdisplay (i,j)a w(fi|ej) lex(e|f,a) = mproductdisplay j=1 1 |{i|(i, j) a}| summationdisplay (i,j)a w(ej|fi) phrase penalty: ( f|e) = e; log(( f|e)) = 1 2.2 Decoding We used the Pharaoh decoder for both the Minimum Error Rate Training (Och, 2003) and test dataset decoding.

Title:W06-3121		Conference:Workshop On Statistical Machine Translation		Author:Olteanu, Marian; Davis, Chris; Volosen, Ionut; Moldovan, Dan
We generated for each phrase pair in the translation table 5 features: phrase translation probability (both directions), lexical weighting (Koehn et al. , 2003) (both directions) and phrase penalty (constant value).

Title:P06-1067		Conference:International Conference On Computational Linguistics And Annual Meeting Of The Association For Computational Linguistics		Author:Al-Onaizan, Yaser; Papineni, Kishore
Similarly, (Koehn et al. , 2003) propose a relative distortion model to be used with a phrase decoder.

Title:N06-1032		Conference:Human Language Technology Conference And Meeting Of The North American Association For Computational Linguistics		Author:Riezler, Stefan; Maxwell III, John T.
1 Introduction Recent approaches to statistical machine translation (SMT) piggyback on the central concepts of phrasebased SMT (Och et al. , 1999; Koehn et al. , 2003) and at the same time attempt to improve some of its shortcomings by incorporating syntactic knowledge in the translation process.

Title:P06-1123		Conference:International Conference On Computational Linguistics And Annual Meeting Of The Association For Computational Linguistics		Author:Wellington, Benjamin; Waxmonsky, Sonjia; Melamed, I. Dan
is relevant to finite-state phrase-based models that use no parse trees (Koehn et al. , 2003), tree-tostring models that rely on one parse tree (Yamada and Knight, 2001), and tree-to-tree models that rely on two parse trees (Groves et al. , 2004, e.g.).

Title:N06-1013		Conference:Human Language Technology Conference And Meeting Of The North American Association For Computational Linguistics		Author:Ayan, Necip Fazil; Dorr, Bonnie Jean
Based on the observations in (Koehn et al. , 2003), we also limited the phrase length to 3 for computational reasons.

Title:N06-1013		Conference:Human Language Technology Conference And Meeting Of The North American Association For Computational Linguistics		Author:Ayan, Necip Fazil; Dorr, Bonnie Jean
For comparison purposes, three additional heuristically-induced alignments are generated for each system: (1) Intersection of both directions (Aligner(int)); (2) Union of both directions (Aligner(union)); and (3) The previously bestknown heuristic combination approach called growdiag-final (Koehn et al. , 2003) (Aligner(gdf)).

Title:N06-1013		Conference:Human Language Technology Conference And Meeting Of The North American Association For Computational Linguistics		Author:Ayan, Necip Fazil; Dorr, Bonnie Jean
1 Introduction Word alignmentdetection of corresponding words between two sentences that are translations of each otheris usually an intermediate step of statistical machine translation (MT) (Brown et al. , 1993; Och and Ney, 2003; Koehn et al. , 2003), but also has been shown useful for other applications such as construction of bilingual lexicons, word-sense disambiguation, projection of resources, and crosslanguage information retrieval.

Title:W06-3115		Conference:Workshop On Statistical Machine Translation		Author:Watanabe, Taro; Tsukada, Hajime; Isozaki, Hideki
In a phrase-based statistical translation (Koehn et al. , 2003), a bilingual text is decomposed as K phrase translation pairs (e1, fa1), (e2, fa2 ),: The input foreign sentence is segmented into phrases f K1, 122 mapped into corresponding English eK1, then, reordered to form the output English sentence according to a phrase alignment index mapping a. In a hierarchical phrase-based translation (Chiang, 2005), translation is modeled after a weighted synchronous-CFG consisting of production rules whose right-hand side is paired (Aho and Ullman, 1969): X ,, where X is a non-terminal, and are strings of terminals and non-terminals.

Title:W06-3115		Conference:Workshop On Statistical Machine Translation		Author:Watanabe, Taro; Tsukada, Hajime; Isozaki, Hideki
Second, phrase translation pairs are extracted from the word aligned corpus (Koehn et al. , 2003).

Title:W06-3115		Conference:Workshop On Statistical Machine Translation		Author:Watanabe, Taro; Tsukada, Hajime; Isozaki, Hideki
The decoding process is very similar to those described in (Koehn et al. , 2003): It starts from an initial empty hypothesis.

Title:W06-3115		Conference:Workshop On Statistical Machine Translation		Author:Watanabe, Taro; Tsukada, Hajime; Isozaki, Hideki
One is a phrase-based translation in which a phrasal unit is employed for translation (Koehn et al. , 2003).

Title:W06-3115		Conference:Workshop On Statistical Machine Translation		Author:Watanabe, Taro; Tsukada, Hajime; Isozaki, Hideki
For each differently tokenized corpus, we computed word alignments by a HMM translation model (Och and Ney, 2003) and by a word alignment refinement heuristic of grow-diagfinal (Koehn et al. , 2003).

Title:W06-3115		Conference:Workshop On Statistical Machine Translation		Author:Watanabe, Taro; Tsukada, Hajime; Isozaki, Hideki
2.3 Feature Functions Our phrase-based model uses a standard pharaoh feature functions listed as follows (Koehn et al. , 2003): Relative-count based phrase translation probabilities in both directions.

Title:P06-1066		Conference:International Conference On Computational Linguistics And Annual Meeting Of The Association For Computational Linguistics		Author:Xiong, Deyi; Liu, Qun; Lin, Shouxun
One is distortion model (Och and Ney, 2004; Koehn et al. , 2003) which penalizes translations according to their jump distance instead of their content.

Title:N06-1031		Conference:Human Language Technology Conference And Meeting Of The North American Association For Computational Linguistics		Author:Huang, Bryant; Knight, Kevin
1 Introduction Recent work in statistical machine translation (MT) has sought to overcome the limitations of phrasebased models (Marcu and Wong, 2002; Koehn et al. , 2003; Och and Ney, 2004) by making use of syntactic information.

Title:P06-1122		Conference:International Conference On Computational Linguistics And Annual Meeting Of The Association For Computational Linguistics		Author:Talbot, David; Osborne, Miles
4 Experiments Phrase-based SMT systems have been shown to outperform word-based approaches (Koehn et al. , 2003).

Title:P06-1122		Conference:International Conference On Computational Linguistics And Annual Meeting Of The Association For Computational Linguistics		Author:Talbot, David; Osborne, Miles
4.1 Applications to phrase-based SMT Aphrase-basedtranslationmodelcanbeestimated in two stages: first a parallel corpus is aligned at the word-level and then phrase pairs are extracted (Koehn et al. , 2003).

Title:W06-1606		Conference:Conference On Empirical Methods In Natural Language Processing		Author:Marcu, Daniel; Wang, Wei; Echihabi, Abdessamad; Knight, Kevin
1 Introduction During the last four years, various implementations and extentions to phrase-based statistical models (Marcu and Wong, 2002; Koehn et al. , 2003; Och and Ney, 2004) have led to significant increases in machine translation accuracy. (self citation)

Title:W06-3120		Conference:Workshop On Statistical Machine Translation		Author:Costa-Juss&agrave;, Marta Ruiz; Crego, Josep M.; Gispert, Adri&agrave;; de; Lambert, Patrik; Khalilov, Maxim; Banches, Rafael E.; Mari&ntilde;o, Jos&eacute;e B.; Fonollosa, Jos&eacute;; A. R.
The huge increase in computational and storage cost of including longer phrases does not provide a signi cant improvement in quality (Koehn et al. , 2003) as the probability of reappearance of larger phrases decreases.

Title:P06-2101		Conference:International Conference On Computational Linguistics And Annual Meeting Of The Association For Computational Linguistics - Poster Sessions		Author:Smith, David A.; Eisner, Jason M.
791 and score the alignment template models phrases (Koehn et al. , 2003).

Title:N06-1004		Conference:Human Language Technology Conference And Meeting Of The North American Association For Computational Linguistics		Author:Kuhn, Roland; Yuen, Denis; Simard, Michel; Paul, Patrick; Foster, George; Joanis, Eric; Johnson, Howard
1 Introduction: Defining SCMs The work presented here was done in the context of phrase-based MT (Koehn et al. , 2003; Och and Ney, 2004).

Title:N06-1004		Conference:Human Language Technology Conference And Meeting Of The North American Association For Computational Linguistics		Author:Kuhn, Roland; Yuen, Denis; Simard, Michel; Paul, Patrick; Foster, George; Joanis, Eric; Johnson, Howard
Phrase tables were learned from the training corpus using the diag-and method (Koehn et al. , 2003), and using IBM model 2 to produce initial word alignments (these authors found this worked as well as IBM4).

Title:P06-2005		Conference:International Conference On Computational Linguistics And Annual Meeting Of The Association For Computational Linguistics - Poster Sessions		Author:Aw, Aiti; Zhang, Min; Xiao, Juan; Su, Jian
The normalization is visualized as a translation problem where messages in the SMS language are to be translated to normal English using a similar phrase-based statistical MT method (Koehn et al. , 2003).

Title:P06-1077		Conference:International Conference On Computational Linguistics And Annual Meeting Of The Association For Computational Linguistics		Author:Liu, Yang; Liu, Qun; Lin, Shouxun
5.1 Pharaoh The baseline system we used for comparison was Pharaoh (Koehn et al. , 2003; Koehn, 2004), a freely available decoder for phrase-based translation models: p(e|f) = p(f|e) pLM(e)LM pD(e,f)D length(e)W(e) (10) We ran GIZA++ (Och and Ney, 2000) on the training corpus in both directions using its default setting, and then applied the refinement rule diagand described in (Koehn et al. , 2003) to obtain a single many-to-many word alignment for each sentence pair.

Title:P06-1077		Conference:International Conference On Computational Linguistics And Annual Meeting Of The Association For Computational Linguistics		Author:Liu, Yang; Liu, Qun; Lin, Shouxun
h1(eI1,fJ1 ) = log Kproductdisplay k=1 N(z)(T(z), Tk) N(T(z)) h2(eI1,fJ1 ) = log Kproductdisplay k=1 N(z)(T(z), Tk) N(S(z)) h3(eI1,fJ1 ) = log Kproductdisplay k=1 lex(T(z)|S(z))(T(z), Tk) h4(eI1,fJ1 ) = log Kproductdisplay k=1 lex(S(z)|T(z))(T(z), Tk) h5(eI1,fJ1 ) = K h6(eI1,fJ1 ) = log Iproductdisplay i=1 p(ei|ei2,ei1) h7(eI1,fJ1 ) = I 4When computing lexical weighting features (Koehn et al. , 2003), we take only terminals into account.

Title:P06-1077		Conference:International Conference On Computational Linguistics And Annual Meeting Of The Association For Computational Linguistics		Author:Liu, Yang; Liu, Qun; Lin, Shouxun
1 Introduction Phrase-based translation models (Marcu and Wong, 2002; Koehn et al. , 2003; Och and Ney, 2004), which go beyond the original IBM translation models (Brown et al. , 1993) 1 by modeling translations of phrases rather than individual words, have been suggested to be the state-of-theart in statistical machine translation by empirical evaluations.

Title:W06-3106		Conference:Workshop On Statistical Machine Translation		Author:Langlais, Philippe; Gotti, Fabrizio
It has the advantage of naturally capturing local reorderings and is shown to outperform word-based machine translation (Koehn et al. , 2003).

Title:W06-3106		Conference:Workshop On Statistical Machine Translation		Author:Langlais, Philippe; Gotti, Fabrizio
This includes the standard notion of phrase, popular with phrasedbased SMT (Koehn et al. , 2003; Vogel et al. , 2003) aswellassequencesofwordsthatcontaingaps(possibly of arbitrary size).

Title:W06-3106		Conference:Workshop On Statistical Machine Translation		Author:Langlais, Philippe; Gotti, Fabrizio
PP-model WecollectedthePPparametersbysimply reading the alignment matrices resulting from the word alignment, in a way similar to the one described in (Koehn et al. , 2003).

Title:E06-2002		Conference:Conference Of The European Association For Computational Linguistics - Demonstrations		Author:Cattoni, Roldano; Bertoldi, Nicola; Cettolo, Mauro; Chen, Boxing; Federico, Marcello
By introducing the hidden word alignment variable a, the following approximate optimization criterion can be applied for that purpose: e = argmaxe Pr(e | f) = argmaxe summationdisplay a Pr(e,a | f) argmaxe,a Pr(e,a | f) Exploiting the maximum entropy (Berger et al. , 1996) framework, the conditional distribution Pr(e,a | f) can be determined through suitable real valued functions (called features) hr(e,f,a),r = 1R, and takes the parametric form: p(e,a | f) exp Rsummationdisplay r=1 rhr(e,f,a)} The ITC-irst system (Chen et al. , 2005) is based on a log-linear model which extends the original IBM Model 4 (Brown et al. , 1993) to phrases (Koehn et al. , 2003; Federico and Bertoldi, 2005).

Title:P06-1098		Conference:International Conference On Computational Linguistics And Annual Meeting Of The Association For Computational Linguistics		Author:Watanabe, Taro; Tsukada, Hajime; Isozaki, Hideki
A phrase-based translation model is one of the modern approaches which exploits a phrase, a contiguous sequence of words, as a unit of translation (Koehn et al. , 2003; Zens and Ney, 2003; Tillman, 2004).

Title:P06-1098		Conference:International Conference On Computational Linguistics And Annual Meeting Of The Association For Computational Linguistics		Author:Watanabe, Taro; Tsukada, Hajime; Isozaki, Hideki
Many-to-many word alignments are induced by running a one-to-many word alignment model, such as GIZA++ (Och and Ney, 2003), in both directions and by combining the results based on a heuristic (Koehn et al. , 2003).

Title:P06-1098		Conference:International Conference On Computational Linguistics And Annual Meeting Of The Association For Computational Linguistics		Author:Watanabe, Taro; Tsukada, Hajime; Isozaki, Hideki
Second, phrase translation pairs are extracted from the word alignment corpus (Koehn et al. , 2003).

Title:W06-3125		Conference:Workshop On Statistical Machine Translation		Author:Crego, Josep M.; Gispert, Adri&agrave;; de; Lambert, Patrik; Costa-Juss&agrave;, Marta Ruiz; Khalilov, Maxim; Banches, Rafael E.; Mari&ntilde;o, Jos&eacute;e B.; Fonollosa, Jos&eacute;; A. R.
This translation model differs from the well known phrase-based translation approach (Koehn et al. , 2003) in two basic issues: rst, training data is monotonously segmented into bilingual units; and second, the model considers n-gram probabilities instead of relative frequencies.

Title:P06-1139		Conference:International Conference On Computational Linguistics And Annual Meeting Of The Association For Computational Linguistics		Author:Soricut, Radu; Marcu, Daniel
Automatic Creation of WIDL-expressions for MT. We generate WIDL-expressions from Chinese strings by exploiting a phrase-based translation table (Koehn et al. , 2003). (self citation)

Title:P06-1009		Conference:International Conference On Computational Linguistics And Annual Meeting Of The Association For Computational Linguistics		Author:Blunsom, Philip; Cohn, Trevor
Most current SMT systems (Och and Ney, 2004; Koehn et al. , 2003) use a generative model for word alignment such as the freely available GIZA++ (Och and Ney, 2003), an implementation of the IBM alignment models (Brown et al. , 1993).

Title:W06-3113		Conference:Workshop On Statistical Machine Translation		Author:Federico, Marcello; Bertoldi, Nicola
The current state of the art is represented by the so-called phrase-based translation approach (Och and Ney, 2004; Koehn et al. , 2003).

Title:P06-1096		Conference:International Conference On Computational Linguistics And Annual Meeting Of The Association For Computational Linguistics		Author:Liang, Percy; Bouchard-C&ocirc;t&eacute;, Alexandre; Klein, Dan; Taskar, Ben
The discrepancy between DEV performance and TEST performance is due to temporal distance from TRAIN and high variance in BLEU score.11 We also compared our model with Pharaoh (Koehn et al. , 2003).

Title:P06-1096		Conference:International Conference On Computational Linguistics And Annual Meeting Of The Association For Computational Linguistics		Author:Liang, Percy; Bouchard-C&ocirc;t&eacute;, Alexandre; Klein, Dan; Taskar, Ben
At the end we ran our models once on TEST to get final numbers.2 4 Models Our experiments used phrase-based models (Koehn et al. , 2003), which require a translation table and language model for decoding and feature computation.

Title:P06-1096		Conference:International Conference On Computational Linguistics And Annual Meeting Of The Association For Computational Linguistics		Author:Liang, Percy; Bouchard-C&ocirc;t&eacute;, Alexandre; Klein, Dan; Taskar, Ben
The process of phrase extraction is difficult to optimize in a non-discriminative setting: many heuristics have been proposed (Koehn et al. , 2003), but it is not obvious which one should be chosen for a given language pair.

Title:P06-1096		Conference:International Conference On Computational Linguistics And Annual Meeting Of The Association For Computational Linguistics		Author:Liang, Percy; Bouchard-C&ocirc;t&eacute;, Alexandre; Klein, Dan; Taskar, Ben
In the future, we plan to explore our discriminative framework on a full distortion model (Koehn et al. , 2003) or even a hierarchical model (Chiang, 2005).

Title:W06-3109		Conference:Workshop On Statistical Machine Translation		Author:Ortiz-Mart&iacute;nez, Daniel; Garc&iacute;a-Varea, Ismael; Casacuberta, Francisco
On the other hand, models that deal with structures or phrases instead of single words have also been proposed: the syntax translation models are described in (Yamada and Knight, 2001), alignment templates are used in (Och, 2002), and the alignment template approach is re-framed into the so-called phrase based translation (PBT) in (Marcu and Wong, 2002; Zens et al. , 2002; Koehn et al. , 2003; Tomas and Casacuberta, 2003).

Title:W06-1609		Conference:Conference On Empirical Methods In Natural Language Processing		Author:Costa-Juss&agrave;, Marta Ruiz; Fonollosa, Jos&eacute;; A. R.
1 Introduction During the last few years, SMT systems have evolved from the original word-based approach (Brown et al. , 1993) to phrase-based translation systems (Koehn et al. , 2003).

Title:N06-1014		Conference:Human Language Technology Conference And Meeting Of The North American Association For Computational Linguistics		Author:Liang, Percy; Taskar, Ben; Klein, Dan
1 Introduction Word alignment is an important component of a complete statistical machine translation pipeline (Koehn et al. , 2003).

Title:N06-1014		Conference:Human Language Technology Conference And Meeting Of The North American Association For Computational Linguistics		Author:Liang, Percy; Taskar, Ben; Klein, Dan
Using GIZA++ model 4 alignments and Pharaoh (Koehn et al. , 2003), we achieved a BLEU score of 0.3035.

Title:N06-1015		Conference:Human Language Technology Conference And Meeting Of The North American Association For Computational Linguistics		Author:Lacoste-Julien, Simon; Taskar, Ben; Klein, Dan; Jordan, Michael I.
We view this as a particularly promising aspect of our work, given that phrase-based systems such as Pharaoh (Koehn et al. , 2003) perform better with higher recall alignments.

Title:W06-3601		Conference:Workshop On Computationally Hard Problems And Joint Inference In Speech And Language Processing		Author:Huang, Liang; Knight, Kevin; Joshi, Aravind K.
2 Previous Work It is helpful to compare this approach with recent efforts in statistical MT. Phrase-based models (Koehn et al. , 2003; Och and Ney, 2004) are good at learning local translations that are pairs of (consecutive) sub-strings, but often insufficient in modeling the reorderings of phrases themselves, especially between language pairs with very different word-order.

Title:P07-1001		Conference:45th Annual Meeting of the Association of Computational Linguistics		Author:Deng, Yonggang; Gao, Yuqing
Our decoder is a phrase-based multi-stack imple5 mentation of the log-linear model similar to Pharaoh (Koehn et al. , 2003).

Title:P07-1039		Conference:45th Annual Meeting of the Association of Computational Linguistics		Author:Ma, Yanjun; Stroppa, Nicolas; Way, Andy
4.3 Baseline We use a standard log-linear phrase-based statistical machine translation system as a baseline: GIZA++ implementation of IBM word alignment model 4 (Brown et al. , 1993; Och and Ney, 2003),8 the refinement and phrase-extraction heuristics described in (Koehn et al. , 2003), minimum-error-rate training 7More specifically, we choose the first English reference from the 7 references and the Chinese sentence to construct new sentence pairs.

Title:P07-1083		Conference:45th Annual Meeting of the Association of Computational Linguistics		Author:Bergsma, Shane; Kondrak, Grzegorz
A similar use of the term phrase exists in machine translation, where phrases are often pairs of word sequences consistent with word-based alignments (Koehn et al. , 2003).

Title:N07-2008		Conference:Human Language Technologies 2007: The Conference of the North American Chapter of the Association for Computational Linguistics; Companion Volume, Short Papers		Author:Enright, Jessica; Kondrak, Grzegorz
They have been employed in word sense disambiguation (Diab and Resnik, 2002), automatic construction of bilingual dictionaries (McEwan et al. , 2002), and inducing statistical machine translation models (Koehn et al. , 2003).

Title:W07-1512		Conference:Linguistic Annotation Workshop		Author:Buch-Kromann, Matthias
However, many of these models are not applicable to parallel treebanks because they assume translation units where either the source text, the target text or both are represented as word sequences without any syntactic structure (Galley et al. , 2004; Marcu et al. , 2006; Koehn et al. , 2003).

Title:D07-1103		Conference:2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning (EMNLP-CoNLL)		Author:Johnson, Howard; Martin, Joel; Foster, George; Kuhn, Roland
These joint counts are estimated using the phrase induction algorithm described in (Koehn et al. , 2003), with symmetrized word alignments generated using IBM model 2 (Brown et al. , 1993).

Title:D07-1103		Conference:2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning (EMNLP-CoNLL)		Author:Johnson, Howard; Martin, Joel; Foster, George; Kuhn, Roland
The features used are: the length of t; a single-parameter distortion penalty on phrase reordering in a, as described in (Koehn et al. , 2003); phrase translation model probabilities; and 4-gram language model probabilities logp(t), using Kneser-Ney smoothing as implemented in the SRILM toolkit (Stolcke, 2002).

Title:W07-0716		Conference:Workshop on Statistical Machine Translation		Author:Madnani, Nitin; Ayan, Necip Fazil; Resnik, Philip; Dorr, Bonnie Jean
1 Introduction Viewed at a very high level, statistical machine translationinvolvesfourphases: languageandtranslation model training, parameter tuning, decoding, and evaluation (Lopez, 2007; Koehn et al. , 2003).

Title:W07-0716		Conference:Workshop on Statistical Machine Translation		Author:Madnani, Nitin; Ayan, Necip Fazil; Resnik, Philip; Dorr, Bonnie Jean
??Initial phrase pairs are identified following the procedure typically employed in phrase based systems (Koehn et al. , 2003; Och and Ney, 2004).

Title:W07-0716		Conference:Workshop on Statistical Machine Translation		Author:Madnani, Nitin; Ayan, Necip Fazil; Resnik, Philip; Dorr, Bonnie Jean
We use the following features in our induced English-to-English grammar:3 3Hiero also uses lexical weights (Koehn et al. , 2003) in both 122 ??The joint probability of the two English hierarchical paraphrases, conditioned on the nonterminal symbol, as defined by this formula: p(e1, e2|x) = c(X ???e1, e2??summationtext e1prime, e2prime c(X ???e1prime, e2prime??

Title:P07-1091		Conference:45th Annual Meeting of the Association of Computational Linguistics		Author:Li, Chi-Ho; Li, Minghui; Zhang, Dongdong; Li, Mu; Zhou, Ming; Guan, Yi
The implementation is similar to the idea of lexical weight in (Koehn et al. , 2003): all points in the alignment matrices of the entire training corpus are collected to calculate the probabilistic distribution, P(t|s), of some TL word 3Some readers may prefer the expression the subtree rooted at node N to node N. The latter term is used in this paper for simplicity.

Title:P07-1091		Conference:45th Annual Meeting of the Association of Computational Linguistics		Author:Li, Chi-Ho; Li, Minghui; Zhang, Dongdong; Li, Mu; Zhou, Ming; Guan, Yi
The translation table is obtained as described in (Koehn et al. , 2003), i.e. the alignment tool GIZA++ is run over the training data in both translation directions, and the two alignTest Setting BLEU B1 standard phrase-based SMT 29.22 B2 (B1) + clause splitting 29.13 Table 2: Experiment Baseline Test Setting BLEU BLEU 2-ary 2,3-ary 1 rule 29.77 30.31 2 ME (phrase label) 29.93 30.49 3 ME (left,right) 30.10 30.53 4 ME ((3)+head) 30.24 30.71 5 ME ((3)+phrase label) 30.12 30.30 6 ME ((4)+context) 30.24 30.76 Table 3: Tests on Various Reordering Models The 3rd column comprises the BLEU scores obtained by reordering binary nodes only, the 4th column the scores by reordering both binary and 3-ary nodes.

Title:P07-1091		Conference:45th Annual Meeting of the Association of Computational Linguistics		Author:Li, Chi-Ho; Li, Minghui; Zhang, Dongdong; Li, Mu; Zhou, Ming; Guan, Yi
For example, the distancebased reordering model (Koehn et al. , 2003) allows a decoder to translate in non-monotonous order, under the constraint that the distance between two phrases translated consecutively does not exceed a limit known as distortion limit.

Title:D07-1056		Conference:2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning (EMNLP-CoNLL)		Author:Zhang, Dongdong; Li, Mu; Li, Chi-Ho; Zhou, Ming
There have been considerable amount of efforts to improve the reordering model in SMT systems, ranging from the fundamental distance-based distortion model (Och and Ney, 2004; Koehn et al. , 2003), flat reordering model (Wu, 1996; Zens et al. , 2004; Kumar et al. , 2005), to lexicalized reordering model (Tillmann, 2004; Kumar et al. , 2005; Koehn et al. , 2005), hierarchical phrase-based model (Chiang, 2005), and maximum entropy-based phrase reordering model (Xiong et al. , 2006).

Title:D07-1056		Conference:2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning (EMNLP-CoNLL)		Author:Zhang, Dongdong; Li, Mu; Li, Chi-Ho; Zhou, Ming
In phrase-based SMT systems (Koehn et al. , 2003; Koehn, 2004), foreign sentences are firstly segmented into phrases which consists of adjacent words.

Title:W07-0704		Conference:Workshop on Statistical Machine Translation		Author:Oflazer, Kemal; Durgar El-Kahlout, Ilknur
We employ the phrase-based SMT framework (Koehn et al. , 2003), and use the Moses toolkit (Koehn et al. , 2007), and the SRILM language modelling toolkit (Stolcke, 2002), and evaluate our decoded translations using the BLEU measure (Papineni et al. , 2002), using a single reference translation.

Title:P07-1089		Conference:45th Annual Meeting of the Association of Computational Linguistics		Author:Liu, Yang; Huang, Yun; Liu, Qun; Lin, Shouxun
We ran GIZA++ (Och and Ney, 2000) on the training corpus in both directions using its default setting, and then applied the refinement rule diagand described in (Koehn et al. , 2003) to obtain a single many-to-many word alignment for each sentence pair.

Title:P07-1089		Conference:45th Annual Meeting of the Association of Computational Linguistics		Author:Liu, Yang; Huang, Yun; Liu, Qun; Lin, Shouxun
We compared our system Lynx against a freely available phrase-based decoder Pharaoh (Koehn et al. , 2003).

Title:P07-1119		Conference:45th Annual Meeting of the Association of Computational Linguistics		Author:Sherif, Tarek; Kondrak, Grzegorz
The phrase-based approach developed for statistical machine translation (Koehn et al. , 2003) is designed to overcome the restrictions on many-tomany mappings in word-based translation models.

Title:P07-1119		Conference:45th Annual Meeting of the Association of Computational Linguistics		Author:Sherif, Tarek; Kondrak, Grzegorz
Starting from a word-based alignment for each pair of sentences, the training for the algorithm accepts all contiguous bilingual phrase pairs (up to a predetermined maximum length) whose words are only aligned with each other (Koehn et al. , 2003).

Title:W07-0719		Conference:Workshop on Statistical Machine Translation		Author:Gim&eacute;nez, Jes&uacute;s; M&agrave;rquez, Llu&iacute;s
159 2.1 Baseline System The baseline system is a phrase-based SMT system (Koehn et al. , 2003), built almost entirely using freely available components.

Title:W07-0719		Conference:Workshop on Statistical Machine Translation		Author:Gim&eacute;nez, Jes&uacute;s; M&agrave;rquez, Llu&iacute;s
1 Introduction Translations tables in Phrase-based Statistical Machine Translation (SMT) are often built on the basis of Maximum-likelihood Estimation (MLE), being one of the major limitations of this approach that the source sentence context in which phrases occur is completely ignored (Koehn et al. , 2003).

Title:N07-1063		Conference:Human Language Technologies 2007: The Conference of the North American Chapter of the Association for Computational Linguistics; Proceedings of the Main Conference		Author:Venugopal, Ashish; Zollmann, Andreas; Vogel, Stephan
Grammar rules were induced with the syntaxbased SMT system SAMT described in (Zollmann and Venugopal, 2006), which requires initial phrase alignments that we generated with GIZA++ (Koehn et al. , 2003), and syntactic parse trees of the target training sentences, generated by the Stanford Parser (D. Klein, 2003) pre-trained on the Penn Treebank.

Title:P07-1059		Conference:45th Annual Meeting of the Association of Computational Linguistics		Author:Riezler, Stefan; Vasserman, Alexander; Tsochantaridis, Ioannis; Mittal, Vibhu O.; Liu, Yi
We present two approaches to SMT-based query expansion, both of which are implemented in the framework of phrase-based SMT (Och and Ney, 2004; Koehn et al. , 2003).

Title:P07-1059		Conference:45th Annual Meeting of the Association of Computational Linguistics		Author:Riezler, Stefan; Vasserman, Alexander; Tsochantaridis, Ioannis; Mittal, Vibhu O.; Liu, Yi
4 SMT-Based Query Expansion Our SMT-based query expansion techniques are based on a recent implementation of the phrasebased SMT framework (Koehn et al. , 2003; Och and Ney, 2004).

Title:N07-2009		Conference:Human Language Technologies 2007: The Conference of the North American Chapter of the Association for Computational Linguistics; Companion Volume, Short Papers		Author:Filali, Karim; Bilmes, Jeff A.
For comparison, we use the MT training program, GIZA++ (Och and Ney, 2003), the phrase-base decoder, Pharaoh (Koehn et al. , 2003), and the wordbased decoder, Rewrite (Germann, 2003).

Title:W07-0703		Conference:Workshop on Statistical Machine Translation		Author:Kashani, Mehdi M.; Joanis, Eric; Kuhn, Roland; Foster, George; Popowich, Fred
To generate phrase pairs from a parallel corpus, we use the "diag-and" phrase induction algorithm described in (Koehn et al, 2003), with symmetrized word alignments generated using IBM model 2 (Brown et al, 1993).

Title:W07-0703		Conference:Workshop on Statistical Machine Translation		Author:Kashani, Mehdi M.; Joanis, Eric; Kuhn, Roland; Foster, George; Popowich, Fred
Portage is a statistical phrase-based SMT system similar to Pharaoh (Koehn et al, 2003).

Title:P07-1108		Conference:45th Annual Meeting of the Association of Computational Linguistics		Author:Wu, Hua; Wang, Haifeng
Thus, equation (3) can be rewritten as = i p i iii i i eppfef )|()|()|( (4) 4.2 Lexical Weight Given a phrase pair ),( ef and a word alignment a between the source word positions ni,,1= and the target word positions mj,,1=, the lexical weight can be estimated according to the following method (Koehn et al. , 2003).

Title:P07-1108		Conference:45th Annual Meeting of the Association of Computational Linguistics		Author:Wu, Hua; Wang, Haifeng
1 Introduction For statistical machine translation (SMT), phrasebased methods (Koehn et al. , 2003; Och and Ney, 2004) and syntax-based methods (Wu, 1997; Alshawi et al. 2000; Yamada and Knignt, 2001; Melamed, 2004; Chiang, 2005; Quick et al. , 2005; Mellebeek et al. , 2006) outperform word-based methods (Brown et al. , 1993).

Title:P07-1108		Conference:45th Annual Meeting of the Association of Computational Linguistics		Author:Wu, Hua; Wang, Haifeng
3 Phrase-Based SMT According to the translation model presented in (Koehn et al. , 2003), given a source sentence f, the best target translation best e can be obtained according to the following model )( )()|(maxarg )|(maxarg e e e eef fee length LM best pp p = = (1) Where the translation model )|( efp can be decomposed into = = I i i iii i i II aefpbadef efp 1 1 1 1 ),|()()|( )|( w (2) Where )|( i i ef and )( 1 ii bad denote phrase translation probability and distortion probability, respectively.

Title:P07-1090		Conference:45th Annual Meeting of the Association of Computational Linguistics		Author:Setiawan, Hendra; Kan, Min-Yen; Li, Haizhou
The basic phrase reordering model is a simple unlexicalized, context-insensitive distortion penalty model (Koehn et al. , 2003).

Title:P07-1090		Conference:45th Annual Meeting of the Association of Computational Linguistics		Author:Setiawan, Hendra; Kan, Min-Yen; Li, Haizhou
However, the pb features yields no noticeable improvement unlike in prefect lexical choice scenario; this is similar to the findings in (Koehn et al. , 2003).

Title:W07-0717		Conference:Workshop on Statistical Machine Translation		Author:Foster, George; Kuhn, Roland
2 Phrase-based Statistical MT Our baseline is a standard phrase-based SMT system (Koehn et al. , 2003).

Title:W07-0717		Conference:Workshop on Statistical Machine Translation		Author:Foster, George; Kuhn, Roland
To derive the joint counts c(?s,?t) from which p(?s|?t) and p(?t|?s) are estimated, we use the phrase induction algorithm described in (Koehn et al. , 2003), with symmetrized word alignments generated using IBM model 2 (Brown et al. , 1993).

Title:W07-0717		Conference:Workshop on Statistical Machine Translation		Author:Foster, George; Kuhn, Roland
The features used in this study are: the length of t; a single-parameter distortion penalty on phrase reordering in a, as described in (Koehn et al. , 2003); phrase translation model probabilities; and 4-gram language model probabilities logp(t), using Kneser-Ney smoothing as implemented in the SRILM toolkit.

Title:J07-1003		Conference:Computational Linguistics		Author:Ueffing, Nicola; Ney, Hermann
Nowadays, most state-of-the-art SMT systems are based on bilingual phrases (Och, Tillmann, and Ney 1999; Koehn, Och, and Marcu 2003; Tillmann 2003; Bertoldi et al. 2004; Vogel et al. 2004; Zens and Ney 2004; Chiang 2005).

Title:D07-1008		Conference:2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning (EMNLP-CoNLL)		Author:Cohn, Trevor; Lapata, Mirella
Our corpora were automatically aligned with Giza++ (Och et al. , 1999) in both directions between source and target and symmetrised using the intersection heuristic (Koehn et al. , 2003).

Title:D07-1105		Conference:2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning (EMNLP-CoNLL)		Author:Macherey, Wolfgang; Och, Franz Josef
For instance, word alignment models are often trained using the GIZA++ toolkit (Och and Ney, 2003); error minimizing training criteria such as the Minimum Error Rate Training (Och, 2003) are employed in order to learn feature function weights for log-linear models; and translation candidates are produced using phrase-based decoders (Koehn et al. , 2003) in combination with n-gram language models (Brants et al. , 2007). (self citation)

Title:P07-2046		Conference:45th Annual Meeting of the Association for Computational Linguistics Companion Volume Proceedings of the Demo and Poster Sessions		Author:Zhang, Ruiqiang; Sumita, Eiichiro
It is an extension of Pharaoh (Koehn et al. , 2003), and supports factor training and decoding.

Title:W07-0403		Conference:SSST, NAACL-HLT 2007 / AMTA Workshop on Syntax and Structure in Statistical Translation		Author:Cherry, Colin; Lin, Dekang
Two are conditionalized phrasal models, each EM trained until performance degrades: C-JPTM3 as described in (Birch et al. , 2006) Phrasal ITG as described in Section 4.1 Three provide alignments for the surface heuristic: GIZA++ with grow-diag-final (GDF) Viterbi Phrasal ITG with and without the noncompositional constraint We use the Pharaoh decoder (Koehn et al. , 2003) with the SMT Shared Task baseline system (Koehn and Monz, 2006).

Title:W07-0403		Conference:SSST, NAACL-HLT 2007 / AMTA Workshop on Syntax and Structure in Statistical Translation		Author:Cherry, Colin; Lin, Dekang
It extracts all consistent phrase pairs from word-aligned bitext (Koehn et al. , 2003).

Title:W07-0403		Conference:SSST, NAACL-HLT 2007 / AMTA Workshop on Syntax and Structure in Statistical Translation		Author:Cherry, Colin; Lin, Dekang
4.1 Translation Modeling We can test our models utility for translation by transforming its parameters into a phrase table for the phrasal decoder Pharaoh (Koehn et al. , 2003).

Title:W07-0403		Conference:SSST, NAACL-HLT 2007 / AMTA Workshop on Syntax and Structure in Statistical Translation		Author:Cherry, Colin; Lin, Dekang
The grow-diag-final (GDF) combination heuristic (Koehn et al. , 2003) adds links so that each new link connects a previously unlinked token.

Title:W07-0403		Conference:SSST, NAACL-HLT 2007 / AMTA Workshop on Syntax and Structure in Statistical Translation		Author:Cherry, Colin; Lin, Dekang
2 Background 2.1 Phrase Table Extraction Phrasal decoders require a phrase table (Koehn et al. , 2003), which contains bilingual phrase pairs and 17 scores indicating their utility.

Title:W07-0403		Conference:SSST, NAACL-HLT 2007 / AMTA Workshop on Syntax and Structure in Statistical Translation		Author:Cherry, Colin; Lin, Dekang
Pharaoh also includes lexical weighting parameters that are derived from the alignments used to induce its phrase pairs (Koehn et al. , 2003).

Title:D07-1030		Conference:2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning (EMNLP-CoNLL)		Author:Hu, Xiaoguang; Wang, Haifeng; Wu, Hua
SMT has evolved from the original word-based approach (Brown et al. , 1993) into phrase-based approaches (Koehn et al. , 2003; Och and Ney, 2004) and syntax-based approaches (Wu, 1997; Alshawi et al. , 2000; Yamada and Knignt, 2001; Chiang, 2005).

Title:D07-1030		Conference:2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning (EMNLP-CoNLL)		Author:Hu, Xiaoguang; Wang, Haifeng; Wu, Hua
3.1 Phrase-Based Models According to the translation model presented in (Koehn et al. , 2003), given a source sentence f, the best target translation can be obtained using the following model best e 288 )( )()(maxarg )(maxarg | | e e e eef fee length LM best pp p = = (1) Where the translation model can be decomposed into )( | efp = = I i i iii i i II aefpbadef efp 1 1 1 1 ),|()()|( )|( w (2) Where )|( i i ef is the phrase translation probability.

Title:N07-1007		Conference:Human Language Technologies 2007: The Conference of the North American Chapter of the Association for Computational Linguistics; Proceedings of the Main Conference		Author:Toutanova, Kristina; Suzuki, Hisami
Most stateof-the-art SMT systems treat grammatical elements in exactly the same way as content words, and rely on general-purpose phrasal translations and target language models to generate these elements (e.g. , Och and Ney, 2002; Koehn et al. , 2003; Quirk et al. , 2005; Chiang, 2005; Galley et al. , 2006).

Title:P07-2045		Conference:45th Annual Meeting of the Association for Computational Linguistics Companion Volume Proceedings of the Demo and Poster Sessions		Author:Koehn, Philipp; Hoang, Hieu; Birch, Alexandra; Callison-Burch, Chris; Federico, Marcello; Bertoldi, Nicola; Cowan, Brooke; Shen, Wade; Moran, Christine; Zens, Richard; Dyer, Chris; Bojar, Ond&#x159;ej; Constantin, Alexandra; Herbst, Evan
1 Motivation Phrase-based statistical machine translation (Koehn et al. 2003) has emerged as the dominant paradigm in machine translation research. (self citation)

Title:W07-0731		Conference:Workshop on Statistical Machine Translation		Author:Zollmann, Andreas; Venugopal, Ashish; Paulik, Matthias; Vogel, Stephan
As in phrasebased translation model estimation, ? also contains two lexical weights (Koehn et al. , 2003), counters for number of target terminals generated.

Title:W07-0731		Conference:Workshop on Statistical Machine Translation		Author:Zollmann, Andreas; Venugopal, Ashish; Paulik, Matthias; Vogel, Stephan
Table 1 shows the impact of increasing reordering window length (Koehn et al. , 2003) on translation quality for the ?dev06??data.2 Increasing the reordering window past 2 has minimal impact on translation quality, implying that most of the reordering effects across Spanish and English are well modeled at the local or phrase level.

Title:W07-0711		Conference:Workshop on Statistical Machine Translation		Author:He, Xiaodong
1 Introduction Word alignment is an important step of most modern approaches to statistical machine translation (Koehn et al. , 2003).

Title:W07-0709		Conference:Workshop on Statistical Machine Translation		Author:Sun, Jiadong; Zhao, Tiejun; Liang, Huashen
5.1 The baseline System used for comparison was Pharaoh (Koehn et al. , 2003; Koehn, 2004), which uses a beam search algorithm for decoding.

Title:J07-2003		Conference:Computational Linguistics		Author:Chiang, David
Above the phrase level, some models perform no reordering (Zens and Ney 2004; Kumar, Deng, and Byrne 2006), some have a simple distortion model that reorders phrases independently of their content (Koehn, Och, and Marcu 2003; Och and Ney 2004), and some, for example, the Alignment Template System (Och et al. 2004; Thayer et al. 2004), hereafter ATS, and the IBM phrase-based system (Tillmann 2004; Tillmann and Zhang 2005), have phrase-reordering models that add some lexical sensitivity.

Title:P07-1092		Conference:45th Annual Meeting of the Association of Computational Linguistics		Author:Cohn, Trevor; Lapata, Mirella
The translation models and lexical scores were estimated on the training corpus whichwasautomaticallyalignedusingGiza++(Och et al. , 1999) in both directions between source and target and symmetrised using the growing heuristic (Koehn et al. , 2003).

Title:P07-1092		Conference:45th Annual Meeting of the Association of Computational Linguistics		Author:Cohn, Trevor; Lapata, Mirella
This represents the translation probability of a phrase when it is decomposed into a series of independent word-for-word translation steps (Koehn et al. , 2003), and has proven a very effective feature (Zens and Ney, 2004; Foster et al. , 2006).

Title:P07-1092		Conference:45th Annual Meeting of the Association of Computational Linguistics		Author:Cohn, Trevor; Lapata, Mirella
1 Introduction Statistical machine translation (Brown et al. , 1993) has seen many improvements in recent years, most notably the transition from wordto phrase-based models (Koehn et al. , 2003).

Title:P07-1092		Conference:45th Annual Meeting of the Association of Computational Linguistics		Author:Cohn, Trevor; Lapata, Mirella
As with conventional smoothing methods (Koehn et al. , 2003; Foster et al. , 2006), triangulation increases the robustness of phrase translation estimates.

Title:P07-1005		Conference:45th Annual Meeting of the Association of Computational Linguistics		Author:Chan, Yee Seng; Ng, Hwee Tou; Chiang, David
Recently, Cabezas and Resnik (2005) experimented with incorporating WSD translations into Pharaoh, a state-of-the-art phrase-based MT system (Koehn et al. , 2003).

Title:P07-1005		Conference:45th Annual Meeting of the Association of Computational Linguistics		Author:Chan, Yee Seng; Ng, Hwee Tou; Chiang, David
To perform translation, state-of-the-art MT systems use a statistical phrase-based approach (Marcu and Wong, 2002; Koehn et al. , 2003; Och and Ney, 2004) by treating phrases as the basic units of translation.

Title:N07-2007		Conference:Human Language Technologies 2007: The Conference of the North American Chapter of the Association for Computational Linguistics; Companion Volume, Short Papers		Author:Elming, Jakob; Habash, Nizar
The baseline we measure against in all of these experiments is the state-of-the-art grow-diag-final (gdf ) alignment refinement heuristic commonly used in phrase-based SMT (Koehn et al. , 2003).

Title:N07-2053		Conference:Human Language Technologies 2007: The Conference of the North American Chapter of the Association for Computational Linguistics; Companion Volume, Short Papers		Author:Zettlemoyer, Luke; Moore, Robert C.
They provide pairs of phrases that are used to construct a large set of potential translations for each input sentence, along with feature values associated with each phrase pair that are used to select the best translation from this set.1 The most widely used method for building phrase translation tables (Koehn et al. , 2003) selects, from a word alignment of a parallel bilingual training corpus, all pairs of phrases (up to a given length) that are consistent with the alignment.

Title:N07-2053		Conference:Human Language Technologies 2007: The Conference of the North American Chapter of the Association for Computational Linguistics; Companion Volume, Short Papers		Author:Zettlemoyer, Luke; Moore, Robert C.
(2006), modified from (Koehn et al. , 2003), which is an average of pairwise word translation probabilities.

Title:D07-1006		Conference:2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning (EMNLP-CoNLL)		Author:Fraser, Alexander; Marcu, Daniel
(Och and Ney, 2003) invented heuristic symmetriza57 FRENCH/ENGLISH ARABIC/ENGLISH SYSTEM F-MEASURE ( = 0.4) BLEU F-MEASURE ( = 0.1) BLEU GIZA++ 73.5 30.63 75.8 51.55 (FRASER AND MARCU, 2006B) 74.1 31.40 79.1 52.89 LEAF UNSUPERVISED 74.5 72.3 LEAF SEMI-SUPERVISED 76.3 31.86 84.5 54.34 Table 3: Experimental Results tion of the output of a 1-to-N model and a M-to-1 model resulting in a M-to-N alignment, this was extended in (Koehn et al. , 2003). (self citation)

Title:D07-1006		Conference:2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning (EMNLP-CoNLL)		Author:Fraser, Alexander; Marcu, Daniel
This operation does not change the collection of phrases or rules extracted from a hypothesized alignment, see, for instance, (Koehn et al. , 2003). (self citation)

Title:D07-1006		Conference:2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning (EMNLP-CoNLL)		Author:Fraser, Alexander; Marcu, Daniel
For French/English translation we use a state of the art phrase-based MT system similar to (Och and Ney, 2004; Koehn et al. , 2003). (self citation)

Title:W07-0409		Conference:SSST, NAACL-HLT 2007 / AMTA Workshop on Syntax and Structure in Statistical Translation		Author:Bonneau-Maynard, H&eacute;l&egrave;ne; Allauzen, Alexandre; D&eacute;chelotte, Daniel; Schwenk, Holger
1 Introduction Recent works in statistical machine translation (SMT) shows how phrase-based modeling (Och and Ney, 2000a; Koehn et al. , 2003) significantly outperform the historical word-based modeling (Brown et al. , 1993).

Title:N07-1022		Conference:Human Language Technologies 2007: The Conference of the North American Chapter of the Association for Computational Linguistics; Proceedings of the Main Conference		Author:Wong, Yuk Wah; Mooney, Raymond J.
Like WASP1, the phrase extraction algorithm of PHARAOH is based on the output of a word alignment model such as GIZA++ (Koehn et al. , 2003), which performs poorly when applied directly to MRLs (Section 3.2).

Title:N07-1022		Conference:Human Language Technologies 2007: The Conference of the North American Chapter of the Association for Computational Linguistics; Proceedings of the Main Conference		Author:Wong, Yuk Wah; Mooney, Raymond J.
In this paper we present results on using a recent phrase-based SMT system, PHARAOH (Koehn et al. , 2003), for NLG.1 Although moderately effec1We also tried IBM Model 4/REWRITE (Germann, 2003), a word-based SMT system, but it gave much worse results.

Title:N07-1022		Conference:Human Language Technologies 2007: The Conference of the North American Chapter of the Association for Computational Linguistics; Proceedings of the Main Conference		Author:Wong, Yuk Wah; Mooney, Raymond J.
Toremedythis situation, we can borrow the probabilistic model of PHARAOH, and define the parsing model as: Pr(d|e(d)) = productdisplay dd w(r(d)) (4) which is the product of the weights of the rules used in a derivation d. The rule weight, w(X ,), is in turn defined as: P(|)1P(|)2Pw(|)3Pw(|)4 exp(||)5 where P(|) and P(|) are the relative frequencies of and , and Pw(|) and Pw(|) are 176 the lexical weights (Koehn et al. , 2003).

Title:N07-1022		Conference:Human Language Technologies 2007: The Conference of the North American Chapter of the Association for Computational Linguistics; Proceedings of the Main Conference		Author:Wong, Yuk Wah; Mooney, Raymond J.
These rules are learned using a word alignment model, which finds an optimal mapping from words to MR predicates given a set of training sentences and their correct MRs. Word alignment models have been widely used for lexical acquisition in SMT (Brown et al. , 1993; Koehn et al. , 2003).

Title:N07-1022		Conference:Human Language Technologies 2007: The Conference of the North American Chapter of the Association for Computational Linguistics; Proceedings of the Main Conference		Author:Wong, Yuk Wah; Mooney, Raymond J.
Following the phrase extraction phase in PHARAOH, we eliminate word gaps by incorporating unaligned words as part of the extracted NL phrases (Koehn et al. , 2003).

Title:N07-1022		Conference:Human Language Technologies 2007: The Conference of the North American Chapter of the Association for Computational Linguistics; Proceedings of the Main Conference		Author:Wong, Yuk Wah; Mooney, Raymond J.
3.1 Generation using PHARAOH PHARAOH (Koehn et al. , 2003) is an SMT system that uses phrases as basic translation units.

Title:W07-0701		Conference:Workshop on Statistical Machine Translation		Author:Menezes, Arul; Quirk, Chris
1 Introduction Modern phrasal SMT systems such as (Koehn et al. , 2003) derive much of their power from being able to memorize and use long phrases.

Title:W07-0701		Conference:Workshop on Statistical Machine Translation		Author:Menezes, Arul; Quirk, Chris
We compared our system to Pharaoh, a leading phrasal SMT decoder (Koehn et al. , 2003), and our treelet system.

Title:N07-1061		Conference:Human Language Technologies 2007: The Conference of the North American Chapter of the Association for Computational Linguistics; Proceedings of the Main Conference		Author:Utiyama, Masao; Isahara, Hitoshi
2 Phrase-based SMT We use a phrase-based SMT system, Pharaoh, (Koehn et al. , 2003; Koehn, 2004), which is based on a log-linear formulation (Och and Ney, 2002).

Title:N07-1061		Conference:Human Language Technologies 2007: The Conference of the North American Chapter of the Association for Computational Linguistics; Proceedings of the Main Conference		Author:Utiyama, Masao; Isahara, Hitoshi
For details on these feature functions, please refer to (Koehn et al. , 2003; Koehn, 2004; Koehn et al. , 2005).

Title:N07-1061		Conference:Human Language Technologies 2007: The Conference of the North American Chapter of the Association for Computational Linguistics; Proceedings of the Main Conference		Author:Utiyama, Masao; Isahara, Hitoshi
The definitions of the phrase and lexical translation probabilities are as follows (Koehn et al. , 2003).

Title:N07-1061		Conference:Human Language Technologies 2007: The Conference of the North American Chapter of the Association for Computational Linguistics; Proceedings of the Main Conference		Author:Utiyama, Masao; Isahara, Hitoshi
That is, phrases are heuristically extracted from word-level alignments produced by doing GIZA++ training on the corresponding parallel corpora (Koehn et al. , 2003).

Title:D07-1104		Conference:2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning (EMNLP-CoNLL)		Author:Lopez, Adam
We symmetrized bidirectional alignments using the growdiag-final heuristic (Koehn et al. , 2003).

Title:D07-1104		Conference:2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning (EMNLP-CoNLL)		Author:Lopez, Adam
So far, these techniques have focused on phrasebased models using contiguous phrases (Koehn et al. , 2003; Och and Ney, 2004).

Title:D07-1080		Conference:2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning (EMNLP-CoNLL)		Author:Watanabe, Taro; Suzuki, Jun; Tsukada, Hajime; Isozaki, Hideki
Such a quasi-syntactic structure can naturally capture the reordering of phrases that is not directly modeled by a conventional phrase-based approach (Koehn et al. , 2003).

Title:D07-1080		Conference:2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning (EMNLP-CoNLL)		Author:Watanabe, Taro; Suzuki, Jun; Tsukada, Hajime; Isozaki, Hideki
1 Introduction The recent advances in statistical machine translation have been achieved by discriminatively training a small number of real-valued features based either on (hierarchical) phrase-based translation (Och and Ney, 2004; Koehn et al. , 2003; Chiang, 2005) or syntax-based translation (Galley et al. , 2006).

Title:D07-1080		Conference:2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning (EMNLP-CoNLL)		Author:Watanabe, Taro; Suzuki, Jun; Tsukada, Hajime; Isozaki, Hideki
Second, the word alignment is refined by a grow-diag-final heuristic (Koehn et al. , 2003).

Title:D07-1036		Conference:2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning (EMNLP-CoNLL)		Author:L&uuml;, Yajuan; Huang, Jin; Liu, Qun
In training process, we use GIZA++ 4 toolkit for word alignment in both translation directions, and apply grow-diag-final method to refine it (Koehn et al. , 2003).

Title:W07-0724		Conference:Workshop on Statistical Machine Translation		Author:Ueffing, Nicola; Simard, Michel; Larkin, Samuel; Johnson, Howard
They are generated from the training corpus via the ?diag-and??method (Koehn et al. , 2003) and smoothed using Kneser-Ney smoothing (Foster et al. , 2006), ??one or several n-gram language model(s) trained with the SRILM toolkit (Stolcke, 2002); in the baseline experiments reported here, we used a trigram model, ??a distortion model which assigns a penalty based on the number of source words which are skipped when generating a new target phrase, ??a word penalty.

Title:W07-0721		Conference:Workshop on Statistical Machine Translation		Author:Costa-Juss&agrave;, Marta Ruiz; Fonollosa, Jos&eacute;; A. R.
1 Introduction Nowadays, statistical machine translation is mainly based on phrases (Koehn et al. , 2003).

Title:W07-0725		Conference:Workshop on Statistical Machine Translation		Author:Schwenk, Holger
2 Architecture of the system The goal of statistical machine translation (SMT) is to produce a target sentence e from a source sentence f. It is today common practice to use phrases as translation units (Koehn et al. , 2003; Och and Ney, 2003) and a log linear framework in order to introduce several models explaining the translation process: e??= argmaxp(e|f) = argmaxe {exp(summationdisplay i ihi(e,f))} (1) The feature functions hi are the system models and the i weights are typically optimized to maximize a scoring function on a development set (Och and Ney, 2002).

Title:N07-2015		Conference:Human Language Technologies 2007: The Conference of the North American Chapter of the Association for Computational Linguistics; Companion Volume, Short Papers		Author:Hasan, Sa&scaron;a; Zens, Richard; Ney, Hermann
Many research groups use a decoder based on a log-linear approach incorporating phrases as main paradigm (Koehn et al. , 2003).

Title:D07-1079		Conference:2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning (EMNLP-CoNLL)		Author:DeNeefe, Steve; Knight, Kevin; Wang, Wei; Marcu, Daniel
Approaches include word substitution systems (Brown et al. , 1993), phrase substitution systems (Koehn et al. , 2003; Och and Ney, 2004), and synchronous context-free grammar systems (Wu and Wong, 1998; Chiang, 2005), all of which train on string pairs and seek to establish connections between source and target strings. (self citation)

Title:N07-1062		Conference:Human Language Technologies 2007: The Conference of the North American Chapter of the Association for Computational Linguistics; Proceedings of the Main Conference		Author:Zens, Richard; Ney, Hermann
We have investigated this and our results are in line with (Koehn et al. , 2003) showing that the translation quality does not improve if we utilize phrases beyond a certain length.

Title:N07-1062		Conference:Human Language Technologies 2007: The Conference of the North American Chapter of the Association for Computational Linguistics; Proceedings of the Main Conference		Author:Zens, Richard; Ney, Hermann
Even a length limit of 3, as proposed by (Koehn et al. , 2003), would result in almost optimal translation quality.

Title:W07-0406		Conference:SSST, NAACL-HLT 2007 / AMTA Workshop on Syntax and Structure in Statistical Translation		Author:Hopkins, Mark; Kuhn, Jonas
However, attempts to retrofit syntactic information into the phrase-based paradigm have not met with enormous success (Koehn et al. , 2003; Och et al. , 2003)1, and purely phrase-based machine translation systems continue to outperform these syntax/phrase-based hybrids.

Title:I08-1033		Conference:Proceedings of the Third International Joint Conference on Natural Language Processing		Author:Bai, Ming-Hong; Chen, Keh-Jiann; Chang, Jason S.
However for remedy, many of the current word alignment methods combine the results of both alignment directions, via intersection or 249 grow-diag-final heuristic, to improve the alignment reliability (Koehn et al., 2003; Liang et al., 2006; Ayan et al., 2006; DeNero et al., 2007).

Title:I08-1033		Conference:Proceedings of the Third International Joint Conference on Natural Language Processing		Author:Bai, Ming-Hong; Chen, Keh-Jiann; Chang, Jason S.
The phrasebased machine translation (Koehn et al., 2003) uses the grow-diag-final heuristic to extend the word alignment to phrase alignment by using the intersection result.

Title:P08-1089		Conference:Annual Meeting Of The Association For Computational Linguistics		Author:Zhao, Shiqi; Wang, Haifeng; Liu, Ting; Li, Sheng
LW was originally used to validate the quality of a phrase translation pair in MT (Koehn et al., 2003).

Title:D08-1021		Conference:Conference On Empirical Methods In Natural Language Processing		Author:Callison-Burch, Chris
They give a probabilistic formation of paraphrasing which naturally falls out of the fact that they use techniques from phrase-based statistical machine translation: e2 = argmax e2:e2negationslash=e1 p(e2|e1) (1) where p(e2|e1) = summationdisplay f p(f|e1)p(e2|f,e1) (2) summationdisplay f p(f|e1)p(e2|f) (3) Phrase translation probabilities p(f|e1) and p(e2|f) are commonly calculated using maximum likelihood estimation (Koehn et al., 2003): p(f|e) = count(e,f)summationtext f count(e,f) (4) where the counts are collected by enumerating all bilingual phrase pairs that are consistent with the 197 conseguido .opportunitiesequalcreatetofailedhasprojecteuropeanthe oportunidadesdeigualdadlahanoeuropeoproyectoel Figure 1: The interaction of the phrase extraction heuristic with unaligned English words means that the Spanish phrase la igualdad aligns with equal, create equal, and to create equal.

Title:W08-0409		Conference:Proceedings of the ACL-08: HLT Second Workshop on Syntax and Structure in Statistical Translation (SSST-2)		Author:Ma, Yanjun; Ozdowska, Sylwia; Sun, Yanli; Way, Andy
73 ment and phrase-extraction heuristics described in (Koehn et al., 2003), minimum-error-rate training (Och, 2003), a trigram language model with KneserNey smoothing trained with SRILM (Stolcke, 2002) on the English side of the training data, and Moses (Koehn et al., 2007) to decode.

Title:W08-2119		Conference:CoNLL 2008: Proceedings of the Twelfth Conference on Computational Natural Language Learning		Author:Nguyen, Thai Phuong; Shimazu, Akira; Ho, Tu Bao; Nguyen, Minh Le; Nguyen, Vinh Van
This system uses all featuresof conventionalphrase-basedSMT as in (Koehn et al., 2003).

Title:W08-2119		Conference:CoNLL 2008: Proceedings of the Twelfth Conference on Computational Natural Language Learning		Author:Nguyen, Thai Phuong; Shimazu, Akira; Ho, Tu Bao; Nguyen, Minh Le; Nguyen, Vinh Van
Our method does not suppose a uniform distribution over all possible phrase segmentationsas (Koehn et al., 2003) since each phrase tree has a probability.

Title:W08-0309		Conference:Proceedings of the Third Workshop on Statistical Machine Translation		Author:Callison-Burch, Chris; Fordyce, Cameron; Koehn, Philipp; Monz, Christof; Schroeder, Josh
The phrases in the translations were located using standard phrase extraction techniques (Koehn et al., 2003). (self citation)

Title:W08-0333		Conference:Proceedings of the Third Workshop on Statistical Machine Translation		Author:Dyer, Chris; Cordova, Aaron; Mont, Alex; Lin, Jimmy
In this paper we present MapReduce implementations of training algorithms for two kinds of models commonly used in statistical MT today: a phrasebased translation model (Koehn et al., 2003) and word alignment models based on pairwise lexical translation trained using expectation maximization (Dempster et al., 1977).

Title:W08-0333		Conference:Proceedings of the Third Workshop on Statistical Machine Translation		Author:Dyer, Chris; Cordova, Aaron; Mont, Alex; Lin, Jimmy
4 Phrase-Based Translation In phrase-based translation, the translation process is modeled by splitting the source sentence into phrases (a contiguous string of words) and translating the phrases as a unit (Och et al., 1999; Koehn et al., 2003).

Title:P08-1049		Conference:Annual Meeting Of The Association For Computational Linguistics		Author:Li, Zhifei; Yarowsky, David
However, since most of statistical translation models (Koehn et al., 2003; Chiang, 2007; Galley et al., 2006) are symmetrical, it is relatively easy to train a translation system to translate from English to Chinese, except that weneed to train aChinese language model from the Chinese monolingual data.

Title:P08-1049		Conference:Annual Meeting Of The Association For Computational Linguistics		Author:Li, Zhifei; Yarowsky, David
While the research in statistical machine translation (SMT) has made significant progress, most SMT systems (Koehn et al., 2003; Chiang, 2007; Galleyetal., 2006) relyonparallel corpora toextract translation entries.

Title:P08-1064		Conference:Annual Meeting Of The Association For Computational Linguistics		Author:Zhang, Min; Jiang, Hongfei; Aw, Aiti; Li, Haizhou; Tan, Chew Lim; Li, Sheng
However, most of them fail to utilize non-syntactic phrases well that are proven useful in the phrase-based methods (Koehn et al., 2003).

Title:P08-1064		Conference:Annual Meeting Of The Association For Computational Linguistics		Author:Zhang, Min; Jiang, Hongfei; Aw, Aiti; Li, Haizhou; Tan, Chew Lim; Li, Sheng
1 Introduction Phrase-based modeling method (Koehn et al., 2003; Och and Ney, 2004a) is a simple, but powerful mechanism to machine translation since it can model local reorderings and translations of multiword expressions well.

Title:W08-0310		Conference:Proceedings of the Third Workshop on Statistical Machine Translation		Author:D&eacute;chelotte, Daniel; Adda, Gilles; Allauzen, Alexandre; Bonneau-Maynard, H&eacute;l&egrave;ne; Galibert, Olivier; Gauvain, Jean-Luc; Langlais, Philippe; Yvon, Fran&ccedil;ois
translation systems (Och and Ney, 2004; Koehn et al., 2003) and use Moses (Koehn et al., 2007) to search for the best target sentence.

Title:I08-1064		Conference:Proceedings of the Third International Joint Conference on Natural Language Processing		Author:Spreyer, Kathrin; Frank, Anette
Although bi-alignments are known to exhibit high precision (Koehn et al., 2003), in the face of sparse annotations we use unidirectional alignments as a fallback, as has been proposed in the context of phrase-based machine translation (Koehn et al., 2003; Tillmann, 2003).

Title:W08-1501		Conference:Coling 2008: Proceedings of the Workshop on Cognitive Aspects of the Lexicon (COGALEX 2008)		Author:Ettelaie, Emil; Georgiou, Panayiotis G.; Narayanan, Shrikanth S.
To generate the n-best lists, a phrase based SMT (Koehn et al., 2003) was used.

Title:D08-1089		Conference:Conference On Empirical Methods In Natural Language Processing		Author:Galley, Michel; Manning, Christopher D.
1 Introduction Statistical phrase-based systems (Och and Ney, 2004; Koehn et al., 2003) have consistently delivered state-of-the-art performance in recent machine translation evaluations, yet these systems remain weak at handling word order changes.

Title:W08-0406		Conference:Proceedings of the ACL-08: HLT Second Workshop on Syntax and Structure in Statistical Translation (SSST-2)		Author:Elming, Jakob
1 Introduction The emergence of phrase-based statistical machine translation (PSMT) (Koehn et al., 2003) has been one of the major developments in statistical approaches to translation.

Title:W08-0316		Conference:Proceedings of the Third Workshop on Statistical Machine Translation		Author:Blackwood, Graeme; Gispert, Adri&agrave;; de; Brunning, Jamie; Byrne, William
After unioning the Viterbi alignments, the stems were replaced with their original words, and phrase-pairs of up to five foreign words in length were extracted in the usual fashion (Koehn et al., 2003).

Title:W08-0318		Conference:Proceedings of the Third Workshop on Statistical Machine Translation		Author:Koehn, Philipp; Arun, Abhishek; Hoang, Hieu
Foralllanguagepairs,weusedtheMosesdecoder (Koehnetal.,2007), whichfollowsthephrase-based statistical machine translation approach (Koehn et al., 2003), with default settings as a starting point. (self citation)

Title:P08-1115		Conference:Proceedings of the 9th SIGdial Workshop on Discourse and Dialogue		Author:Dyer, Chris; Muresan, Smaranda; Resnik, Philip
Models that support non-monotonic decoding generally include a distortion cost, such as|aibi11|where ai is the starting position of the foreign phrasefi andbi1 is the ending position of phrase fi1 (Koehn et al., 2003).

Title:C08-1138		Conference:International Conference On Computational Linguistics		Author:Zhang, Min; Jiang, Hongfei; Li, Haizhou; Aw, Aiti; Li, Sheng
Based on these grammars, a great number of SMT models have been recently proposed, including string-to-string model (Synchronous FSG) (Brown et al., 1993; Koehn et al., 2003), tree-to-string model (TSG-string) (Huang et al., 2006; Liu et al., 2006; Liu et al., 2007), string-totree model (string-CFG/TSG) (Yamada and Knight, 2001; Galley et al., 2006; Marcu et al., 2006), tree-to-tree model (Synchronous CFG/TSG, Data-Oriented Translation) (Chiang, 2005; Cowan et al., 2006; Eisner, 2003; Ding and Palmer, 2005; Zhang et al., 2007; Bod, 2007; Quirk wt al., 2005; Poutsma, 2000; Hearne and Way, 2003) and so on.

Title:W08-0336		Conference:Proceedings of the Third Workshop on Statistical Machine Translation		Author:Chang, Pi-Chuan; Galley, Michel; Manning, Christopher D.
2.2 Phrase-based Chinese-to-English MT The MT system used in this paper is Moses, a stateof-the-art phrase-based system (Koehn et al., 2003).

Title:D08-1059		Conference:Conference On Empirical Methods In Natural Language Processing		Author:Zhang, Yue; Clark, Stephen
Beam-search has been successful in many NLP tasks (Koehn et al., 2003; 562 Inputs: training examples (xi,yi) Initialization: set vectorw = 0 Algorithm: // R training iterations; N examples for t = 1R, i = 1N: zi = argmaxyGEN(xi) (y) vectorw if zi negationslash= yi: vectorw = vectorw + (yi)(zi) Outputs: vectorw Figure 1: The perceptron learning algorithm Collins and Roark, 2004), and can achieve accuracy that is close to exact inference.

Title:P08-1114		Conference:Proceedings of the 9th SIGdial Workshop on Discourse and Dialogue		Author:Marton, Yuval; Resnik, Philip
Rules have the form X e, f, where e and f are phrases containing terminal symbols (words) and possibly co-indexed instances of the nonterminal symbol X.2 Associated with each rule is a set of translation model features, i( f, e); for example, one intuitively natural feature of a rule is the phrase translation (log-)probability ( f, e) = log p(e| f) , directly analogous to the corresponding feature in non-hierarchical phrase-based models like Pharaoh (Koehn et al., 2003).

Title:P08-1114		Conference:Proceedings of the 9th SIGdial Workshop on Discourse and Dialogue		Author:Marton, Yuval; Resnik, Philip
In addition to this phrase translation probability feature, Hieros feature set includes the inverse phrase translation probability log p( f|e), lexical weights lexwt( f|e) and lexwt(e| f), which are estimates of translation quality based on word-level correspondences (Koehn et al., 2003), and a rule penalty allowing the model to learn a preference for longer or shorter derivations; see (Chiang, 2007) for details.

Title:P08-1011		Conference:Annual Meeting Of The Association For Computational Linguistics		Author:Zhang, Dongdong; Li, Mu; Duan, Nan; Li, Chi-Ho; Zhou, Ming
We ran GIZA++ (Och and Ney, 2000) on the training corpus in both directions with IBM model 4, and then applied the refinement rule described in (Koehn et al., 2003) to obtain a many-to-many word alignment for each sentence pair.

Title:P08-1011		Conference:Annual Meeting Of The Association For Computational Linguistics		Author:Zhang, Dongdong; Li, Mu; Duan, Nan; Li, Chi-Ho; Zhou, Ming
In most statistical machine translation (SMT) models (Och et al., 2004; Koehn et al., 2003; Chiang, 2005), some of measure words can be generated without modification or additional processing.

Title:W08-0306		Conference:Proceedings of the Third Workshop on Statistical Machine Translation		Author:Fossum, Victoria Li; Knight, Kevin; Abney, Steven
GIZA++ refined alignments have been used in state-of-the-art phrase-based statistical MT systems such as (Och, 2004); variations on the refined heuristic have been used by (Koehn et al., 2003) (diag and diag-and) and by the phrase-based system Moses (grow-diag-final) (Koehn et al., 2007).

Title:W08-0405		Conference:Proceedings of the ACL-08: HLT Second Workshop on Syntax and Structure in Statistical Translation (SSST-2)		Author:Tillmann, Christoph
2 Baseline DP Decoder The translation model used in this paper is a phrasebased model (Koehn et al., 2003), where the translation units are so-called blocks: a block b is a pair consisting of a source phrase s and a target phrase t which are translations of each other.

Title:W08-0301		Conference:Proceedings of the Third Workshop on Statistical Machine Translation		Author:Li, Chi-Ho; Zhang, Hailei; Zhang, Dongdong; Li, Mu; Zhou, Ming
The subsequent construction of translation table was done in exactly the same way as explained 4 in (Koehn et al., 2003).

Title:W08-0301		Conference:Proceedings of the Third Workshop on Statistical Machine Translation		Author:Li, Chi-Ho; Zhang, Hailei; Zhang, Dongdong; Li, Mu; Zhou, Ming
4 Experiments 4.1 Experiment Settings A series of experiments were run to compare the performance of the three SWD models against the baseline, which is the standard phrase-based approach to SMT as elaborated in (Koehn et al., 2003).

Title:P08-2041		Conference:Annual Meeting Of The Association For Computational Linguistics		Author:He, Zhongjun; Liu, Qun; Lin, Shouxun
1 Introduction Currently, most of the phrase-based statistical machine translation (PBSMT) models (Marcu and Wong, 2002; Koehn et al., 2003) adopt full matching strategy for phrase translation, which means that a phrase pair (tildewidef,tildewidee) can be used for translating a source phrase f, only if tildewidef = f. Due to lack of generalization ability, the full matching strategy has some limitations.

Title:I08-2088		Conference:Proceedings of the Third International Joint Conference on Natural Language Processing		Author:Yasuda, Keiji; Zhang, Ruiqiang; Yamamoto, Hirohumi; Sumita, Eiichiro
3.2.2 Features We used eight features (Och and Ney, 2003; Koehn et al., 2003) and their weights for the translations.

Title:I08-2088		Conference:Proceedings of the Third International Joint Conference on Natural Language Processing		Author:Yasuda, Keiji; Zhang, Ruiqiang; Yamamoto, Hirohumi; Sumita, Eiichiro
We used the preprocessed data to train the phrase-based translation model by using GIZA++ (Och and Ney, 2003) and the Pharaoh tool kit (Koehn et al., 2003).

Title:W08-0305		Conference:Proceedings of the Third Workshop on Statistical Machine Translation		Author:Turchi, Marco; De Bie, Tijl; Cristianini, Nello
The de-facto answer came during the 1990s from the research community on Statistical Machine Translation, who made use of statistical tools based on a noisy channel model originally developed for speech recognition (Brown et al., 1994; Och and Weber, 1998; R.Zens et al., 2002; Och and Ney, 2001; Koehn et al., 2003).

Title:C08-1064		Conference:International Conference On Computational Linguistics		Author:Lopez, Adam
Sum of logarithms of source-to-target lexical weighting (Koehn et al., 2003).

Title:C08-1064		Conference:International Conference On Computational Linguistics		Author:Lopez, Adam
Our baseline uses Giza++ alignments (Och and Ney, 2003) symmetrized with the grow-diag-final-and heuristic (Koehn et al., 2003).

Title:C08-1064		Conference:International Conference On Computational Linguistics		Author:Lopez, Adam
It compares favorably 505 with conventional phrase-based translation (Koehn et al., 2003) on Chinese-English news translation (Chiang, 2007).

Title:C08-1064		Conference:International Conference On Computational Linguistics		Author:Lopez, Adam
Our results are similar to those for conventional phrase-based models (Koehn et al., 2003; Zens and Ney, 2007).

Title:C08-1064		Conference:International Conference On Computational Linguistics		Author:Lopez, Adam
4.3 Relaxing Length Restrictions Increasing the maximum phrase length in standard phrase-based translation does not improve BLEU (Koehn et al., 2003; Zens and Ney, 2007).

Title:C08-1064		Conference:International Conference On Computational Linguistics		Author:Lopez, Adam
Except where noted, each system was trained on 27 million words of newswire data, aligned with GIZA++ (Och and Ney, 2003) and symmetrized with the grow-diag-final-and heuristic (Koehn et al., 2003).

Title:C08-2005		Conference:COLING - Posters		Author:Blackwood, Graeme; Gispert, Adri&agrave;; de; Byrne, William
1 Introduction In phrase-based statistical machine translation (Koehn et al., 2003) phrases extracted from word-aligned parallel data are the fundamental unit of translation.

Title:C08-1127		Conference:International Conference On Computational Linguistics		Author:Xiong, Deyi; Zhang, Min; Aw, Aiti; Li, Haizhou
With these linguistic annotations, we expect the LABTG to address two traditional issues of standard phrase-based SMT (Koehn et al., 2003) in a more effective manner.

Title:C08-1127		Conference:International Conference On Computational Linguistics		Author:Xiong, Deyi; Zhang, Min; Aw, Aiti; Li, Haizhou
Firstly, we run GIZA++ (Och and Ney, 2000) on the training corpus in both directions and then apply the ogrow-diag-finalprefinement rule (Koehn et al., 2003) to obtain many-to-many word alignments.

Title:I08-1067		Conference:Proceedings of the Third International Joint Conference on Natural Language Processing		Author:Ramanathan, Ananthakrishnan; Hegde, Jayprasad; Shah, Ritesh M.; Bhattacharyya, Pushpak; M, Sasikumar
Phrases extracted using these heuristics are also shown to perform better than syntactically motivated phrases, the joint model, and IBM model 4 (Koehn et al., 2003).

Title:I08-1067		Conference:Proceedings of the Third International Joint Conference on Natural Language Processing		Author:Ramanathan, Ananthakrishnan; Hegde, Jayprasad; Shah, Ritesh M.; Bhattacharyya, Pushpak; M, Sasikumar
The phrase translation table is learnt in the following manner: The parallel corpus is word-aligned bidirectionally, and using various heuristics (see (Koehn et al., 2003) for details) phrase correspondences are established.

Title:D08-1010		Conference:Conference On Empirical Methods In Natural Language Processing		Author:Liu, Qun; He, Zhongjun; Liu, Yang; Lin, Shouxun
Thenthewordalignment is refined by performing grow-diag-final method (Koehn et al., 2003).

Title:W08-0302		Conference:Proceedings of the Third Workshop on Statistical Machine Translation		Author:Gimpel, Kevin; Smith, Noah A.
Phrase-based MT systems are straightforward to train from parallel corpora (Koehn et al., 2003) and, like the original IBM models (Brown et al., 1990), benefit from standard language models built on large monolingual, target-language corpora (Brants et al., 2007).

Title:W08-0302		Conference:Proceedings of the Third Workshop on Statistical Machine Translation		Author:Gimpel, Kevin; Smith, Noah A.
(2003), in which we translate a source-language sentence f into the target-language sentence e that maximizes a linear combination of features and weights:1 e,a = argmax e,a score(e,a,f) (1) = argmax e,a Msummationdisplay m=1 mhm(e,a,f) (2) where a represents the segmentation of e and f into phrases and a correspondence between phrases, and each hm is a R-valued feature with learned weight m. The translation is typically found using beam search (Koehn et al., 2003).

Title:P08-1024		Conference:Annual Meeting Of The Association For Computational Linguistics		Author:Blunsom, Philip; Cohn, Trevor; Osborne, Miles
(Koehn et al., 2003).

Title:P08-1024		Conference:Annual Meeting Of The Association For Computational Linguistics		Author:Blunsom, Philip; Cohn, Trevor; Osborne, Miles
The standard solution is to approximate the maximum probability translation using a single derivation (Koehn et al., 2003).

Title:C08-1027		Conference:International Conference On Computational Linguistics		Author:Elming, Jakob
1 Introduction The emergence of phrase-based statistical machine translation (PSMT) (Koehn et al., 2003) has been one of the major developments in statistical approaches to translation.

Title:W08-0403		Conference:Proceedings of the ACL-08: HLT Second Workshop on Syntax and Structure in Statistical Translation (SSST-2)		Author:Zhou, Bowen; Xiang, Bing; Zhu, Xiaodan; Gao, Yuqing
Our baseline model follows Chiangs hierarchical model (Chiang, 2007) in conjunction with additional features: conditional probabilities in both directions: P(|) and P(|); lexical weights (Koehn et al., 2003) in both directions: Pw(|) and Pw(|); 21 word counts |e|; rule counts |D|; target n-gram language model PLM(e); glue rule penalty to learn preference of nonterminal rewriting over serial combination through Eq.

Title:P08-1009		Conference:Annual Meeting Of The Association For Computational Linguistics		Author:Cherry, Colin
Phrase-based decoding (Koehn et al., 2003) is a dominant formalism in statistical machine translation.

Title:P08-1009		Conference:Annual Meeting Of The Association For Computational Linguistics		Author:Cherry, Colin
Restricting phrases to syntactic constituents has been shown to harm performance (Koehn et al., 2003), so we tighten our definition of a violation to disregard cases where the only point of overlap is obscured by our phrasal resolution.

Title:P08-1009		Conference:Annual Meeting Of The Association For Computational Linguistics		Author:Cherry, Colin
Early experiments with syntactically-informed phrases (Koehn et al., 2003), and syntactic reranking of K-best lists (Och et al., 2004) produced mostly negative results.

Title:C08-1041		Conference:International Conference On Computational Linguistics		Author:He, Zhongjun; Liu, Qun; Lin, Shouxun
Then the word alignment is refined by performing growdiag-final method (Koehn et al., 2003).

Title:P08-1116		Conference:Proceedings of the 9th SIGdial Workshop on Discourse and Dialogue		Author:Zhao, Shiqi; Niu, Cheng; Zhou, Ming; Liu, Ting; Li, Sheng
Given phrase p1 and its paraphrase p2, we compute Score3(p1,p2) by relative frequency (Koehn et al., 2003): Score3(p1,p2) = p(p2|p1) = count(p2,p1)P pprime count(pprime,p1) (7) People may wonder why we do not use the same method on the monolingual parallel and comparable corpora.

Title:W08-0303		Conference:Proceedings of the Third Workshop on Statistical Machine Translation		Author:Niehues, Jan; Vogel, Stephan
For the first two tasks, all heuristics of the Pharaoh-Toolkit (Koehn et al., 2003) as well as the refined heuristic (Och and Ney, 2003) to combine both IBM4-alignments were tested and the best ones are shown in the tables.

Title:D08-1078		Conference:Conference On Empirical Methods In Natural Language Processing		Author:Birch, Alexandra; Osborne, Miles; Koehn, Philipp
The automatic alignments were extracted by appending the manually aligned sentences on to the respective Europarl v3 corpora and aligning them using GIZA++ (Och and Ney, 2003) and the growfinal-diag algorithm (Koehn et al., 2003). (self citation)

Title:D08-1066		Conference:Conference On Empirical Methods In Natural Language Processing		Author:Mylonakis, Markos; Sima'an, Khalil
These heuristics define a phrase pair to consist of a source and target ngrams of a word-aligned source-target sentence pair such that if one end of an alignment is in the one ngram, the other end is in the other ngram (and there is at least one such alignment) (Och and Ney, 2004; Koehn et al., 2003).

Title:D08-1066		Conference:Conference On Empirical Methods In Natural Language Processing		Author:Mylonakis, Markos; Sima'an, Khalil
From this aligned training corpus, we extract the phrase pairs according to the heuristics in (Koehn et al., 2003).

Title:D08-1066		Conference:Conference On Empirical Methods In Natural Language Processing		Author:Mylonakis, Markos; Sima'an, Khalil
The pervading method for estimating these probabilities is a simple heuristic based on the relative frequency of the phrase pair in the multi-set of the phrase pairs extracted from the word-aligned corpus (Koehn et al., 2003).

Title:D08-1066		Conference:Conference On Empirical Methods In Natural Language Processing		Author:Mylonakis, Markos; Sima'an, Khalil
1 Motivation A major component in phrase-based statistical Machine translation (PBSMT) (Zens et al., 2002; Koehn et al., 2003) is the table of conditional probabilities of phrase translation pairs.

Title:D08-1066		Conference:Conference On Empirical Methods In Natural Language Processing		Author:Mylonakis, Markos; Sima'an, Khalil
(Koehn et al., 2003; Och and Ney, 2004)).

Title:W08-0335		Conference:Proceedings of the Third Workshop on Statistical Machine Translation		Author:Zhang, Ruiqiang; Yasuda, Keiji; Sumita, Eiichiro
The training and decoding system of our SMT used the publicly available Pharaoh (Koehn et al., 2003)2.

Title:C08-2032		Conference:COLING - Posters		Author:Tsunakawa, Takashi; Okazaki, Naoaki; Tsujii, Jun'ichi
This paper proposes a method for building a bilingual lexicon through a pivot language by using phrase-based statistical machine translation (SMT) (Koehn et al., 2003).

Title:W08-0314		Conference:Proceedings of the Third Workshop on Statistical Machine Translation		Author:Axelrod, Amittai; Yang, Mei; Duh, Kevin; Kirchhoff, Katrin
3 System Overview 3.1 Translation model The system developed for this years shared task is a state-of-the-art, two-pass phrase-based statistical machine translation system based on a log-linear translation model (Koehn et al, 2003).

Title:D08-1051		Conference:Conference On Empirical Methods In Natural Language Processing		Author:Sanchis, Germ&aacute;n; Ortiz-Mart&iacute;nez, Daniel; Civera, Jorge; Casacuberta, Francisco; Vidal, Enrique; Hoang, Hieu
486 One of the most popular instantiations of loglinear models is that including phrase-based (PB) models (Zens et al., 2002; Koehn et al., 2003).

Title:I08-8001		Conference:Proceedings of the Workshop on Technologies and Corpora for Asia-Pacific Speech Translation (TCAST)		Author:Lee, Jonghoon; Lee, Donghyeon; Lee, Gary Geunbae
However, reordering models in traditional phrase-based systems are not sufficient to treat such complex cases when we translate long sentences (Koehn et al, 2003).

Title:C08-1005		Conference:International Conference On Computational Linguistics		Author:Ayan, Necip Fazil; Zheng, Jing; Wang, Wen
grow-diagfinal (Koehn et al., 2003)).

Title:W08-0322		Conference:Proceedings of the Third Workshop on Statistical Machine Translation		Author:Wang, Zhuoran; Shawe-Taylor, John
Our system is actually designed as a hybrid of the classic phrase-based SMT model (Koehn et al., 2003) and the kernel regression model as follows: First, for each source sentence a small relevant set of sentence pairs are retrieved from the large-scale parallel corpus.

Title:C08-1017		Conference:International Conference On Computational Linguistics		Author:Chew, Peter A.; Bader, Brett W.; Abdelali, Ahmed
However, Moores Law, the driving force of change in computing since then, has opened the way for recent progress in the field, such as Statistical Machine Translation (SMT) (Koehn et al. 2003).

Title:C08-1144		Conference:International Conference On Computational Linguistics		Author:Zollmann, Andreas; Venugopal, Ashish; Och, Franz Josef; Ponte, Jay
Phrase pairs are extracted up to a fixed maximum length, since very long phrases rarely have a tangible impact during translation (Koehn et al., 2003). (self citation)

Title:C08-1144		Conference:International Conference On Computational Linguistics		Author:Zollmann, Andreas; Venugopal, Ashish; Och, Franz Josef; Ponte, Jay
Starting with bilingualphrasepairsextractedfromautomatically aligned parallel text (Och and Ney, 2004; Koehn et al., 2003), these PSCFG approaches augment each contiguous (in source and target words) phrase pair with a left-hand-side symbol (like the VP in the example above), and perform a generalization procedure to form rules that include nonterminal symbols. (self citation)

Title:W08-1911		Conference:Coling 2008: Proceedings of the workshop on Knowledge and Reasoning for Answering Questions		Author:Max, Aur&eacute;lien; Zock, Michael
(Och and Ney, 2003)), and the phrase-based approach to Statistical Machine Translation (Koehn et al., 2003) has led to the development of heuristics for obtaining alignments between phrases of any number of words.

Title:W08-1911		Conference:Coling 2008: Proceedings of the workshop on Knowledge and Reasoning for Answering Questions		Author:Max, Aur&eacute;lien; Zock, Michael
4 Experiments and evaluation We carried out an evaluation on the local rephrasing of French sentences, using English as the pivot language.2 We extracted phrase alignments of up to 7 word forms using the Giza++ alignment tool (Och and Ney, 2003) and the grow-diag-final-and heuristics described in (Koehn et al., 2003) on 948,507 sentences of the French-English part of the Europarl corpus (Koehn, 2005) and obtained some 42 million phrase pairs for which probabilities were estimated using maximum likelihood estimation.

Title:W08-0404		Conference:Proceedings of the ACL-08: HLT Second Workshop on Syntax and Structure in Statistical Translation (SSST-2)		Author:Subotin, Michael
Consider the lexical model pw(ry|rx), defined following Koehn et al (2003), with a denoting the most frequent word alignment observed for the rule in the training set.

Title:W08-0404		Conference:Proceedings of the ACL-08: HLT Second Workshop on Syntax and Structure in Statistical Translation (SSST-2)		Author:Subotin, Michael
by diag-and symmetrization (Koehn et al., 2003).

Title:W08-0313		Conference:Proceedings of the Third Workshop on Statistical Machine Translation		Author:Schwenk, Holger; Fouet, Jean-Baptiste; Senellart, Jean
2 Architecture of the system The goal of statistical machine translation (SMT) is to produce a target sentence e from a source sentence f. It is today common practice to use phrases as translation units (Koehn et al., 2003; Och and Ney, 2003) and a log linear framework in order to introduce several models explaining the translation process: e = argmaxp(e|f) = argmaxe {exp(summationdisplay i ihi(e,f))} (1) The feature functions hi are the system models and the i weights are typically optimized to maximize a scoring function on a development set (Och and Ney, 2002).

Title:P08-1010		Conference:Annual Meeting Of The Association For Computational Linguistics		Author:Deng, Yonggang; Xu, Jia; Gao, Yuqing
4.1 Training and Translation Setup Our decoder is a phrase-based multi-stack implementation of the log-linear model similar to Pharaoh (Koehn et al., 2003).

Title:P08-1010		Conference:Annual Meeting Of The Association For Computational Linguistics		Author:Deng, Yonggang; Xu, Jia; Gao, Yuqing
Since most phrases appear only a few times in training data, a phrase pair translation is also evaluated by lexical weights (Koehn et al., 2003) or term weighting (Zhao et al., 2004) as additional features to avoid overestimation.

Title:P08-1010		Conference:Annual Meeting Of The Association For Computational Linguistics		Author:Deng, Yonggang; Xu, Jia; Gao, Yuqing
The most widely used approach derives phrase pairs from word alignment matrix (Och and Ney, 2003; Koehn et al., 2003).

Title:P08-1010		Conference:Annual Meeting Of The Association For Computational Linguistics		Author:Deng, Yonggang; Xu, Jia; Gao, Yuqing
The commonly used phrase extraction approach based on word alignment heuristics (referred as ViterbiExtract algorithm for comparison in this paper) as described in (Och, 2002; Koehn et al., 2003) is a special case of the algorithm, where candidate phrase pairs are restricted to those that respect word alignment boundaries.

Title:D08-1024		Conference:Conference On Empirical Methods In Natural Language Processing		Author:Chiang, David; Marton, Yuval; Resnik, Philip
5.1 Experimental setup The baseline model was Hiero with the following baseline features (Chiang, 2005; Chiang, 2007): two language models phrase translation probabilities p(f | e) and p(e| f) lexical weighting in both directions (Koehn et al., 2003) word penalty penalties for: automatically extracted rules identity rules (translating a word into itself) two classes of number/name translation rules glue rules The probability features are base-100 logprobabilities.

Title:W08-0411		Conference:Proceedings of the ACL-08: HLT Second Workshop on Syntax and Structure in Statistical Translation (SSST-2)		Author:Lavie, Alon; Parlikar, Alok; Ambati, Vamshi
1 Introduction Phrase-based Statistical MT (PB-SMT) (Koehn et al., 2003) has become the predominant approach to Machine Translation in recent years.

Title:W09-2307		Conference:Proceedings of the Third Workshop on Syntax and Structure in Statistical Translation (SSST-3) at NAACL HLT 2009		Author:Chang, Pi-Chuan; Tseng, Huihsin; Jurafsky, Daniel; Manning, Christopher D.
2 Discriminative Reordering Model Basic reordering models in phrase-based systems use linear distance as the cost for phrase movements (Koehn et al., 2003).

Title:W09-2307		Conference:Proceedings of the Third Workshop on Syntax and Structure in Statistical Translation (SSST-3) at NAACL HLT 2009		Author:Chang, Pi-Chuan; Tseng, Huihsin; Jurafsky, Daniel; Manning, Christopher D.
Our MT experiments use a re-implementation of Moses (Koehn et al., 2003) called Phrasal, which provides an easier API for adding features.

Title:W09-0436		Conference:Proceedings of the Fourth Workshop on Statistical Machine Translation		Author:Chang, Pi-Chuan; Jurafsky, Daniel; Manning, Christopher D.
4 Machine Translation Experiments 4.1 Experimental Setting For our MT experiments, we used a reimplementation of Moses (Koehn et al., 2003), a state-of-the-art phrase-based system.

Title:W09-1117		Conference:CoNLL		Author:Garera, Nikesh; Callison-Burch, Chris; Yarowsky, David
1 Introduction Recent trends in machine translation illustrate that highly accurate word and phrase translations can be learned automatically given enough parallel training data (Koehn et al., 2003; Chiang, 2007).

Title:P09-1087		Conference:ACL-IJCNLP		Author:Galley, Michel; Manning, Christopher D.
1 Introduction Hierarchical approaches to machine translation have proven increasingly successful in recent years (Chiang, 2005; Marcu et al., 2006; Shen et al., 2008), and often outperform phrase-based systems (Och and Ney, 2004; Koehn et al., 2003) on target-language fluency and adequacy.

Title:D09-1073		Conference:EMNLP		Author:Zhang, Min; Li, Haizhou
1 Introduction Phrase-based method (Koehn et al., 2003; Och and Ney, 2004; Koehn et al., 2007) and syntaxbased method (Wu, 1997; Yamada and Knight, 2001; Eisner, 2003; Chiang, 2005; Cowan et al., 2006; Marcu et al., 2006; Liu et al., 2007; Zhang et al., 2007c, 2008a, 2008b; Shen et al., 2008; Mi and Huang, 2008) represent the state-of-the-art technologies in statistical machine translation (SMT).

Title:P09-1067		Conference:ACL-IJCNLP		Author:Li, Zhifei; Eisner, Jason M.; Khudanpur, Sanjeev P.
They recover additional latent variables so-called nuisance variablesthat are not of interest to the user.1 For example, though machine translation (MT) seeks to output a string, typical MT systems (Koehn et al., 2003; Chiang, 2007) 1These nuisance variables may be annotated in training data, but it is more common for them to be latent even there, i.e., there is no supervision as to their correct values.

Title:P09-1067		Conference:ACL-IJCNLP		Author:Li, Zhifei; Eisner, Jason M.; Khudanpur, Sanjeev P.
594 2.3 Viterbi Approximation To approximate the intractable decoding problem of (2), most MT systems (Koehn et al., 2003; Chiang, 2007) use a simple Viterbi approximation, y = argmax yT(x) pViterbi(y|x) (4) = argmax yT(x) max dD(x,y) p(y,d|x) (5) = Y parenleftBigg argmax dD(x) p(y,d|x) parenrightBigg (6) Clearly, (5) replaces the sum in (2) with a max.

Title:D09-1107		Conference:EMNLP		Author:K&auml;&auml;ri&auml;inen, Matti
While theoretically sound, this approach is computationally challenging both in practice (DeNero et al., 2008) and in theory (DeNero and Klein, 2008), may suffer from reference reachability problems (DeNero et al., 2006), and in the end may lead to inferior translation quality (Koehn et al., 2003).

Title:P09-2058		Conference:ACL-IJCNLP: Short Papers		Author:Deng, Yonggang; Zhou, Bowen
This is applied to maximize coverage, which is similar as the final in (Koehn et al., 2003).

Title:P09-2058		Conference:ACL-IJCNLP: Short Papers		Author:Deng, Yonggang; Zhou, Bowen
The next two methods are heuristic (H) in (Och and Ney, 2003) and grow-diagonal (GD) proposed in (Koehn et al., 2003).

Title:P09-2058		Conference:ACL-IJCNLP: Short Papers		Author:Deng, Yonggang; Zhou, Bowen
It is a fundamental and often a necessary step before linguistic knowledge acquisitions, such as training a phrase translation table in phrasal machine translation (MT) system (Koehn et al., 2003), or extracting hierarchial phrase rules or synchronized grammars in syntax-based translation framework.

Title:P09-2058		Conference:ACL-IJCNLP: Short Papers		Author:Deng, Yonggang; Zhou, Bowen
Our decoder is a phrase-based multi-stack implementation of the log-linear model similar to Pharaoh (Koehn et al., 2003).

Title:P09-1063		Conference:ACL-IJCNLP		Author:Liu, Yang; L&uuml;, Yajuan; Liu, Qun
We obtained word alignments of the training data by first running GIZA++ (Och and Ney, 2003) and then applying the refinement rule grow-diagfinal-and (Koehn et al., 2003).

Title:D09-1115		Conference:EMNLP		Author:Feng, Yang; Liu, Yang; Mi, Haitao; Liu, Qun; L&uuml;, Yajuan
Then, we apply a grow-diag-final algorithm which is widely used in bilingual phrase extraction (Koehn et al., 2003) to monolingual alignments.

Title:N09-1029		Conference:HLT-NAACL		Author:Chen, Han-Bin; Wu, Jian-Cheng; Chang, Jason S.
Therefore, while phrase-based SMT moves from words to phrases as the basic unit of translation, implying effective local reordering within phrases, it suffers when determining phrase reordering, especially when phrases are longer than three words (Koehn et al., 2003).

Title:N09-1029		Conference:HLT-NAACL		Author:Chen, Han-Bin; Wu, Jian-Cheng; Chang, Jason S.
For example, in phrase-based SMT systems (Koehn et al., 2003; Koehn, 2004), distortion model is used, in which reordering probabilities depend on relative positions of target side phrases between adjacent blocks.

Title:W09-0430		Conference:Proceedings of the Fourth Workshop on Statistical Machine Translation		Author:Do, Thi Ngoc Diep; Le, Viet Bac; Bigi, Brigitte; Besacier, Laurent; Castelli, Eric
Then the two models and a search module are used to decode the best translation (Brown et al., 1993; Koehn et al., 2003).

Title:D09-1006		Conference:EMNLP		Author:Zaidan, Omar F.; Callison-Burch, Chris
1 Introduction Many state-of-the-art machine translation (MT) systems over the past few years (Och and Ney, 2002; Koehn et al., 2003; Chiang, 2007; Koehn et al., 2007; Li et al., 2009) rely on several models to evaluate the goodness of a given candidate translation in the target language.

Title:E09-1033		Conference:EACL		Author:Fraser, Alexander; Wang, Renjing; Sch&uuml;tze, Hinrich
These were combined using the Grow Diag Final And symmetrization heuristic (Koehn et al., 2003).

Title:P09-1038		Conference:ACL-IJCNLP		Author:Zaslavskiy, Mikhail; Dymetman, Marc; Cancedda, Nicola
5.2 Translation experiments with a bigram language model In this section we consider two real translation tasks, namely, translation from English to French, trained on Europarl (Koehn et al., 2003) and translation from German to Spanish training on the NewsCommentary corpus.

Title:P09-1038		Conference:ACL-IJCNLP		Author:Zaslavskiy, Mikhail; Dymetman, Marc; Cancedda, Nicola
1 Introduction Phrase-based systems (Koehn et al., 2003) are probably the most widespread class of Statistical Machine Translation systems, and arguably one of the most successful.

Title:E09-1003		Conference:EACL		Author:Abdul-Rauf, Sadaf; Schwenk, Holger
It is today common practice to use phrases as translation units (Koehn et al., 2003; Och and Ney, 2003) instead of the original word-based approach.

Title:N09-2055		Conference:HLT-NAACL, Companion Volume: Short Papers		Author:Lagarda, Antonio L.; Alabau, Vicent; Casacuberta, Francisco; Silva, Roberto; D&iacute;az-de-Lia&ntilde;o, Enrique
Each model can represent an important feature for the translation, such as phrase-based, language, or lexical models (Koehn et al., 2003).

Title:N09-1021		Conference:HLT-NAACL		Author:Olsson, J. Scott; Oard, Douglas W.
In particular, we adopt the approach of phrase-based statistical machine translation (Koehn et al., 2003; Koehn and Hoang, 2007).

Title:N09-1046		Conference:HLT-NAACL		Author:Dyer, Chris
The features used by the decoder were the English language model log probability, logf(e|f), the lexical translation log probabilities in both directions (Koehn et al., 2003), and a word count feature.

Title:N09-1046		Conference:HLT-NAACL		Author:Dyer, Chris
Word alignment was carried out by running Giza++ implementation of IBM Model 4 initialized with 5 iterations of Model 1, 5 of the HMM aligner, and 3 iterations of Model 4 (Och and Ney, 2003) in both directions and then symmetrizing using the grow-diag-final-and heuristic (Koehn et al., 2003).

Title:W09-0439		Conference:Proceedings of the Fourth Workshop on Statistical Machine Translation		Author:Foster, George; Kuhn, Roland
1 Introduction Most recent approaches in SMT, eg (Koehn et al., 2003; Chiang, 2005), use a log-linear model to combine probabilistic features.

Title:W09-2306		Conference:Proceedings of the Third Workshop on Syntax and Structure in Statistical Translation (SSST-3) at NAACL HLT 2009		Author:Jiang, Hongfei; Li, Sheng; Yang, Muyun; Zhao, Tiejun
1 Introduction Phrase-based statistical machine translation models (Marcu and Wong, 2002; Koehn et al., 2003; Och and Ney, 2004; Koehn, 2004; Koehn et al., 2007) have achieved significant improvements in translation accuracy over the original IBM word-based model.

Title:D09-1021		Conference:EMNLP		Author:Carreras, Xavier; Collins, Michael John
The method thereby retains the full set of lexical entries of phrase-based systems (e.g., (Koehn et al., 2003)).1 The model allows a straightforward integration of lexicalized syntactic language modelsfor example the models of (Charniak, 2001)in addition to a surface language model.

Title:D09-1021		Conference:EMNLP		Author:Carreras, Xavier; Collins, Michael John
We used Pharoah (Koehn et al., 2003) as a baseline system for comparison; the s-phrases used in our system include all phrases, with the same scores, as those used by Pharoah, allowing a direct comparison.

Title:D09-1021		Conference:EMNLP		Author:Carreras, Xavier; Collins, Michael John
The future score is based on the source-language words that are still to be translatedthis can be directly inferred from the items bit-stringthis is similar to the use of future scores in Pharoah (Koehn et al., 2003), and in fact we use Pharoahs future scores in our model.

Title:D09-1021		Conference:EMNLP		Author:Carreras, Xavier; Collins, Michael John
In our experiments we use standard methods in phrase-based systems (Koehn et al., 2003) to define the set of phrase entries for each sentence in training data.

Title:P09-4005		Conference:ACL-IJCNLP: Software Demos		Author:Koehn, Philipp
4 Options from the Translation Table Phrase-based statistical machine translation methods acquire their translation knowledge in form of large phrase translation tables automatically from large amounts of translated texts (Koehn et al., 2003). (self citation)

Title:D09-1123		Conference:EMNLP		Author:Hassan, Hany; Sima'an, Khalil; Way, Andy
The prior probability P0 is the prior distribution for the phrase probability which is estimated using the phrase normalized counts commonly used in conventional Phrasebased SMT systems, e.g., (Koehn et al., 2003).

Title:D09-1037		Conference:EMNLP		Author:Cohn, Trevor; Blunsom, Philip
In contrast, standard phrase-based models (Koehn et al., 2003) assume a mostly monotone mapping between source and target, and therefore cannot adequately model these phenomena.

Title:D09-1037		Conference:EMNLP		Author:Cohn, Trevor; Blunsom, Philip
These heuristics are extensions of those developed for phrase-based models (Koehn et al., 2003), and involve symmetrising two directional word alignments followed by a projection step which uses the alignments to find a mapping between source words and nodes in the target parse trees (Galley et al., 2004).

Title:D09-1037		Conference:EMNLP		Author:Cohn, Trevor; Blunsom, Philip
2.1 Heuristic Grammar Induction Grammar based SMT models almost exclusively follow the same two-stage approach to grammar induction developed for phrase-based methods (Koehn et al., 2003).

Title:D09-1037		Conference:EMNLP		Author:Cohn, Trevor; Blunsom, Philip
The rules are then treated as events in a relative frequency estimate.4 We used Giza++ Model 4 to obtain word alignments (Och and Ney, 2003), using the grow-diag-final-and heuristic to symmetrise the two directional predictions (Koehn et al., 2003).

Title:D09-1037		Conference:EMNLP		Author:Cohn, Trevor; Blunsom, Philip
The production weights are estimated either by heuristic counting (Koehn et al., 2003) or using the EM algorithm.

Title:D09-1136		Conference:EMNLP		Author:Liu, Ding; Gildea, Daniel
The word alignment is computed using GIZA++2 for the selected 73,597 sentence pairs in the FBIS corpus in both directions and then combined using union and heuristic diagonal growing (Koehn et al., 2003).

Title:D09-1136		Conference:EMNLP		Author:Liu, Ding; Gildea, Daniel
1313 E2C C2E Union Heuristic w/ Big 13.37 12.66 14.55 14.28 w/o Big 13.20 12.62 14.53 14.21 Table 3: BLEU-4 scores (test set) of systems based on GIZA++ word alignments 5 6 7 8 BLEU-4 14.27 14.42 14.43 14.45 14.55 Table 4: BLEU-4 scores (test set) of the union alignment, using TTS templates up to a certain size, in terms of the number of leaves in their LHSs 4.1 Baseline Systems GHKM (Galley et al., 2004) is used to generate the baseline TTS templates based on the word alignments computed using GIZA++ and different combination methods, including union and the diagonal growing heuristic (Koehn et al., 2003).

Title:P09-1088		Conference:ACL-IJCNLP		Author:Blunsom, Philip; Cohn, Trevor; Dyer, Chris; Osborne, Miles
1 Introduction The field of machine translation has seen many advances in recent years, most notably the shift from word-based (Brown et al., 1993) to phrasebased models which use token n-grams as translation units (Koehn et al., 2003).

Title:P09-1088		Conference:ACL-IJCNLP		Author:Blunsom, Philip; Cohn, Trevor; Dyer, Chris; Osborne, Miles
These wordbased models are used to find the latent wordalignments between bilingual sentence pairs, from which a weighted string transducer can be induced (either finite state (Koehn et al., 2003) or synchronous context free grammar (Chiang, 2007)).

Title:W09-1114		Conference:CoNLL		Author:Arun, Abhishek; Dyer, Chris; Haddow, Barry; Blunsom, Philip; Lopez, Adam; Koehn, Philipp
Our technique is based on a novel Gibbs sampler that draws samples from the posterior distributionofaphrase-basedtranslationmodel(Koehn et al., 2003) but operates in linear time with respect to the number of input words (Section 2). (self citation)

Title:E09-1063		Conference:EACL		Author:Ma, Yanjun; Way, Andy
5.3 Baseline System We conducted experiments using different segmenters with a standard log-linear PB-SMT model: GIZA++ implementation of IBM word alignment model 4 (Och and Ney, 2003), the refinement and phrase-extraction heuristics described in (Koehn et al., 2003), minimum-errorrate training (Och, 2003), a 5-gram language model with Kneser-Ney smoothing trained with SRILM (Stolcke, 2002) on the English side of the training data, and Moses (Koehn et al., 2007; Dyer et al., 2008) to translate both single best segmentation and word lattices.

Title:N09-3016		Conference:HLT-NAACL, Companion Volume: Student Research Workshop and Doctoral Consortium		Author:Rama, Taraka; Singh, Anil Kumar; Kolachina, Sudheer
The transcription probabilities can then be easily learnt from the alignments induced by GIZA++, using a scoring function (Koehn et al., 2003).

Title:N09-3016		Conference:HLT-NAACL, Companion Volume: Student Research Workshop and Doctoral Consortium		Author:Rama, Taraka; Singh, Anil Kumar; Kolachina, Sudheer
We used minimum error rate training (Och, 2003) and the A* beam search decoder implemented by Koehn (Koehn et al., 2003).

Title:N09-3016		Conference:HLT-NAACL, Companion Volume: Student Research Workshop and Doctoral Consortium		Author:Rama, Taraka; Singh, Anil Kumar; Kolachina, Sudheer
5.1 ExploringtheParameters Theparameterswhichhaveamajorinuenceonthe performance of a phrase-based SMT model are the alignment heuristics, the maximum phrase length (MPR) and the order of the language model (Koehn et al., 2003).

Title:D09-1040		Conference:EMNLP		Author:Marton, Yuval; Callison-Burch, Chris; Resnik, Philip
1 Introduction Phrase-based systems, flat and hierarchical alike (Koehn et al., 2003; Koehn, 2004b; Koehn et al., 2007; Chiang, 2005; Chiang, 2007), have achieved a much better translation coverage than wordbased ones (Brown et al., 1993), but untranslated words remain a major problem in SMT.

Title:P09-2037		Conference:ACL-IJCNLP: Short Papers		Author:&#x17D;abokrtsk&yacute;, Zden&#x11B;k; Popel, Martin
(Koehn et al., 2003)), in which translation and language models are trainable separately too.

Title:D09-1050		Conference:EMNLP		Author:Bai, Ming-Hong; You, Jia-Ming; Chen, Keh-Jiann; Chang, Jason S.
Computing the phrase translation probability is trivial in the training corpora, but lexical weighting (Koehn et al., 2003) needs lexical-level alignment.

Title:D09-1050		Conference:EMNLP		Author:Bai, Ming-Hong; You, Jia-Ming; Chen, Keh-Jiann; Chang, Jason S.
(Och et al., 1999; Koehn et al., 2003; Liang et al., 2006).

Title:W09-2310		Conference:Proceedings of the Third Workshop on Syntax and Structure in Statistical Translation (SSST-3) at NAACL HLT 2009		Author:Khalilov, Maxim; Fonollosa, Jos&eacute;; A. R.; Dras, Mark
The state-of-the-art SMT system Moses implements a distance-based reordering model (Koehn et al., 2003) and a distortion model, operating with rewrite patterns extracted from a phrase alignment table (Tillman, 2004).

Title:P09-1103		Conference:ACL-IJCNLP		Author:Sun, Jun; Zhang, Min; Tan, Chew Lim
Between them, the phrase-based approach (Marcu and Wong, 2002; Koehn et al, 2003; Och and Ney, 2004) allows local reordering and contiguous phrase translation.

Title:W09-0434		Conference:Proceedings of the Fourth Workshop on Statistical Machine Translation		Author:Birch, Alexandra; Blunsom, Philip; Osborne, Miles
Phrase-based models (Och and Ney, 2004; Koehn et al., 2003) have been a major paradigm in statistical machine translation in the last few years, showing state-of-the-art performance for many language pairs.

Title:W09-1104		Conference:CoNLL		Author:Spreyer, Kathrin; Kuhn, Jonas
By using only the bidirectional word alignment links, one can implement a very robust such filter, as the bidirectional links are generally reliable, even though they have low recall for overall translational correspondences (Koehn et al., 2003).

Title:D09-1111		Conference:EMNLP		Author:Cherry, Colin; Suzuki, Hisami
Substring-based transliteration with a generative hybrid model is very similar to existing solutions for phrasal SMT (Koehn et al., 2003), operating on characters rather than words.

Title:W09-1908		Conference:Proceedings of the NAACL HLT 2009 Workshop on Active Learning for Natural Language Processing		Author:Ambati, Vamshi; Carbonnell, Jaime G.
While the amount of parallel data required to build such systems is orders of magnitude smaller than corresponding phrase based statistical systems (Koehn et al., 2003), the variety of linguistic annotation required is greater.

Title:W09-1908		Conference:Proceedings of the NAACL HLT 2009 Workshop on Active Learning for Natural Language Processing		Author:Ambati, Vamshi; Carbonnell, Jaime G.
We conclude with some challenges that still remain in applying proactive learning for MT. 2 Syntax Based Machine Translation In recent years, corpus based approaches to machine translation have become predominant, with Phrase Based Statistical Machine Translation (PBSMT) (Koehn et al., 2003) being the most actively progressing area.

Title:N09-2024		Conference:HLT-NAACL, Companion Volume: Short Papers		Author:Tillmann, Christoph; Xu, Jian-ming
Typically, a phrase-based SMT system includes a feature that scores phrase pairs using lexical weights (Koehn et al., 2003) which are computed for two directions: source to target and target to source.

Title:P09-2060		Conference:ACL-IJCNLP: Short Papers		Author:Yang, Mei; Zheng, Jing
1 Introduction Phrase-based translation (Koehn et al., 2003) and hierarchical phrase-based translation (Chiang, 2005) are the state of the art in statistical machine translation (SMT) techniques.

Title:D09-1106		Conference:EMNLP		Author:Liu, Yang; Xia, Tian; Xiao, Xinyan; Liu, Qun
Besides relative frequencies, lexical weights (Koehn et al., 2003) are widely used to estimate how well the words in f translate the words in e. To do this, one needs first to estimate a lexical translation probability distribution w(e|f) by relative frequency from the same word alignments in the training corpus: w(e|f) = count(f,e)summationtext e count(f,e) (3) Note that a special source NULL token is added to each source sentence and aligned to each unaligned target word.

Title:D09-1106		Conference:EMNLP		Author:Liu, Yang; Xia, Tian; Xiao, Xinyan; Liu, Qun
The methods for calculating relative frequencies (Och and Ney, 2004) and lexical weights (Koehn et al., 2003) are also adapted for the weighted matrix case.

Title:D09-1106		Conference:EMNLP		Author:Liu, Yang; Xia, Tian; Xiao, Xinyan; Liu, Qun
Word-aligned corpora have been found to be an excellent source for translation-related knowledge, not only for phrase-based models (Och and Ney, 2004; Koehn et al., 2003), but also for syntax-based models (e.g., (Chiang, 2007; Galley et al., 2006; Shen et al., 2008; Liu et al., 2006)).

Title:D09-1106		Conference:EMNLP		Author:Liu, Yang; Xia, Tian; Xiao, Xinyan; Liu, Qun
Then, we used the refinement technique grow-diag-final-and (Koehn et al., 2003) to all 50 50 bidirectional alignment pairs.

Title:W09-0424		Conference:Proceedings of the Fourth Workshop on Statistical Machine Translation		Author:Li, Zhifei; Callison-Burch, Chris; Dyer, Chris; Khudanpur, Sanjeev P.; Schwartz, Lane; Thornton, Wren N. G.; Weese, Jonathan; Zaidan, Omar F.
In such tasks, feature calculation is also very expensive in terms of time required; huge sets of extracted rules must be sorted in two directions for relative frequency calculation of such features as the translation probability p(f|e) and reverse translation probability p(e|f) (Koehn et al., 2003).

Title:E09-1043		Conference:EACL		Author:Hoang, Hieu; Koehn, Philipp
The problem is typically presented in log-space, which simplifies computations, but otherwise does not change the problem due to the monotonicity of the log function (hm = log hprimem) log p(t|s) = summationdisplay m m hm(t,s) (3) Phrase-based models (Koehn et al., 2003) are limited to the mapping of small contiguous chunks of text. (self citation)

Title:N09-1013		Conference:HLT-NAACL		Author:Brunning, Jamie; Gispert, Adri&agrave;; de; Byrne, William
3.2.2 Alignment Error Rate Since MT systems are usually built on the union of the two sets of alignments (Koehn et al., 2003), we consider the union of alignments in the two directions as well as those in each direction.

Title:P09-2031		Conference:ACL-IJCNLP: Short Papers		Author:He, Zhongjun; Meng, Yao; L&uuml;, Yajuan; Yu, Hao; Liu, Qun
1LDC2002E18 (4,000 sentences), LDC2002T01, LDC2003E07, LDC2003E14, LDC2004T07, LDC2005T10, LDC2004T08 HK Hansards (500,000 sentences) 2http://www.statmt.org/wmt07/shared-task.html For both the tasks, the word alignment were trained by GIZA++ in two translation directions and refined by grow-diag-final method (Koehn et al., 2003).

Title:W09-0809		Conference:Proceedings of the EACL 2009 Workshop on Computational Approaches to Semitic Languages		Author:Elming, Jakob; Habash, Nizar
Separating the scoring from the source language reordering also has the advantage that the approach in essence is compatible with other approaches such as a traditional PSMT system (Koehn et al., 2003b) or a hierarchical phrase system (Chiang, 2005).

Title:W09-0809		Conference:Proceedings of the EACL 2009 Workshop on Computational Approaches to Semitic Languages		Author:Elming, Jakob; Habash, Nizar
1 Introduction The emergence of phrase-based statistical machine translation (PSMT) (Koehn et al., 2003a) has been one of the major developments in statistical approaches to translation.

Title:W09-0809		Conference:Proceedings of the EACL 2009 Workshop on Computational Approaches to Semitic Languages		Author:Elming, Jakob; Habash, Nizar
We are also interested in examining the approach within a standard phrase-based decoder such as Moses (Koehn et al., 2003b) or a hierarchical phrase system (Chiang, 2005).

Title:W09-0423		Conference:Proceedings of the Fourth Workshop on Statistical Machine Translation		Author:Schwenk, Holger; Abdul-Rauf, Sadaf; Barrault, Lo&iuml;c; Senellart, Jean
4 Architecture of the SMT system The goal of statistical machine translation (SMT) is to produce a target sentence e from a source sentence f. It is today common practice to use phrases as translation units (Koehn et al., 2003; Och and Ney, 2003) and a log linear framework in order to introduce several models explaining the translation process: e = argmaxp(e|f) = argmaxe {exp(summationdisplay i ihi(e,f))} (1) The feature functions hi are the system models and the i weights are typically optimized to maximize a scoring function on a development set (Och and Ney, 2002).

Title:W09-0437		Conference:Proceedings of the Fourth Workshop on Statistical Machine Translation		Author:Auli, Michael; Lopez, Adam; Hoang, Hieu; Koehn, Philipp
The corpus was aligned with GIZA++ (Och and Ney, 2003) and symmetrized with the grow-diag-finaland heuristic (Koehn et al., 2003). (self citation)

Title:P09-1065		Conference:ACL-IJCNLP		Author:Liu, Yang; Mi, Haitao; Feng, Yang; Liu, Qun
We obtained word alignments of training data by first running GIZA++ (Och and Ney, 2003) and then applying the refinement rule grow-diag-final-and (Koehn et al., 2003).

Title:P09-1065		Conference:ACL-IJCNLP		Author:Liu, Yang; Mi, Haitao; Feng, Yang; Liu, Qun
On the other hand, other authors (e.g., (Och and Ney, 2004; Koehn et al., 2003; Chiang, 2007)) do use the expression phrase-based models.

Title:W09-2301		Conference:Proceedings of the Third Workshop on Syntax and Structure in Statistical Translation (SSST-3) at NAACL HLT 2009		Author:Hanneman, Greg; Lavie, Alon
1 Introduction The dominance of traditional phrase-based statistical machine translation (PBSMT) models (Koehn et al., 2003) has recently been challenged by the development and improvement of a number of new models that explicity take into account the syntax of the sentences being translated.

Title:P09-1094		Conference:ACL-IJCNLP		Author:Zhao, Shiqi; Lan, Xiang; Liu, Ting; Li, Sheng
Actually, it is defined similarly to the translation model in SMT (Koehn et al., 2003).

Title:D09-1023		Conference:EMNLP		Author:Gimpel, Kevin; Smith, Noah A.
2.4 Reordering Reordering features take many forms in MT. In phrase-based systems, reordering is accomplished both within phrase pairs (local reordering) as well as through distance-based distortion models (Koehn et al., 2003) and lexicalized reordering models (Koehn et al., 2007).

Title:D09-1023		Conference:EMNLP		Author:Gimpel, Kevin; Smith, Noah A.
220 (Koehn et al., 2003); they can overlap.5 Additionally, since phrase features can be any function of words and alignments, we permit features that consider phrase pairs in which a target word outside the target phrase aligns to a source word inside the source phrase, as well as phrase pairs with gaps (Chiang, 2005; Ittycheriah and Roukos, 2007).

Title:D09-1023		Conference:EMNLP		Author:Gimpel, Kevin; Smith, Noah A.
1 Introduction We have seen rapid recent progress in machine translation through the use of rich features and the development of improved decoding algorithms, often based on grammatical formalisms.1 If we view MT as a machine learning problem, features and formalisms imply structural independence assumptions, which are in turn exploited by efficient inference algorithms, including decoders (Koehn et al., 2003; Yamada and Knight, 2001).

Title:D09-1023		Conference:EMNLP		Author:Gimpel, Kevin; Smith, Noah A.
These estimates are usually heuristic and inconsistent (Koehn et al., 2003).

Title:P09-1036		Conference:ACL-IJCNLP		Author:Xiong, Deyi; Zhang, Min; Aw, Aiti; Li, Haizhou
This, unfortunately, significantly jeopardizes performance (Koehn et al., 2003; Xiong et al., 2008) because by integrating syntactic constraint into decoding as a hard constraint, it simply prohibits any other useful non-syntactic translations which violate constituent boundaries.

Title:P09-1036		Conference:ACL-IJCNLP		Author:Xiong, Deyi; Zhang, Min; Aw, Aiti; Li, Haizhou
In such a process, original phrase-based decoding (Koehn et al., 2003) does not take advantage of any linguistic analysis, which, however, is broadly used in rule-based approaches.

Title:P10-2067		Conference:Proceedings of the ACL 2010 Conference Short Papers		Author:Ambati, Vamshi; Vogel, Stephan; Carbonnell, Jaime G.
1 Introduction Corpus-based approaches to machine translation have become predominant, with phrase-based statistical machine translation (PB-SMT) (Koehn et al., 2003) being the most actively progressing area.

Title:W10-3813		Conference:Proceedings of the 4th Workshop on Syntax and Structure in Statistical Translation		Author:Ma, Yanjun; Way, Andy
grow-diag-final heuristic described in (Koehn et al., 2003) is used to derive the refined alignment from bidirectional alignments.

Title:W10-3813		Conference:Proceedings of the 4th Workshop on Syntax and Structure in Statistical Translation		Author:Ma, Yanjun; Way, Andy
With the word alignment obtained using the method described in 105 section 4.2, we perform phrase-extraction using heuristics described in (Koehn et al., 2003), Minimum Error-Rate Training (MERT) (Och, 2003) optimising the BLEU metric, a 5-gram language model with Kneser-Ney smoothing (Kneser and Ney, 1995) trained with SRILM (Stolcke, 2002) on the English side of the training data, and MOSES (Koehn et al., 2007) for decoding.

Title:W10-3813		Conference:Proceedings of the 4th Workshop on Syntax and Structure in Statistical Translation		Author:Ma, Yanjun; Way, Andy
(Koehn et al., 2003)).

Title:W10-1762		Conference:Proceedings of the Joint Fifth Workshop on Statistical Machine Translation and MetricsMATR		Author:Sudoh, Katsuhito; Duh, Kevin; Tsukada, Hajime; Hirao, Tsutomu; Nagata, Masaaki
Distance-based reordering is a typical approach used in many previous studies related to word-based SMT (Brown et al., 1993) and phrase-based SMT (Koehn et al., 2003).

Title:P10-2005		Conference:Proceedings of the ACL 2010 Conference Short Papers		Author:Xiang, Bing; Deng, Yonggang; Zhou, Bowen
Usually people start from the intersection of two sets of alignments, and gradually add links in the union based on certain heuristics, as in (Koehn et al., 2003), to achieve a better balance compared to using either intersection (high precision) or union (high recall).

Title:P10-2005		Conference:Proceedings of the ACL 2010 Conference Short Papers		Author:Xiang, Bing; Deng, Yonggang; Zhou, Bowen
The baseline is a phrase-based MT system similar to (Koehn et al., 2003).

Title:P10-2005		Conference:Proceedings of the ACL 2010 Conference Short Papers		Author:Xiang, Bing; Deng, Yonggang; Zhou, Bowen
Finally, we compare the proposed alignment combination c2 with the heuristics-based method (gdf), where the latter starts from the intersection of all 4 sets of alignments and then applies grow-diagonalfinal (Koehn et al., 2003) based on the links in the union.

Title:C10-2124		Conference:COLING - POSTERS		Author:Sanchis, Germ&aacute;n; Casacuberta, Francisco
3 Phrase-based SMT One of the most popular instantiations of loglinear models in SMT are phrase-based (PB) models (Zens et al., 2002; Koehn et al., 2003).

Title:P10-1049		Conference:ACL		Author:Wuebker, Joern; Mauser, Arne; Ney, Hermann
1 Introduction A phrase-based SMT system takes a source sentence and produces a translation by segmenting the sentence into phrases and translating those phrases separately (Koehn et al., 2003).

Title:P10-1085		Conference:ACL		Author:Liu, Zhanyi; Wang, Haifeng; Wu, Hua; Li, Sheng
In phrase-based SMT (Koehn et al., 2003), the phrase boundary is usually determined based on the bi-directional word alignments.

Title:W10-1604		Conference:Proceedings of the NAACL HLT 2010 Young Investigators Workshop on Computational Approaches to Languages of the Americas		Author:Caseli, Helena M.; Sugiyama, Bruno Akio; Anacleto, Junia Coutinho
Nowadays, the majority of the researches has being centered around the phrase-based statistical MT (PB-SMT) approach such as (Koehn et al., 2003) and (Och and Ney, 2004).

Title:P10-1112		Conference:ACL		Author:Bansal, Mohit; Klein, Dan
For machine translation, the key modern advancement has been the ability to represent and memorize large training substructures, be it in contiguous phrases (Koehn et al., 2003) or syntactic trees 1In this paper, a fragment means an elementary tree in a tree-substitution grammar, while a subtree means a fragment that bottoms out in terminals.

Title:P10-2002		Conference:Proceedings of the ACL 2010 Conference Short Papers		Author:Cui, Lei; Zhang, Dongdong; Li, Mu; Zhou, Ming; Zhao, Tiejun
It can not only maintain the strength of phrase translation in traditional phrase-based models (Koehn et al., 2003; Xiong et al., 2006), but also characterize the complicated long distance reordering similar to syntactic based statistical machine translation (SMT) models (Yamada and Knight, 2001; Quirk et al., 2005; Galley et al., 2006; Liu et al., 2006; Marcu et al., 2006; Mi et al., 2008; Shen et al., 2008).

Title:P10-2002		Conference:Proceedings of the ACL 2010 Conference Short Papers		Author:Cui, Lei; Zhang, Dongdong; Li, Mu; Zhou, Ming; Zhao, Tiejun
In the original work (Chiang, 2005), the target-side rule selection is analogous to the model in traditional phrase-based SMT system such as Pharaoh (Koehn et al., 2003).

Title:N10-1129		Conference:Human Language Technologies: The 2010 Annual Conference of the North American Chapter of the Association for Computational Linguistics		Author:Green, Spence; Galley, Michel; Manning, Christopher D.
This search is made tractable by the use of beams (Koehn et al., 2003).

Title:W10-2915		Conference:Proceedings of the Fourteenth Conference on Computational Natural Language Learning		Author:Mylonakis, Markos; Sima'an, Khalil
(Chiang, 2007), assumes the word-alignments are given in the parallel corpus, but the problem of learning phrase translation probabilities is usually avoided by using surface counts of phrase pairs (Koehn et al., 2003).

Title:W10-2915		Conference:Proceedings of the Fourteenth Conference on Computational Natural Language Learning		Author:Mylonakis, Markos; Sima'an, Khalil
Another important contribution is in defining a lexicalised reordering component within BITG that captures order divergences orthogonal to Chiangs model (Chiang, 2007) but somewhat akin to Phrase-Based Statistical Machine Translation reordering models (Koehn et al., 2003).

Title:W10-2915		Conference:Proceedings of the Fourteenth Conference on Computational Natural Language Learning		Author:Mylonakis, Markos; Sima'an, Khalil
In contrast, the switch grammar models the reordering preferences of the phrasepairs themselves, similarly to the monotone-swapdiscontinuous reordering models of Phrase-based SMT models (Koehn et al., 2003).

Title:W10-2915		Conference:Proceedings of the Fourteenth Conference on Computational Natural Language Learning		Author:Mylonakis, Markos; Sima'an, Khalil
Given the word-alignments, the set of phrase-pairs extracted is the set of all translational equivalents (without length upperbound) under the word-alignment as defined in (Och and Ney, 2004; Koehn et al., 2003).

Title:C10-2095		Conference:COLING - POSTERS		Author:Maskey, Sameer; Rennie, Steven; Zhou, Bowen
Coling 2010: Poster Volume, pages 828836, Beijing, August 2010 A Power Mean Based Algorithm for Combining Multiple Alignment Tables Sameer Maskey, Steven J. Rennie, Bowen Zhou IBM T.J. Watson Research Center {smaskey, sjrennie, zhou}@us.ibm.com Abstract Most existing techniques for combining multiple alignment tables can combine only two alignment tables at a time, and are based on heuristics (Och and Ney, 2003), (Koehn et al., 2003).

Title:C10-2095		Conference:COLING - POSTERS		Author:Maskey, Sameer; Rennie, Steven; Zhou, Bowen
We then also re-produced the two commonly used combination heuristic methods that are based on growing the alignment diagonally (GDF) (Koehn et al., 2003), and adding links based on refined heuristics (H) (Och and Ney, 2003), respectively.

Title:C10-2095		Conference:COLING - POSTERS		Author:Maskey, Sameer; Rennie, Steven; Zhou, Bowen
The alignment pairs are then used to extract phrases tables (Koehn et al., 2003), hierarchical rules (Chiang, 2005), or tree-to-string mappings (Yamada and Knight, 2001).

Title:C10-2095		Conference:COLING - POSTERS		Author:Maskey, Sameer; Rennie, Steven; Zhou, Bowen
It is better by 1.22 absolute BLEU score on the dev set and 1.18 on a test compared to commonly used GDF (Koehn et al., 2003) heuristics.

Title:C10-2095		Conference:COLING - POSTERS		Author:Maskey, Sameer; Rennie, Steven; Zhou, Bowen
2 Related Work Most existing methods for alignment combination (symmetrization) rely on heuristics to identify reliable links (Och and Ney, 2003), (Koehn et al., 2003).

Title:C10-2095		Conference:COLING - POSTERS		Author:Maskey, Sameer; Rennie, Steven; Zhou, Bowen
We showed that the approach is more effective than intersection, union, the heuristics of (Och and Ney, 2003), and the grow diagonal final (GDF) algorithm of (Koehn et al., 2003).

Title:C10-2095		Conference:COLING - POSTERS		Author:Maskey, Sameer; Rennie, Steven; Zhou, Bowen
E2F Dev Test I 0.1064 0.0941 H 0.1028 0.0894 GDF 0.1256 0.1091 PM 0.1214 0.1094 PMn 0.1378 0.1209 U 0.1062 0.0897 Table 2: E2F BLEU: PM Alignment Combination Based MT Model Comparision We built a standard phrase-based translation system (Koehn et al., 2003) that utilizes a stackbased decoder based on an A search.

Title:C10-2095		Conference:COLING - POSTERS		Author:Maskey, Sameer; Rennie, Steven; Zhou, Bowen
Another example is the method in (Koehn et al., 2003), which adds links to the intersection of two alignment tables that are the diagonal neighbors of existing links, optionally requiring that any added links connect two previously unaligned words.

Title:C10-2095		Conference:COLING - POSTERS		Author:Maskey, Sameer; Rennie, Steven; Zhou, Bowen
F2E Dev Test I 0.1145 0.1101 H 0.1262 0.1193 GDF 0.1115 0.1204 PM 0.1201 0.1155 PMn 0.1198 0.1196 U 0.1111 0.1155 Table 3: F2E BLEU : PM Alignment Combination Based MT Model Comparision We built five different MT models based on Intersection (I), Union (U), (Koehn et al., 2003) Grow Diagonal Final (GDF), (Och and Ney, 2003) H refined heuristics and Power Mean (PMn) alignment sets where n = 5.

Title:P10-1062		Conference:ACL		Author:Xiong, Deyi; Zhang, Min; Li, Haizhou
5 SMT System To obtain machine-generated translation hypothesesforourerrordetection,weuseastate-of-the-art phrase-based machine translation system MOSES (Koehn et al., 2003; Koehn et al., 2007).

Title:N10-1040		Conference:Human Language Technologies: The 2010 Annual Conference of the North American Chapter of the Association for Computational Linguistics		Author:Liberato, Frank; Mohit, Behrang; Hwa, Rebecca
While the lexical weights can be computed using the standard method (Koehn et al., 2003), estimating the conditional phrase probabilities is not straightforward for our approach because they are not observed in bilingual training data.

Title:N10-1040		Conference:Human Language Technologies: The 2010 Annual Conference of the North American Chapter of the Association for Computational Linguistics		Author:Liberato, Frank; Mohit, Behrang; Hwa, Rebecca
We then find phrases that are consistent with (Koehn et al., 2003).

Title:D10-1090		Conference:EMNLP		Author:Liu, Chang; Dahlmeier, Daniel; Ng, Hwee Tou
In this work, we use the widely-used phrase extraction heuristic in (Koehn et al., 2003) to extract phrase pairs from parallel texts into a phrase table1.

Title:P10-1064		Conference:ACL		Author:He, Yifan; Ma, Yanjun; van Genabith, Josef; Way, Andy
As for the SMT system, we use a standard log-linear PB-SMT model (Och and Ney, 2002): GIZA++ implementation of IBM word alignment model 4,1 the refinement and phraseextraction heuristics described in (Koehn et al., 2003), minimum-error-rate training (Och, 2003), a 5-gram language model with Kneser-Ney smoothing (Kneser and Ney, 1995) trained with SRILM (Stolcke, 2002) on the English side of the training data, and Moses (Koehn et al., 2007) to decode.

Title:P10-4002		Conference:Proceedings of the ACL 2010 System Demonstrations		Author:Dyer, Chris; Lopez, Adam; Ganitkevitch, Juri; Weese, Jonathan; Ture, Ferhan; Blunsom, Philip; Setiawan, Hendra; Eidelman, Vladimir; Resnik, Philip
In a phrase-based translation hypergraph, the node will correspond to a source coverage vector (Koehn et al., 2003).

Title:P10-4002		Conference:Proceedings of the ACL 2010 System Demonstrations		Author:Dyer, Chris; Lopez, Adam; Ganitkevitch, Juri; Weese, Jonathan; Ture, Ferhan; Blunsom, Philip; Setiawan, Hendra; Eidelman, Vladimir; Resnik, Philip
Phrase-based models (Koehn et al., 2003), lexical translation models (Brown et al., 1993), and finite-state conditional random fields (Sha and Pereira, 2003) exemplify the former, and hierarchical phrase-based models the latter (Chiang, 2007).

Title:W10-2916		Conference:Proceedings of the Fourteenth Conference on Computational Natural Language Learning		Author:Ananthakrishnan, Sankaranarayanan; Prasad, Rohit; Stallard, David G.; Natarajan, Premkumar
We also train an initial phrase-based SMT system (Koehn et al., 2003) with the available seed corpus.

Title:W10-2401		Conference:Proceedings of the 2010 Named Entities Workshop		Author:Li, Haizhou; Kumaran, A.; Zhang, Min; Pervouchine, Vladimir
The most popular techniques such as Phrase-Based Machine Transliteration (Koehn et al., 2003), system combination and re-ranking, are inspired by recent progress in statistical machine translation.

Title:W10-2401		Conference:Proceedings of the 2010 Named Entities Workshop		Author:Li, Haizhou; Kumaran, A.; Zhang, Min; Pervouchine, Vladimir
(2010) and Finch and Sumita (2010) adopt the approach of phrase-based statistical machine transliteration (Finch and Sumita, 2008), an approach initially developed for machine translation (Koehn et al., 2003) while Das et al.

Title:W10-1707		Conference:Proceedings of the Joint Fifth Workshop on Statistical Machine Translation and MetricsMATR		Author:Eidelman, Vladimir; Dyer, Chris; Resnik, Philip
The lowercased and tokenized training data was then filtered for length and aligned using the GIZA++ implementation of IBM Model 4 (Och and Ney, 2003) to obtain one-to-many alignments in both directions and symmetrized by combining both into a single alignment using the grow-diagfinal-and method (Koehn et al., 2003).

Title:D10-1052		Conference:EMNLP		Author:Setiawan, Hendra; Dyer, Chris; Resnik, Philip
After n steps, the algorithm returns Amax as its approximation of A. In the experiments reported below, we initialized A(1) with the Model 4 alignments symmetrized by using the grow-diag-final-and heuristic (Koehn et al., 2003).

Title:W10-1732		Conference:Proceedings of the Joint Fifth Workshop on Statistical Machine Translation and MetricsMATR		Author:Zeman, Daniel
Thisincludestheusualcombinationof word clustering usingmkcls3 (Och, 1999), twoway word alignment using GIZA++ 4 (Och and Ney, 2003), and alignment symmetrization using the grow-diag-final-and heuristic (Koehn et al., 2003).

Title:C10-1081		Conference:COLING		Author:Liu, Ding; Gildea, Daniel
Unioning the two single-direction alignments yields better performance for the SSMT systems using TTS templates (Fossum et al., 2008) than the two single-direction alignments and the heuristic diagonal combination (Koehn et al., 2003).

Title:P10-1047		Conference:ACL		Author:Yeniterzi, Reyyan; Oflazer, Kemal
Once these were identified as separate tokens, they were then used as words in a standard phrase-based framework (Koehn et al., 2003).

Title:P10-1047		Conference:ACL		Author:Yeniterzi, Reyyan; Oflazer, Kemal
We assume that the reader is familiar with the basics of phrase-based statistical machine translation (Koehn et al., 2003) and factored statistical machine translation (Koehn and Hoang, 2007).

Title:C10-2017		Conference:COLING - POSTERS		Author:Chevelu, Jonathan; Putois, Ghislain; Lepage, Yves
2 True Score Computing 2.1 Context The phrase based SMT model (Koehn et al., 2003) can be transposed to paraphrase generation as follows: t = arg maxt P(t)P(s|t,B) where s is the source sentence, t the target sentence i.e. the paraphrase, t the best paraphrase and B a model of the noisy channel between the source and target languages i.e. the paraphrase table.

Title:J10-3002		Conference:Computational Linguistics		Author:Liu, Yang; Liu, Qun; Lin, Shouxun
The estimation of translation model parameters usually relies heavily on word-aligned corpora, not only for phrase-based and hierarchical phrase-based models (Koehn, Och, and Marcu 2003; Och and Ney 2004; Chiang 2005, 2007), but also for syntax-based models (Quirk, Menezes, and Cherry 2005; Galley et al. 2006; Liu, Liu, and Lin 2006; Marcu et al. 2006).

Title:W10-3812		Conference:Proceedings of the 4th Workshop on Syntax and Structure in Statistical Translation		Author:Khalilov, Maxim; Sima'an, Khalil
2 Baseline: Phrase-based SMT Given a word-aligned parallel corpus, phrasebased systems (Och and Ney, 2002; Koehn et al., 2003) work with (in principle) arbitrarily large phrase pairs (also called blocks) acquired from word-aligned parallel data under a simple definition of translational equivalence (Zens et al., 2002).

Title:C10-1118		Conference:COLING		Author:Sun, Jun; Zhang, Min; Tan, Chew Lim
7.2 Experimental results Utilizing the syntactic rules only has been argued to be ineffective (Koehn et al., 2003).

Title:C10-1135		Conference:COLING		Author:Xiao, Xinyan; Liu, Yang; Hwang, Young-Sook; Liu, Qun; Lin, Shouxun
We used GIZA++ (Och and Ney, 2003) to perform word alignment in both directions, and grow-diag-final-and (Koehn et al., 2003) to generate symmetric word alignment.

Title:C10-1135		Conference:COLING		Author:Xiao, Xinyan; Liu, Yang; Hwang, Young-Sook; Liu, Qun; Lin, Shouxun
We believe that our approach can be applied to other string-based model such as phrase-based model (Koehn et al., 2003), stringto-tree model (Galley et al., 2006) and string-todependency model (Shen et al., 2008).

Title:C10-1135		Conference:COLING		Author:Xiao, Xinyan; Liu, Yang; Hwang, Young-Sook; Liu, Qun; Lin, Shouxun
Based on the type of input, Mi and Huang (2008) distinguish between two categories of SMT systems : string-based systems (Koehn et al., 2003; Chiang, 2007; Galley et al., source target tokenize+translate string tokenization translation source target string tokenize tokenization translate translation (a) (b) Figure 1: (a) Separate tokenization and translation and (b) joint tokenization and translation.

Title:P10-1076		Conference:ACL		Author:Xiao, Tong; Zhu, Jingbo; Zhu, Muhua; Wang, Huizhen
Many SMT frameworks have been developed, including phrase-based SMT (Koehn et al., 2003), hierarchical phrase-based SMT (Chiang, 2005), syntax-based SMT (Eisner, 2003; Ding and Palmer, 2005; Liu et al., 2006; Galley et al., 2006; Cowan et al., 2006), etc. With the emergence of various structurally different SMT systems, more and more studies are focused on combining multiple SMT systems for achieving higher translation accuracy rather than using a single translation system.

Title:W10-2917		Conference:Proceedings of the Fourteenth Conference on Computational Natural Language Learning		Author:Huang, Shujian; Li, Kangxi; Dai, Xinyu; Chen, Jiajun
Moses (Koehn et al., 2003) is used for decoding.

Title:C10-2147		Conference:COLING - POSTERS		Author:Visweswariah, Karthik; Chenthamarakshan, Vijil; Kambhatla, Nanda
Modern SMT systems (Koehn et al., 2003; Ittycheriah and Roukos, 2007) learn translation models based on large amounts of parallel data.

Title:W10-3805		Conference:Proceedings of the 4th Workshop on Syntax and Structure in Statistical Translation		Author:Kolachina, Prasanth; Venkatapathy, Sriram; Bangalore, Srinivas; Kolachina, Sudheer; P. V. S., Avinesh
To handle the contextual information, phrasebased models were introduced (Koehn et al., 2003).

Title:N10-1080		Conference:Human Language Technologies: The 2010 Annual Conference of the North American Chapter of the Association for Computational Linguistics		Author:Cer, Daniel; Manning, Christopher D.; Jurafsky, Daniel
Phraseswereextracted by running GIZA++ (Och and Ney, 2003) in both directions and then merging the alignments using the grow-diag-final heuristic (Koehn et al., 2003).

Title:N10-1080		Conference:Human Language Technologies: The 2010 Annual Conference of the North American Chapter of the Association for Computational Linguistics		Author:Cer, Daniel; Manning, Christopher D.; Jurafsky, Daniel
Phrases were extracted using the grow heuristic (Koehn et al., 2003).

Title:C10-2086		Conference:COLING - POSTERS		Author:Liu, Shui; Li, Sheng; Zhao, Tiejun; Zhang, Min; Liu, Pengyuan
BorrowLink( fj ): if the word fj in source without a alignment word in target, i.e. fj FNULL ; let l(ei,fj)=1 where ei aligned to the word fj , which is the nearest word to fj in the source side; when there are two words nearest to fj with alignment words in the target side at the same time, we select the alignment of the left word firstly . FindAnchor( ): for the word ei in target with more than one words aligned in source , i.e. ei E1-to-N ; we select the word fm aligned to ei as its anchor word to decide the reordering type of ei , where fm= argmaxj p(ei | fj) and p(fj | ei) is estimated by ( Koehn et al, 2003); For the rest of words aligned to ei , we would set their word indexes with true in the update procedure of decoding in the 18th line of Fig.4.

Title:P10-1032		Conference:ACL		Author:Sun, Jun; Zhang, Min; Tan, Chew Lim
However, utilizing syntactic translational equivalences alone for machine translation loses the capability of modeling non-syntactic phrases (Koehn et al., 2003).

Title:P10-1016		Conference:ACL		Author:Duan, Xiangyu; Zhang, Min; Li, Haizhou
1 Introduction The pipeline of most Phrase-Based Statistical Machine Translation (PB-SMT) systems starts from automatically word aligned parallel corpus generated from word-based models (Brown et al., 1993), proceeds with step of induction of phrase table (Koehn et al., 2003) or synchronous grammar (Chiang, 2007) and with model weights tuning step.

Title:P10-2033		Conference:Proceedings of the ACL 2010 Conference Short Papers		Author:Carpuat, Marine; Marton, Yuval; Habash, Nizar
These issues are particularly problematic in phrase-based SMT (Koehn et al., 2003).

Title:N10-2003		Conference:Proceedings of the NAACL HLT 2010 Demonstration Session		Author:Cer, Daniel; Galley, Michel; Jurafsky, Daniel; Manning, Christopher D.
(Liang et al., 2006).2 From the word-to-word alignments, the system extracts a phrase table (Koehn et al., 2003) and hierarchical reordering model (Galley and Manning, 2008).

Title:C10-1064		Conference:COLING		Author:Kim, Seokhwan; Jeong, Minwoo; Lee, Jonghoon; Lee, Gary Geunbae
The bi-direcional alignments were joined by the grow-diag-final algorithm, which is widely used in bilingual phrase extraction (Koehn et al., 2003) for statistical machine translation.

Title:C10-1149		Conference:COLING		Author:Zhao, Shiqi; Wang, Haifeng; Lan, Xiang; Liu, Ting
D-2: The extracted phrasal paraphrases (including self-paraphrases) are stored in a phrase table, in which each phrase pair has 4 scores measuring their alignment confidence (Koehn et al., 2003).

Title:W10-3804		Conference:Proceedings of the 4th Workshop on Syntax and Structure in Statistical Translation		Author:Cao, Hailong; Finch, Andrew; Sumita, Eiichiro
This is consistent with the observation of (Koehn et al., 2003) who applied both source and target constraints in German to English translation experiments.

Title:W10-3804		Conference:Proceedings of the 4th Workshop on Syntax and Structure in Statistical Translation		Author:Cao, Hailong; Finch, Andrew; Sumita, Eiichiro
1 Introduction Both PBMT models (Koehn et al., 2003; Chiang, 2005) and syntax-based machine translation models (Yamada et al., 2000; Quirk et al., 2005; Galley et al., 2006; Liu et al., 2006; Marcu et al., 2006; and numerous others) are the state-of-theart statistical machine translation (SMT) methods.

Title:W10-3804		Conference:Proceedings of the 4th Workshop on Syntax and Structure in Statistical Translation		Author:Cao, Hailong; Finch, Andrew; Sumita, Eiichiro
(Koehn et al., 2003) uses syntactic constraints from both the source and target languages, and over 80% of all phrase pairs are eliminated.

Title:W10-3804		Conference:Proceedings of the 4th Workshop on Syntax and Structure in Statistical Translation		Author:Cao, Hailong; Finch, Andrew; Sumita, Eiichiro
However, (Koehn et al., 2003) showed that restricting phrasal translation to only syntactic phrases yields poor translation performance the ability to translate nonsyntactic phrases (such as there are, note that, and according to) turns out to be critical and pervasive.

Title:D10-1054		Conference:EMNLP		Author:He, Zhongjun; Meng, Yao; Yu, Hao
To obtain word alignments, we first ran GIZA++ (Och and Ney, 2000) in both translation directions and then refined the results using the grow-diagfinal method (Koehn et al., 2003).

Title:W10-3222		Conference:Proceedings of the Eighth Workshop on Asian Language Resouces		Author:Wen, Li; Lei, Chen; Wudabala, Han; Miao, Li
Bidirectional word alignments obtained with GIZA++ are intersected using the grow-diagfinal heuristic (Koehn et al., 2003).

Title:W10-3222		Conference:Proceedings of the Eighth Workshop on Asian Language Resouces		Author:Wen, Li; Lei, Chen; Wudabala, Han; Miao, Li
3.2 Phrase-based SMT The authors assume the reader to be familiar with current approaches to machine translation, so that we briefly introduce the phrasebased statistical machine translation model (Koehn et al., 2003) here, which is the foundation of chained SMT system.

Title:W10-3707		Conference:Proceedings of the 2010 Workshop on Multiword Expressions: from Theory to Applications		Author:Pal, Santanu; Naskar, Sudip Kumar; Pecina, Pavel; Bandyopadhyay, Sivaji; Way, Andy
Secondly, the IBM Models only allow at most one word in the source language to correspond to a word in the target language (Marcu, 2001, Koehn et al., 2003).

Title:W10-3707		Conference:Proceedings of the 2010 Workshop on Multiword Expressions: from Theory to Applications		Author:Pal, Santanu; Naskar, Sudip Kumar; Pecina, Pavel; Bandyopadhyay, Sivaji; Way, Andy
The effectiveness of the MWE-aligned parallel corpus developed in the work is demonstrated by using the standard log-linear PB-SMT model as our baseline system: GIZA++ implementation of IBM word alignment model 4, phraseextraction heuristics described in (Koehn et al., 2003), minimum-error-rate training (Och, 2003) on a held-out development set, target language model with Kneser-Ney smoothing (Kneser and 1 The EILMT and ILILMT projects are funded by the Department of Information Technology (DIT), Ministry of Communications and Information Technology (MCIT), Government of India.

Title:P10-2026		Conference:Proceedings of the ACL 2010 Conference Short Papers		Author:Wang, Zhiyang; L&uuml;, Yajuan; Liu, Qun; Hwang, Young-Sook
4 Head Word Trigger (Koehn et al., 2003) introduced the concept of lexical weighting to check how well words of the phrase translate to each other.

Title:P10-2070		Conference:Proceedings of the ACL 2010 Conference Short Papers		Author:Steinberger, Josef; Turchi, Marco; Alexandrov-Kabadjov, Mijail; Steinberger, Ralf; Cristianini, Nello
To model our interpretation of the noisy channel, we make use of one of the most popular classes of SMT systems: the Phrase Based Model (PBM) (Zens et al., 2002; Och and Ney, 2001; Koehn et al., 2003).

Title:P10-2070		Conference:Proceedings of the ACL 2010 Conference Short Papers		Author:Steinberger, Josef; Turchi, Marco; Alexandrov-Kabadjov, Mijail; Steinberger, Ralf; Cristianini, Nello
, LM and d are used to give a different weight to each element (for more details see (Koehn et al., 2003)).

Title:N10-1140		Conference:Human Language Technologies: The 2010 Annual Conference of the North American Chapter of the Association for Computational Linguistics		Author:Galley, Michel; Manning, Christopher D.
4 Features Oursystem incorporates thesameeight baseline features of Moses: two relative-frequency phrase translation probabilities p(e|f) and p(f|e), two lexicallyweighted phrase translation probabilities (Koehn et al., 2003) lex(e|f) and lex(f|e), a language model probability, word penalty, phrase penalty, and linear distortion, and we optionally add 6 lexicalized reordering features as computed in Moses.

Title:N10-1140		Conference:Human Language Technologies: The 2010 Annual Conference of the North American Chapter of the Association for Computational Linguistics		Author:Galley, Michel; Manning, Christopher D.
Experimentally, it was found that longer phrases yield better MT output (Koehn et al., 2003).

Title:N10-1113		Conference:Human Language Technologies: The 2010 Annual Conference of the North American Chapter of the Association for Computational Linguistics		Author:Schwarck, Florian; Fraser, Alexander; Sch&uuml;tze, Hinrich
Figure 2: Disambiguation Algorithm We used standard heuristics for improving word alignment (Och and Ney, 2003; Koehn et al., 2003), but there were many misalignments of ambiguous German words.

Title:W10-1754		Conference:Proceedings of the Joint Fifth Workshop on Statistical Machine Translation and MetricsMATR		Author:Liu, Chang; Dahlmeier, Daniel; Ng, Hwee Tou
The widely used phrase extraction heuristic in (Koehn et al., 2003) is used to extract phrase pairs and phrases of up to 4 words are collected.

Title:W10-4006		Conference:Proceedings of the 4th Workshop on Cross Lingual Information Access		Author:Okita, Tsuyoshi; Maldonado Guerra, Alfredo; Graham, Yvette; Way, Andy
It alone does not effectively capture many-to-many word correspondences, but instead relies on the ability of subsequent heuristic phrase extraction algorithms, such as grow-diagfinal (Koehn et al., 2003), to resolve them.

Title:C10-1054		Conference:COLING		Author:Hong, Gumwon; Li, Chi-Ho; Zhou, Ming; Rim, Hae-Chang
The SMT systems are our implementations of phrase-based SMT (Koehn et al., 2003) and hierarchical phrase-based SMT (Chiang, 2007).

Title:J10-3007		Conference:Computational Linguistics		Author:Gra&ccedil;a, Jo&atilde;o; Ganchev, Kuzman; Taskar, Ben
Word alignments are used primarily for extracting minimal translation units for machine translation (MT) (e.g., phrases [Koehn, Och, and Marcu 2003] and rules [Galley et al. 2004; Chiang et al. 2005]) as well as for INESC-ID Lisboa, Spoken Language Systems Lab, R. Alves Redol 9, 1000-029 LISBOA, Portugal.

Title:D10-1053		Conference:EMNLP		Author:Gispert, Adri&agrave;; de; Pino, Juan; Byrne, William
Our motivation is that symmetrization strategies have been reported to be beneficial for Viterbi extraction methods (Och and Ney, 2003; Koehn et al., 2003).

Title:D10-1053		Conference:EMNLP		Author:Gispert, Adri&agrave;; de; Pino, Juan; Byrne, William
Also, for Viterbi extraction we find that the source-to-target V-st case performs better than any of the symmetrization strategies, which contradicts previous findings for non-hierarchical phrase-based systems(Koehn et al., 2003).

Title:D10-1053		Conference:EMNLP		Author:Gispert, Adri&agrave;; de; Pino, Juan; Byrne, William
Common practice (Koehn et al., 2003) takes a set of word alignment links L and defines the alignment constraints CA so that there is a consistency between the links in the (fj2j1 ,ei2i1) phrase pair.

Title:D10-1053		Conference:EMNLP		Author:Gispert, Adri&agrave;; de; Pino, Juan; Byrne, William
We distinguish four cases, depending on the model used to obtain the set of links: source-totarget (V-st), target-to-source (V-ts), and two common symmetrization strategies: union (Vunion) and grow-diag-final (V-gdf), described in (Koehn et al., 2003).

Title:P10-1028		Conference:ACL		Author:Sun, Xu; Gao, Jianfeng; Micol, Daniel; Quirk, Chris
An alternate translation probability estimate not subject to data sparsity issues is the so-called lexical weight estimate (Koehn et al., 2003).

Title:P10-1028		Conference:ACL		Author:Sun, Xu; Gao, Jianfeng; Micol, Daniel; Quirk, Chris
To this end, inspired by the phrase-based statistical machine translation (SMT) systems (Koehn et al., 2003; Och and Ney, 2004), we propose a phrase-based error model where we assume that query spelling correction is performed at the phrase level.

Title:P10-1028		Conference:ACL		Author:Sun, Xu; Gao, Jianfeng; Micol, Daniel; Quirk, Chris
5.2 Model Estimation We follow a method commonly used in SMT (Koehn et al., 2003) to extract bi-phrases and estimate their replacement probabilities.

Title:C10-2044		Conference:COLING - POSTERS		Author:He, Zhongjun; Meng, Yao; Yu, Hao
To obtain word alignments, we first ran GIZA++ (Och and Ney, 2002) in both translation directions and then refined it by grow-diag-final method (Koehn et al., 2003).

Title:C10-2044		Conference:COLING - POSTERS		Author:He, Zhongjun; Meng, Yao; Yu, Hao
1 Introduction The hierarchial phrase-based (HPB) model (Chiang, 2005) outperformed previous phrase-based models (Koehn et al., 2003; Och and Ney, 2004) by utilizing hierarchical phrases consisting of both words and variables.

Title:P10-2003		Conference:Proceedings of the ACL 2010 Conference Short Papers		Author:Su, Jinsong; Liu, Yang; L&uuml;, Yajuan; Mi, Haitao; Liu, Qun
The early phrase-based paradigm (Koehn et al., 2003) applies a simple distance-based distortion penalty to model the phrase movements.

Title:P10-2003		Conference:Proceedings of the ACL 2010 Conference Short Papers		Author:Su, Jinsong; Liu, Yang; L&uuml;, Yajuan; Mi, Haitao; Liu, Qun
1 Introduction Phrase-based translation systems (Koehn et al., 2003; Och and Ney, 2004) prove to be the stateof-the-art as they have delivered translation performance in recent machine translation evaluations.

Title:C10-2096		Conference:COLING - POSTERS		Author:Mi, Haitao; Huang, Liang; Liu, Qun
We word-align the strings of 1-best segmentations and target strings with GIZA++ (Och and Ney, 2000) and apply the refinement method grow-diag-final-and (Koehn et al., 2003) to get the final alignments.

Title:C10-2096		Conference:COLING - POSTERS		Author:Mi, Haitao; Huang, Liang; Liu, Qun
We again apply the refinement method grow-diag-final-and (Koehn et al., 2003) to get the final alignments.

Title:W10-1709		Conference:Proceedings of the Joint Fifth Workshop on Statistical Machine Translation and MetricsMATR		Author:Hanneman, Greg; Clark, Jonathan H.; Lavie, Alon
In the first, we perform standard (non-syntactic) phrase extraction according to the heuristics of phrase-based SMT (Koehn et al., 2003).

Title:N10-1063		Conference:Human Language Technologies: The 2010 Annual Conference of the North American Chapter of the Association for Computational Linguistics		Author:Smith, Jason R.; Quirk, Chris; Toutanova, Kristina
A standard phrasal SMT system (Koehn et al., 2003) serves as our testbed, using a conventional set of models: phrasal mod408 els of source given target and target given source; lexical weighting models in both directions, language model, word count, phrase count, distortion penalty, and a lexicalized reordering model.

Title:C10-1126		Conference:COLING		Author:Visweswariah, Karthik; Navratil, Jiri; Sorensen, Jeffrey S.; Chenthamarakshan, Vijil; Kambhatla, Nanda
Early distortion models simply penalized longer jumps more than shorter jumps (Koehn et al., 2003) independent of the source or target phrases in question.

Title:N10-1128		Conference:Human Language Technologies: The 2010 Annual Conference of the North American Chapter of the Association for Computational Linguistics		Author:Dyer, Chris; Resnik, Philip
In the derivation on the left, a memorized phrase pair captures the movement of the verb (Koehn et al., 2003).

Title:C10-2043		Conference:COLING - POSTERS		Author:He, Yifan; Ma, Yanjun; Way, Andy; van Genabith, Josef
5.1.2 SMT and TM systems We use a standard log-linear PB-SMT model (Och and Ney, 2002): GIZA++ implementation of IBM word alignment model 4, the phrase-extraction heuristics described in (Koehn et al., 2003), minimum-error-rate training (Och, 2003), a 5-gram language model with Kneser-Ney smoothing trained with SRILM (Stolcke, 2002) on the English side of the training data, and Moses (Koehn et al., 2007) to decode.

Title:N10-1028		Conference:Human Language Technologies: The 2010 Annual Conference of the North American Chapter of the Association for Computational Linguistics		Author:Blunsom, Philip; Cohn, Trevor
The predominant approach for learning phrasebased translation models (both finite state or synchronous grammar based) uses a cascade of heuristics beginning with predicted word alignments and producing a weighted set of translation rules (Koehn et al., 2003).

Title:C10-2037		Conference:COLING - POSTERS		Author:Gangadharaiah, Rashmi; Brown, Ralf D.; Carbonnell, Jaime G.
Similar to Pharaoh (Koehn et al., 2003), the decoder uses multilevel beam search with a priority queue formed based on the number of source words translated.

Title:C10-2037		Conference:COLING - POSTERS		Author:Gangadharaiah, Rashmi; Brown, Ralf D.; Carbonnell, Jaime G.
Koehn (2002) shows translation scores for a number of language pairs with different training sizes translated using the Pharaoh SMT toolkit (Koehn et al., 2003).

Title:P10-1003		Conference:ACL		Author:Chen, Wenliang; Kazama, Jun'ichi; Torisawa, Kentaro
The main problem to be addressed is mapping words on the source side to the target subtree because there are many to many mappings and reordering problems that often occur in translation (Koehn et al., 2003).

Title:P10-1147		Conference:ACL		Author:DeNero, John; Klein, Dan
Extraction set models allow us to incorporate the samephrasalrelativefrequencystatisticsthatdrive phrase-based translation performance (Koehn et al., 2003).

Title:P10-1147		Conference:ACL		Author:DeNero, John; Klein, Dan
2.1 Extraction Sets from Word Alignments Rule extraction is a standard concept in machine translation: word alignment constellations license particular sets of overlapping rules, from which subsets are selected according to limits on phrase length (Koehn et al., 2003), number of gaps (Chiang, 2007), count of internal tree nodes (Galley et al., 2006), etc. In this paper, we focus on phrasal rule extraction (i.e., phrase pair extraction), upon which most other extraction procedures are based.

Title:P10-1147		Conference:ACL		Author:DeNero, John; Klein, Dan
This general paradigm was first pursued using contiguous phrases (Och et al., 1999; Koehn et al., 2003), and has since been generalized to a wide variety of hierarchical and syntactic formalisms.

Title:P10-1147		Conference:ACL		Author:DeNero, John; Klein, Dan
We combined these alignments with 1459 the grow-diag heuristic (Koehn et al., 2003).

Title:W10-2406		Conference:Proceedings of the 2010 Named Entities Workshop		Author:Finch, Andrew; Sumita, Eiichiro
Our approach uses a re-scoring technique to integrate the models of two transliteration systems that are each capable in their own right: a phrase-based statistical machine translation system (Koehn et al., 2003), and a joint multigram model (Deligne and Bimbot, 1995; Bisani and Ney, 2008).

Title:W10-2406		Conference:Proceedings of the 2010 Named Entities Workshop		Author:Finch, Andrew; Sumita, Eiichiro
This decoder operates on exactly the same principles as the publicly available MOSES decoder (Koehn et al., 2003).

Title:W10-3809		Conference:Proceedings of the 4th Workshop on Syntax and Structure in Statistical Translation		Author:Venkatapathy, Sriram; Sangal, Rajeev; Joshi, Aravind K.; Gali, Karthik
For word-alignment, we used the IBM Model 5 implemented in GIZA++ along with the growing heuristics (Koehn et al., 2003).

Title:D10-1015		Conference:EMNLP		Author:Luong, Minh-Thang; Nakov, Preslav; Kan, Min-Yen
We then estimate a lexicalized phrase score using the original formula given in (Koehn et al., 2003), where we plug this induced word alignment and word-token lexical translation probabilities estimated from the word-token dataset The case when (fw,ew) is present in PTw, but (fm,em) is not, is solved similarly.

Title:D10-1015		Conference:EMNLP		Author:Luong, Minh-Thang; Nakov, Preslav; Kan, Min-Yen
The maximum phrase length n is normally limited to seven words; higher values of n increase the table size exponentially without actually yielding performance benefit (Koehn et al., 2003).

Title:D10-1015		Conference:EMNLP		Author:Luong, Minh-Thang; Nakov, Preslav; Kan, Min-Yen
In phrase-based SMT, phrase translation probabilities are computed using maximum likelihood (ML) estimation (f|e) = #(f,e)summationtext f #(f,e) , where #(f,e) is the number of times the pair (f,e) is extracted from the training dataset (Koehn et al., 2003).

Title:D10-1015		Conference:EMNLP		Author:Luong, Minh-Thang; Nakov, Preslav; Kan, Min-Yen
3 Morphological Enhancements We present a morphologically-enhanced version of the classic phrase-based SMT model (Koehn et al., 2003).

Title:D10-1091		Conference:EMNLP		Author:Wisniewski, Guillaume; Allauzen, Alexandre; Yvon, Fran&ccedil;ois
In a first step, the corpus is aligned at the word level, by using alignment tools such as Giza++ (Och and Ney, 2003) and some symmetrisation heuristics; phrasesarethenextractedbyotherheuristics(Koehn et al., 2003) and assigned numerical weights.

Title:W10-2925		Conference:Proceedings of the Fourteenth Conference on Computational Natural Language Learning		Author:Gimpel, Kevin; Das, Dipanjan; Smith, Noah A.
To align test data, we symmetrized both directional Viterbi alignments using the grow-diag-final heuristic (Koehn et al., 2003).

Title:P11-2079		Conference:Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies		Author:Ling, Wang; Lu&iacute;s, Tiago; Gra&ccedil;a, Jo&atilde;o; Trancoso, Isabel; Coheur, Lu&iacute;sa
1 Introduction The translation quality of statistical phrase-based systems (Koehn et al., 2003) is heavily dependent on the quality of the translation and reordering models generated during the phrase extraction algorithm (Ling et al., 2010).

Title:D11-1007		Conference:EMNLP		Author:Chen, Wenliang; Kazama, Jun'ichi; Zhang, Min; Tsuruoka, Yoshimasa; Zhang, Yujie; Wang, Yiou; Torisawa, Kentaro; Li, Haizhou
The second constraint function, denoted as Fb2(rs2 : rt3), checks if the corresponding words form a parent-child-grandchild relation that often occurs in translation (Koehn et al., 2003).

Title:P11-1024		Conference:Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies		Author:Subotin, Michael
All conditions use word alignments produced by sequential iterations of IBM model 1, HMM, and IBM model 4 in GIZA++, followed by diag-and symmetrization (Koehn et al., 2003).

Title:P11-2078		Conference:Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies		Author:Ananthakrishnan, Sankaranarayanan; Prasad, Rohit; Natarajan, Prem
Phrase translation rules (up to a maximum source span of 5 words) were extracted from a combination of forward and backward word alignments (Koehn et al., 2003).

Title:W11-1015		Conference:Proceedings of Fifth Workshop on Syntax, Semantics and Structure in Statistical Translation		Author:Hanneman, Greg; Burroughs, Michelle; Lavie, Alon
Practitioners of both phrasebased and syntax-based SMT have reported severe grammar coverage issues when rules are required to exactly match parse constituents (Koehn et al., 2003; Chiang, 2010).

Title:W11-1015		Conference:Proceedings of Fifth Workshop on Syntax, Semantics and Structure in Statistical Translation		Author:Hanneman, Greg; Burroughs, Michelle; Lavie, Alon
This is analogous to the word-alignment consistency constraint of phrase-based SMT phrase extraction (Koehn et al., 2003).

Title:P11-2066		Conference:Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies		Author:Huang, Shujian; Vogel, Stephan; Chen, Jiajun
An average improvement of 0.52 BLEU (Papineni et al., 2002) score and 2.05 TER (Snover et al., 2006) score over 5 test sets for a typical phrase-based translation system, Moses (Koehn et al., 2003), validated the effectiveness of our experiments.

Title:P11-1044		Conference:Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies		Author:Sajjad, Hassan; Fraser, Alexander; Schmid, Helmut
Baseline: We align the data sets using GIZA++ (Och and Ney, 2003) and refine the alignments using the grow-diag-final-and heuristic (Koehn et al., 2003).

Title:P11-1044		Conference:Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies		Author:Sajjad, Hassan; Fraser, Alexander; Schmid, Helmut
We also apply Algorithm 3 and Algorithm 4 in the alignment direction 436 Algorithm 4 Interpolation with the IBM Model4, eto-f direction 1: {We want to run four iterations of Model4} 2: f(e)total frequency of e in the corpus 3: Run MGIZA++ for one iteration of Model4 4: I1 5: while I <4 do 6: Look up pta(f|e) in the t-table of Model4 7: fta(f,e)pta(f|e)f(e) for all (f,e) 8: p(f|e) fta(f,e)+pti(f|e)fta(e)+ for all (f,e) 9: Resume MGIZA++ training for 1 iteration using the modified t-table probabilities p(f|e) 10: II +1 11: end while f to e. The final alignments are generated using the grow-diag-final-and heuristic (Koehn et al., 2003).

Title:P11-1044		Conference:Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies		Author:Sajjad, Hassan; Fraser, Alexander; Schmid, Helmut
Initially, the parallel corpus is word-aligned using GIZA++ (Och and Ney, 2003), and the alignments are refined using the grow-diag-final-and heuristic (Koehn et al., 2003).

Title:P11-1044		Conference:Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies		Author:Sajjad, Hassan; Fraser, Alexander; Schmid, Helmut
The alignments are refined using the grow-diag-final-and heuristic (Koehn et al., 2003).

Title:P11-1044		Conference:Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies		Author:Sajjad, Hassan; Fraser, Alexander; Schmid, Helmut
2.2 Statistical Machine Transliteration System We build a phrase-based MT system for transliteration using the Moses toolkit (Koehn et al., 2003).

Title:D11-1047		Conference:EMNLP		Author:Cromier&egrave;s, Fabien; Kurohashi, Sadao
We use the term translation rule in a very broad sense here, as it may refer to substring pairs as in (Koehn et al., 2003), synchronous grammar rules as in (Chiang, 2007) or treelet pairs as in (Quirk et al., 2005; Nakazawa and Kurohashi, 2008).

Title:W11-2157		Conference:Proceedings of the Sixth Workshop on Statistical Machine Translation		Author:S&aacute;nchez-Cartagena, V&iacute;ctor M.; S&aacute;nchez-Mart&iacute;nez, Felipe; P&eacute;rez-Ortiz, Juan Antonio
2.1 Phrase-based statistical machine translation Phrase-based statistical machine translation systems (Koehn et al., 2003) translate sentences by maximising the translation probability as defined by the log-linear combination of a number of feature functions, whose weights are chosen to opti457 mise translation quality (Och, 2003).

Title:D11-1085		Conference:EMNLP		Author:Li, Zhifei; Wang, Ziyuan; Eisner, Jason M.; Khudanpur, Sanjeev P.; Roark, Brian
In a task like MT, in addition to the input x and outputy, we often need to introduce a latent variable d to represent the hidden derivation that relates x to y. A derivation d represents a particular phrase segmentation in a phrase-based MT system (Koehn et al., 2003) and a derivation tree in a typical syntaxbased system (Galley et al., 2006; Chiang, 2007).

Title:P11-1130		Conference:Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies		Author:Nakov, Preslav; Ng, Hwee Tou
While several significantly improved models have been developed since then, including phrase-based (Koehn et al., 2003), hierarchical (Chiang, 2005), treelet (Quirk et al., 2005), and syntactic (Galley et al., 2004) models, they all preserved the assumption that words should be atomic.

Title:D11-1080		Conference:EMNLP		Author:Monz, Christof
873 4 Experimental Setup Three approaches are compared in our experiments: the baseline system is a phrase-based statistical machine translation system (Koehn et al., 2003), very similar to Moses (Koehn et al., 2007), using a wordbased 5-gram language model.

Title:W11-2165		Conference:Proceedings of the Sixth Workshop on Statistical Machine Translation		Author:Gimpel, Kevin; Smith, Noah A.
1 Introduction Beginning with the success of phrase-based translation models (Koehn et al., 2003), a trend arose of modeling larger and increasingly complex structural units in translation.

Title:W11-2160		Conference:Proceedings of the Sixth Workshop on Statistical Machine Translation		Author:Weese, Jonathan; Ganitkevitch, Juri; Callison-Burch, Chris; Post, Matt; Lopez, Adam
We calculate these weights as given in (Koehn et al., 2003): let A be the alignment between and , so (i,j) A if and only if the ith word of is aligned to the jth word of .

Title:P11-1131		Conference:Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies		Author:Bansal, Mohit; Quirk, Chris; Moore, Robert C.
Phrase tables containing pairs of source and target language phrases are extracted from word alignments, forming the core of phrase-based statistical machine translation systems (Koehn et al., 2003).

Title:P11-1131		Conference:Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies		Author:Bansal, Mohit; Quirk, Chris; Moore, Robert C.
Much work has addressed this problem: generative models for direct phrasal alignment (Marcu and Wong, 2002), heuristic word-alignment combinations (Koehn et al., 2003; Och and Ney, 2003), models with pseudoword collocations (Lambert and Banchs, 2006; Ma et al., 2007; Duan et al., 2010), synchronous grammar based approaches (Wu, 1997), etc. Most have a large state-space, using constraints and approximations for efficient inference.

Title:P11-2067		Conference:Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies		Author:Howlett, Susan; Dras, Mark
4.1 System Variations CKK uses the PSMT system Pharaoh (Koehn et al., 2003), whereas HD uses its successor Moses (Koehn et al., 2007).

Title:W11-1007		Conference:Proceedings of Fifth Workshop on Syntax, Semantics and Structure in Statistical Translation		Author:Xiang, Bing; Ge, Niyu; Ittycheriah, Abraham
Word order in the translation output relies on how the phrases are reordered based on both language model scores and distortion cost/penalty (Koehn et al., 2003), among all the features utilized in a maximum-entropy (loglinear) model (Och and Ney, 2002).

Title:W11-1007		Conference:Proceedings of Fifth Workshop on Syntax, Semantics and Structure in Statistical Translation		Author:Xiang, Bing; Ge, Niyu; Ittycheriah, Abraham
SMT system (Koehn et al., 2003) that is trained on the same training data.

Title:W11-1007		Conference:Proceedings of Fifth Workshop on Syntax, Semantics and Structure in Statistical Translation		Author:Xiang, Bing; Ge, Niyu; Ittycheriah, Abraham
Phrase-based SMT systems such as (Koehn et al., 2003) move from using words as translation units to using phrases.

Title:W11-2126		Conference:Proceedings of the Sixth Workshop on Statistical Machine Translation		Author:Williams, Philip; Koehn, Philipp
null plex(RHStnullRHSs) and plex(RHSsnullRHSt), the direct and indirect lexical weights (Koehn et al., 2003). (self citation)

Title:W11-1006		Conference:Proceedings of Fifth Workshop on Syntax, Semantics and Structure in Statistical Translation		Author:Lefever, Els; Hoste, V&eacute;ronique
It combines a phrase translation model (which is based on the noisy channel model) and a phrase-based decoder in order to find the most probable translation e of a foreign sentence f (Koehn et al., 2003).

Title:W11-1604		Conference:Proceedings of the Workshop on Monolingual Text-To-Text Generation		Author:Wubben, Sander; Marsi, Erwin; van den Bosch, Antal; Krahmer, Emiel
One popular approach arguably the most successful so far is Statistical Phrase-based Machine Translation (PBMT), which learns phrase translation rules from aligned bilingual text corpora (Och et al., 1999; Vogel et al., 2000; Zens et al., 2002; Koehn et al., 2003).

Title:W11-2124		Conference:Proceedings of the Sixth Workshop on Statistical Machine Translation		Author:Niehues, Jan; Herrmann, Teresa; Vogel, Stephan; Waibel, Alex
1 Introduction In many state-of-the art SMT systems, the phrasebased (Koehn et al., 2003) approach is used.

Title:P11-3001		Conference:Proceedings of the ACL 2011 Student Session		Author:Xi, Ning; Tang, Guangchao; Li, Boyuan; Zhao, Yinggong
We used a phrase-based MT system similar to (Koehn et al., 2003), and generated two baseline alignments using GIZA++ enhanced by gdf heuristics (Koehn et al., 2003) and a linear discriminative word alignment model (DIWA) (Liu et al., 2010) on training set with the three segmentations respectively.

Title:P11-1105		Conference:Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies		Author:Durrani, Nadir; Schmid, Helmut; Fraser, Alexander
Our lexical features are standard (Koehn et al., 2003).

Title:W11-1610		Conference:Proceedings of the Workshop on Monolingual Text-To-Text Generation		Author:Napoles, Courtney; Callison-Burch, Chris; Ganitkevitch, Juri; van Durme, Benjamin
The corresponding foreign phrase (festgenommen) is identified using word alignment and phrase extraction techniques from phrase-based statistical machine translation (Koehn et al., 2003).

Title:D11-1020		Conference:EMNLP		Author:Xie, Jun; Mi, Haitao; Liu, Qun
We obtain the word alignments by running GIZA++ (Och and Ney, 2003) on the corpus in both directions and applying grow-diag-and refinement(Koehn et al., 2003).

Title:W11-1009		Conference:Proceedings of Fifth Workshop on Syntax, Semantics and Structure in Statistical Translation		Author:Attardi, Giuseppe; Chanev, Atanas; Miceli Barone, Antonio Valerio
This has been addressed with a distance based distortion model (Och 2002; Koehn et al. 2003), lexicalized phrase reordering (Tillmann, 2004; Koehn, et.al., 2005; Al-Onaizan and Papineni, 2006), by hierarchical phrase reordering model (Galley and Manning, 2008) or by reordering the nodes in a dependency tree (Xu et al., 2009) Movement of translations of fertile words: a word with fertility higher than one can be translated into several words that do not occur consecutively.

Title:P11-1065		Conference:Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies		Author:Mylonakis, Markos; Sima'an, Khalil
We consider as phrasepair spans those that obey the word-alignment constraints of (Koehn et al., 2003).

Title:P11-1065		Conference:Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies		Author:Mylonakis, Markos; Sima'an, Khalil
Interestingly, early on (Koehn et al., 2003) exemplified the difficulties of integrating linguistic information in translation systems.

Title:W11-2107		Conference:Proceedings of the Sixth Workshop on Statistical Machine Translation		Author:Denkowski, Michael; Lavie, Alon
Phrases are extracted using standard phrase-based heuristics (Koehn et al., 2003) and used to build a translation table and lexicalized reordering model.

Title:W11-2120		Conference:Proceedings of the Sixth Workshop on Statistical Machine Translation		Author:Sennrich, Rico
The Moses phrase table consists of five features: phrase translation probabilities in both translation directions (p(t|s) and p(s|t)), lexical weights (lex(t|s) and lex(s|t)), and a constant phrase penalty (Koehn et al., 2003).

Title:D11-1044		Conference:EMNLP		Author:Gimpel, Kevin; Smith, Noah A.
Our solution is to use a standard supervised dependency parser and extract phrase dependencies using bilingual information.3 We begin by obtaining symmetrized word alignments and extracting phrase pairs using the standard heuristic from phrase-based MT (Koehn et al., 2003).

Title:D11-1044		Conference:EMNLP		Author:Gimpel, Kevin; Smith, Noah A.
We also include lexical weighting features similar to those used in phrase-based MT (Koehn et al., 2003).

Title:D11-1044		Conference:EMNLP		Author:Gimpel, Kevin; Smith, Noah A.
Phrase-based models (Koehn et al., 2003) excel at capturing local reordering phenomena and memorizing multi-word translations.

Title:P11-2074		Conference:Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies		Author:Xiang, Bing; Ittycheriah, Abraham
Among all the proposed approaches, the phrasebased method (Koehn et al., 2003) has become the widely adopted one in SMT due to its capability of capturing local context information from adjacent words.

Title:P11-2074		Conference:Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies		Author:Xiang, Bing; Ittycheriah, Abraham
For example, the system described in (Koehn et al., 2003) is a widely known one using small number of features in a maximum-entropy (log-linear) model (Och and Ney, 2002).

Title:P11-2080		Conference:Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies		Author:Chiang, David; DeNeefe, Steve; Pust, Michael
1 Introduction Lexical weighting features (Koehn et al., 2003) estimate the probability of a phrase pair or translation rule word-by-word.

Title:P11-2080		Conference:Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies		Author:Chiang, David; DeNeefe, Steve; Pust, Michael
We have chosen to implement our approach as extensions to lexical weighting (Koehn et al., 2003), which is nearly ubiquitous, because it is dened at the level of word alignments.

Title:W11-2504		Conference:Proceedings of the GEMS 2011 Workshop on GEometrical Models of Natural Language Semantics		Author:Chan, Tsz Ping; Callison-Burch, Chris; van Durme, Benjamin
The corresponding foreign phrase (festgenommen) is identified using word alignment and phrase extraction techniques from phrase-based statistical machine translation (Koehn et al., 2003).

Title:P11-1042		Conference:Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies		Author:Dyer, Chris; Clark, Jonathan H.; Lavie, Alon; Smith, Noah A.
We symmetrize the alignments from both model types using the grow-diag-final-and heuristic (Koehn et al., 2003) producing, in total, six alignment sets.

Title:P11-1021		Conference:Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies		Author:Tan, Ming; Zhou, Wenli; Zheng, Lei; Wang, Shaojun
It is expected that putting the our composite language into a one pass decoder of both phrase-based (Koehn et al., 2003) and parsing-based (Chiang, 2005; Chiang, 2007) MT systems should result in much improved BLEU scores.

Title:D11-1108		Conference:EMNLP		Author:Ganitkevitch, Juri; Callison-Burch, Chris; Napoles, Courtney; van Durme, Benjamin
These include sentence alignment (Gale and Church, 1993; Barzilay and Elhadad, 2003), word alignment and noisy channel decoding (Brown et al., 1990; Quirk et al., 2004), phrase-based models (Koehn et al., 2003; Bannard and Callison-Burch, 2005), hierarchical phrase-based models (Chiang, 2005; Madnani et al., 2007), log-linear models and minimum error rate training (Och, 2003a; Madnani et al., 2007; Zhao et al., 2008a), and here syntaxbased machine translation (Wu, 1997; Yamada and Knight, 2001; Melamed, 2004; Quirk et al., 2005).

Title:D11-1108		Conference:EMNLP		Author:Ganitkevitch, Juri; Callison-Burch, Chris; Napoles, Courtney; van Durme, Benjamin
Paraphrase extraction using bilingual parallel corpora was proposed by Bannard and Callison-Burch (2005) who induced paraphrases using techniques from phrase-based statistical machine translation (Koehn et al., 2003).

Title:W11-2140		Conference:Proceedings of the Sixth Workshop on Statistical Machine Translation		Author:Eidelman, Vladimir; Hollingshead, Kristy; Resnik, Philip
The combined training corpus from which we extracted our grammar consisted of 123,609 sentence pairs, which was then filtered for length and aligned using the GIZA++ implementation of IBM Model 4 (Och and Ney, 2003) to obtain one-to-many alignments in either direction and symmetrized using the grow-diag-final-and method (Koehn et al., 2003).

Title:W11-2150		Conference:Proceedings of the Sixth Workshop on Statistical Machine Translation		Author:Khalilov, Maxim; Sima'an, Khalil
2.2 Phrase-based translation While first systems following this approach performed translation on the word level, modern stateof-the-art phrase-based SMT systems (Och and Ney, 2002; Koehn et al., 2003) start-out from a wordaligned parallel corpus working with (in principle) arbitrarily large phrase pairs (also called blocks) acquired from word-aligned parallel data under a simple definition of translational equivalence (Zens et al., 2002).

Title:D11-1081		Conference:EMNLP		Author:Xiao, Xinyan; Liu, Yang; Liu, Qun; Lin, Shouxun
word alignment in both directions, and grow-diagfinal-and (Koehn et al., 2003) to generate symmetric word alignment.

Title:D11-1081		Conference:EMNLP		Author:Xiao, Xinyan; Liu, Yang; Liu, Qun; Lin, Shouxun
Here a rule means a phrase translation (Koehn et al., 2003) or a translation pair that contains nonterminals.

Title:P11-1103		Conference:Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies		Author:Birch, Alexandra; Osborne, Miles
We extracted phrases as in (Koehn et al., 2003) by running GIZA++ in both directions and merging alignments with the grow-diag-final heuristic.

Title:D11-1018		Conference:EMNLP		Author:DeNero, John; Uszkoreit, Jakob
5.2 Translation Quality We apply STIR as a pre-ordering step in a stateof-the-art phrase-based translation system from English to Japanese (Koehn et al., 2003).

Title:P11-1124		Conference:Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies		Author:Ma, Yanjun; He, Yifan; Way, Andy; van Genabith, Josef
Specifically, we use the phrase translation probabilities p(fm|em) and p(em|fm), as well as the lexical translation probabilities plex(fm|em) and plex(em|fm) as calculated in (Koehn et al., 2003).

Title:P11-1124		Conference:Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies		Author:Ma, Yanjun; He, Yifan; Way, Andy; van Genabith, Josef
We conducted experiments using a standard loglinear PB-SMT model: GIZA++ implementation of IBM word alignment model 4 (Och and Ney, 2003), the refinement and phrase-extraction heuristics described in (Koehn et al., 2003), minimum-errorrate training (Och, 2003), a 5-gram language model with Kneser-Ney smoothing (Kneser and Ney, 1995) trained with SRILM (Stolcke, 2002) on the Chinese side of the training data, and Moses (Koehn et al., 2007) which is capable of handling user-specified translations for some portions of the input during decoding.

Title:D11-1149		Conference:EMNLP		Author:Lu, Wei; Ng, Hwee Tou
pLM(s): the language model score of the generated sentence s. The first three features, which are also widely used in state-of-the-art machine translation models (Koehn et al., 2003; Chiang, 2007), are rule-specific and thus can be computed before decoding.

Title:D11-1149		Conference:EMNLP		Author:Lu, Wei; Ng, Hwee Tou
Current state-of-theart string-based translation systems (Koehn et al., 2003; Chiang, 2005; Galley and Manning, 2010) typically begin with a word-aligned corpus to construct phrasal correspondences.

Title:W11-2211		Conference:Proceedings of the First workshop on Unsupervised Learning in NLP		Author:Huck, Matthias; Vilar, David; Stein, Daniel; Ney, Hermann
In contrast to Schwenk, we do not apply lightly-supervised training to a conventional phrase-based system (Och et al., 1999; Koehn et al., 2003) but to a hierarchical phrase-based translation (HPBT) system.

Title:W11-2211		Conference:Proceedings of the First workshop on Unsupervised Learning in NLP		Author:Huck, Matthias; Vilar, David; Stein, Daniel; Ney, Hermann
4.2 Unsupervised Data The unsupervised data that we integrate has been created by automatic translations of parts of the Arabic LDC Gigaword corpus (mostly from the HYT collection) with a standard phrase-based system (Koehn et al., 2003).

Title:D11-1079		Conference:EMNLP		Author:Gao, Yang; Koehn, Philipp; Birch, Alexandra
It motivates much of the recent work on tree-based translation models, such as the hierarchical phrase-based model (Chiang, 2007) which extends the phrase-based model (Koehn et al., 2003)byallowingtheso-calledhierarchicalphrases containing subphrases. (self citation)

Title:D11-1079		Conference:EMNLP		Author:Gao, Yang; Koehn, Philipp; Birch, Alexandra
For example, constituency constraints in (Chiang, 2005; Marton and Resnik, 2008; Chiang et al., 2009) would penalize Rule 7 below which is useful for GermanEnglish translation (Koehn et al., 2003), and Rule 8 which can be applied to the Figure 1 sentence. (self citation)

Title:P11-1063		Conference:Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies		Author:Schwartz, Lane; Callison-Burch, Chris; Schuler, William; Wu, Stephen
620 statistical MT that can run in linear-time (4) Integration with Moses (5) along with empirical results for perplexity and significant translation score improvement on a constrained UrduEnglish task (6) 2 Related Work Neither phrase-based (Koehn et al., 2003) nor hierarchical phrase-based translation (Chiang, 2005) take explicit advantage of the syntactic structure of either source or target language.

Title:P11-1063		Conference:Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies		Author:Schwartz, Lane; Callison-Burch, Chris; Schuler, William; Wu, Stephen
Early work in statistical phrase-based translation considered whether restricting translation models to use only syntactically well-formed constituents might improve translation quality (Koehn et al., 2003) but found such restrictions failed to improve translation quality.

Title:W11-2139		Conference:Proceedings of the Sixth Workshop on Statistical Machine Translation		Author:Dyer, Chris; Gimpel, Kevin; Clark, Jonathan H.; Smith, Noah A.
The parallel data were aligned using the Giza++ implementation of IBM Model 4 run in both directions and then symmetrized using the grow-diag-final-and heuristic (Och and Ney, 2002; Brown et al., 1993; Koehn et al., 2003).

Title:W11-2139		Conference:Proceedings of the Sixth Workshop on Statistical Machine Translation		Author:Dyer, Chris; Gimpel, Kevin; Clark, Jonathan H.; Smith, Noah A.
For example, restricting phrases and rules to be consistent with syntactic constituents consistently harms performance (Chiang, 2007; Galley et al., 2006; Koehn et al., 2003), although our intuitions might suggest this is a reasonable thing to do.

Title:W11-2143		Conference:Proceedings of the Sixth Workshop on Statistical Machine Translation		Author:Hanneman, Greg; Lavie, Alon
The non-syntactic grammar was extracted from the parallel corpus and word alignments following the standard heuristics of phrase-based SMT (Koehn et al., 2003).

Title:P11-1043		Conference:Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies		Author:DeNero, John; Macherey, Klaus
The bidirectional model improves both precision and recall relative to all heuristic combination techniques, including grow-diag-final (Koehn et al., 2003).

Title:P11-1043		Conference:Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies		Author:DeNero, John; Macherey, Klaus
Common combination methods include the union or intersection of directional alignments, as well as heuristic interpolations between the union and intersection like grow-diag-final (Koehn et al., 2003).

Title:P11-1043		Conference:Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies		Author:DeNero, John; Macherey, Klaus
A =AaAb A =AaAb . More complex combiners, such as the grow-diagfinal heuristic (Koehn et al., 2003), produce alignment link sets that include all ofA and some subset ofA based on the relationship of multiple links (Och et al., 1999).

Title:P11-1134		Conference:Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies		Author:Mehdad, Yashar; Negri, Matteo; Federico, Marcello
They are widely used in MT as a way to figure out how to translate input in one language into output in another language (Koehn et al., 2003).

Title:D11-1003		Conference:EMNLP		Author:Chang, Yin-Wen; Collins, Michael John
Lagrangian relaxation is used to enforce the constraint 1We refer here to the phrase-based models of (Koehn et al., 2003; Koehn et al., 2007), considered in this paper.

Title:D11-1003		Conference:EMNLP		Author:Chang, Yin-Wen; Collins, Michael John
1 Introduction Phrase-based models (Och et al., 1999; Koehn et al., 2003; Koehn et al., 2007) are a widely-used approach for statistical machine translation.

Title:D11-1003		Conference:EMNLP		Author:Chang, Yin-Wen; Collins, Michael John
Beam search stack decoders (Koehn et al., 2003) are the most commonly used decoding algorithm for phrase-based models.

Title:P11-2032		Conference:Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies		Author:Mermer, Co&scedil;kun; Sara&ccedil;lar, Murat
To obtain the Viterbi alignments, which are required for phrase extraction (Koehn et al., 2003), we select for each aj the most frequent value in the M collected samples.

Title:P11-2032		Conference:Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies		Author:Mermer, Co&scedil;kun; Sara&ccedil;lar, Murat
1 Introduction Word alignment is a crucial early step in the training of most statistical machine translation (SMT) systems, in which the estimated alignments are used for constraining the set of candidates in phrase/grammar extraction (Koehn et al., 2003; Chiang, 2007; Galley et al., 2006).

