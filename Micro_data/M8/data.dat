Title:Towards a Model of Face-to-Face Grounding		Conference:Meeting of the Association for Computational Linguistics - ACL		Author:Yukiko I. Nakano;Gabe Reinstein;Tom Stocky;Justine Cassell
We investigate the verbal and nonverbal means for Based on these results, we present an ECA that uses verbal and nonverbal grounding acts to update dialogue state.

Title:Conversational Grounding in Younger and Older Adults: The Effect of Partner Visibility and Referent Abstractness in Task-Oriented Dialogue		Conference:		Author:Katya Lysander;William S. Horton
...In addition, direction-followers in that study attempted to establish eye contact with direction-givers more often at points of confusion or potential trouble (see also Nakano, Reinstein, Stocky, & Cassell, 2003)...

Title:Generating connection events for human-robot collaboration		Conference:IEEE International Symposium on Robot and Human Interactive Communication - RO-MAN		Author:Aaron Holroyd;Charles Rich;Candace L. Sidner;Brett Ponsler
...Nakano et al. [7] reported on the use of the listener‚Äôs gaze and the lack of negative feedback to determine whether the listener has grounded [8] the speaker‚Äôs turn...

Title:See what i'm saying?: using Dyadic Mobile Eye tracking to study collaborative reference		Conference:Conference on Computer Supported Cooperative Work - CSCW		Author:Darren Gergle;Alan T. Clark
...Nakano and colleagues [25] explored the relation between various dialogue acts and non-verbal behaviors and showed that speakers look at their partners in order to ground references to new entities......Also, as suggested by Nakano et al. [25], we predict decreased gaze overlap when pairs are introducing new referents...

Title:Conversational Grounding in Younger and Older Adults: The Effect of Partner Visibility and Referent Abstractness in Task-Oriented Dialogue		Conference:		Author:Katya Lysander;William S. Horton
...In addition, direction-followers in that study attempted to establish eye contact with direction-givers more often at points of confusion or potential trouble (see also Nakano, Reinstein, Stocky, & Cassell, 2003)...

Title:Recognizing engagement in human-robot interaction		Conference:ACM/IEEE International Conference on Human-Robot Interaction - HRI		Author:Charles Rich;Brett Ponsler;Aaron Holroyd;Candace L. Sidner
...Nakano et al. [7]) reported on the use of the listener‚Äôs gaze and the lack of negative feedback to determine whether the listener has grounded [8] the speaker‚Äôs turn...

Title:Recognizing engagement in human-robot interaction		Conference:Human-Robot Interaction - HRI		Author:Charles Rich;Brett Ponsleur;Aaron Holroyd;Candace L. Sidner
...Nakano et al. [7]) reported on the use of the listener‚Äôs gaze and the lack of negative feedback to determine whether the listener has grounded [8] the speaker‚Äôs turn...

Title:Estimating user's engagement from eye-gaze behaviors in human-agent conversations		Conference:Intelligent User Interfaces - IUI		Author:Yukiko I. Nakano;Ryo Ishii
...As a study focusing on the sensing aspect, Nakano, et al. [17] proposed a gaze model for nonverbal grounding in conversational agents, and, using a head tracker, implemented an agent that can judge whether the information provided from the agent is grounded...

Title:Towards an expressive virtual tutor: an implementation of a virtual tutor based on an empirical study of non-verbal behaviour		Conference:		Author:Maher Ben Moussa;Zerrin Kasap;Nadia Magnenat-Thalmann;Krishna Chandramouli;Seyed Navid Haji Mirza;Qianni Zhang;Ebroul Izquierdo;Iordanis Biperis;Petros Daras
...[22] conformed the role of non-verbal communication and gaze in achieving grounding...

Title:Discovering eye gaze behavior during human-agent conversation in an interactive storytelling application		Conference:International Conference on Multimodal Interaction - ICMI		Author:Nikolaus Bee;Johannes Wagner;Elisabeth Andr®¶;Thurid Vogt;Fred Charles;David Pizzi;Marc Cavazza
...Another application using an virtual agent is the MACK system [22]......Many systems investigating interactive models of visual attention make use of head trackers [22, 28]...

Title:PROT °™ An embodied agent for intelligible and user-friendly human-robot interaction		Conference:International Conference on Intelligent RObots and Systems - IROS - IROS		Author:Ryota Fujimura;Kazuhiro Nakadai;Michita Imai;Ren Ohmura
...For instance, an on-screen agent can easily point to a physical object near the display [16] but not to one far from the display......Several studies have focused on the clarity of information presentation [12], [15], [16], [17], [18]...

Title:Questions and Internalizing Relevance		Conference:		Author:Jonathan Ginzburg
...tion, e.g. Compositional DRT [Muskens(1996)], employed to underpin the PTT dialogue framework [Poesio & Rieser(2009)]...

Title:From observation to simulation: generating culture-specific behavior for interactive systems		Conference:		Author:Matthias Rehm;Yukiko I. Nakano;Elisabeth Andr®¶;Toyoaki Nishida;Nikolaus Bee;Birgit Endrass;Michael Wissner;Afia Akhter Lipi;Hung-hsuan Huang
...Nakano et al. (2003) concentrate on grounding phenomena in interactions with virtual characters and also extract rule-like regularities for gaze behavior from a corpus of human interactions...

Title:Culture-specific communication management for virtual agents		Conference:Autonomous Agents & Multiagent Systems/Agent Theories, Architectures, and Languages - ATAL		Author:Birgit Endra?;Matthias Rehm;Elisabeth Andr®¶
...Based on this work, Nakano and colleagues [6] developed a grounding model for the kiosk agent Mack that provides route descriptions for a paper map...

Title:Multimodal Corpus Analysis as a Method for Ensuring Cultural Usability of Embodied Conversational Agents		Conference:Human-Computer Interaction - HCI		Author:Yukiko I. Nakano;Matthias Rehm
...[16] concentrate on grounding phenomena in interactions with virtual characters and also extract rule-like regularities for gaze behavior from a corpus of human interactions......[16]). Others have investigated the consequences of a mismatch between the appearance of a character and its verbal and nonverbal behavior [9]...

Title:Information State Based Multimodal Dialogue Management: Estimating Conversational Engagement from Gaze Information		Conference:Intelligent Virtual Agents		Author:Yukiko I. Nakano;Yuji Yamaoka
...Previous studies in multimodal user interfaces and intelligent virtual agents presented many interesting applications by exploiting such sensing technologies [1, 2]. However, little has been studied how to extract communication signals from a huge amount of data, and how to use such data in dialogue management in conversational agents...

Title:Communicating with multiple users for embodied conversational agents		Conference:		Author:H. H. Huang;A. Cerekovic;T. Furukawa;Y. Yamaoka;H. Ohashi;I. Pandzic;Y. Nakano;T. Nishida
...In Mack [21], the authors achieved natural nonverbal grounding via a statistical model conducted from the results of Wizard-of-Orz (woz) experiments...

Title:Some Pitfalls for Developing Enculturated Conversational Agents		Conference:Human-Computer Interaction - HCI		Author:Matthias Rehm;Elisabeth Andr®¶;Yukiko I. Nakano
...[6] as well as [23] exemplify this use of multimodal corpora in developing agents that exhibit human turn taking behavior and human grounding behavior respectively...

Title:Estimating User's Conversational Engagement Based on Gaze Behaviors		Conference:Intelligent Virtual Agents		Author:Ryo Ishii;Yukiko I. Nakano
...Nakano et al. [7] proposed a gaze model for nonverbal grounding in ECAs, and Gratch et al. [8] reported that backchannel feedback from a listener agent is effective in establishing a sense of rapport between a user and a virtual character Sidner et al. [9] proposed a gaze model for conversational engagement, and implemented it into a physical communication robot...

Title:The Role of Gesture in Document Explanation by Embodied Conversational Agents		Conference:		Author:Timothy W. Bickmore;Laura M. Pfeifer;Langxuan Yin
...The timing of gesture stroke relative to utterance was also coded as: before utterance, beginning of utterance (1st three words, following [31]), ending of utterance (last 3......Grounding can be exhibited in a number of ways [31], but we looked primarily at acknowledgment tokens, consisting of client ‚Äòack‚Äô speech acts (e.g., ‚ÄúOK‚Äù) and client head nods while the expert is speaking...

Title:Using Context to Disambiguate Communicative Signals		Conference:COST 237 Workshops		Author:Mark Ter Maat;Dirk Heylen
...For example, if you detect that the other person (who is currently speaking) is suddenly gazing at you, then this might be part of a behaviour complex that signals the intention of a turn offer [12,2] or it may indicate a request for feedback [1,8,10]...

Title:Gesture Salience as a Hidden Variable for Coreference Resolution and Keyframe Extraction		Conference:		Author:Jacob Eisenstein;Regina Barzilay;Randall Davis
...Nakano, Reinstein, Stocky, and Cassell (2003) present an empirical study of human-human interaction, showing a statistical relationship between hand-coded descriptions of head gestures and the discourse labels for the associated utterances (e.g., ‚Äúacknowledgment,‚Äù ‚Äúanswer,‚Äù and ‚Äúassertion‚Äù)......Previous NLP research on gesture has largely focused on building recognizers for gestures that characterize specific language phenomena: for example, detecting hand gestures that cue sentence boundaries (Chen et al., 2006), or body language that suggests topic shifts (Nakano et al., 2003)...

Title:Communicating with a virtual human or a skin-based robot head		Conference:IEEE International Conference on Automatic Face and Gesture Recognition - FGR		Author:Nadia Magnenat-thalmann;Zerrin Kasap;Maher Ben Moussa
...[40] suggested that in a face-to-face conversation non-verbal signals as well as verbal signals participate in the grounding process to indicate that an utterance is grounded or needs further work to become grounded...

Title:Dynamic Bayesian network based interest estimation for visual attentive presentation agents		Conference:Autonomous Agents & Multiagent Systems/Agent Theories, Architectures, and Languages - ATAL		Author:Boris Brandherm;Helmut Prendinger;Mitsuru Ishizuka
...Our research is similar to the system described in [8], where the user converses with the virtual agent in the MACK system...

Title:Communicating with a virtual human or a skin-based robot head		Conference:		Author:Nadia Magnenat-Thalmann;Zerrin Kasap;Maher Ben Moussa
...[40] suggested that in a face-to-face conversation non-verbal signals as well as verbal signals participate in the grounding process to indicate that an utterance is grounded or needs further work to become grounded...

Title:Towards Natural Listening on a Humanoid Robot		Conference:		Author:Yasser Mohammad;Toyoaki Nishida
...Many other experiments showed the effectiveness of utilizing facial expression, gaze and gestures for communication purposes [6]...

Title:Attentive Presentation Agents		Conference:Intelligent Virtual Agents		Author:Tobias Eichner;Helmut Prendinger;Elisabeth Andr®¶;Mitsuru Ishizuka
...Another application using an virtual agent is the MACK system described in [10]...

Title:A humanoid robot that pretends to listen to route guidance from a human		Conference:		Author:Takayuki Kanda;Masayuki Kamashima;Michita Imai;Tetsuo Ono;Daisuke Sakamoto;Hiroshi Ishiguro;Yuichiro Anzai
...for effective communication with humans (Cassell et al., 1999; Nakano et al., 2003)...

Title:Turn it this way: grounding collaborative action with remote gestures		Conference:Computer Human Interaction - CHI		Author:David Kirk;Tom Rodden;Danae Stanton Fraser
...Experimental studies [24, 34] have indicated that simply linking remote spaces through audio-visual video links (as opposed to audio-only) does not improve collaborative performance, especially not to the levels observed in copresent collaboration [18, 26]...

Title:Health Document Explanation by Virtual Agents		Conference:Intelligent Virtual Agents		Author:Timothy W. Bickmore;Laura M. Pfeifer;Michael K. Paasche-orlow
...The timing of gesture stroke relative to utterance was also coded as: before utterance, beginning of utterance (first three words), ending of utterance (last 3 words), middle of utterance, or continued from previous utterance (following [26])...

Title:Gaze-based infotainment agents		Conference:Advances in Computer Entertainment Technology - ACMACE		Author:Helmut Prendinger;Tobias Eichner;Elisabeth Andr®¶;Mitsuru Ishizuka
...The agents can adjust their gaze direction depending on which agent the user looks at. The MACK system described in [5] uses a head tracker to determine a user‚Äôs gaze in a direction-giving task, whereby an animated agent monitors lack of negative feedback and positive feedback in the grounding process...

Title:Eye movements as indices for the utility of life-like interface agents: A pilot study		Conference:		Author:Helmut Prendinger;Chunling Ma;Mitsuru Ishizuka
...In the realm of life-like agent based systems, Qu et al. (2004) considered a user‚Äôs focus of attention (among others) to decide an appropriate response for an educational software, and Nakano et al. (2003) investigated attentional focus (among others) for a direction-giv-......Hypothesis 5. (H5) Social Interaction Protocol Hypothesis (Nakano et al., 2003): Subjects in the Agent version shift......IRIs appear to be important interaction patterns in conversation (Nakano et al., 2003), and indicators of the instructor being conceived of as a social actor......Nakano et al. (2003) designed a life-like agent (Mack)...

Title:Conditional Sequence Model for Context-Based Recognition of Gaze Aversion		Conference:Machine Learning for Multimodal Interaction - MLMI		Author:Louis-philippe Morency;Trevor Darrell
...The dialogue manager merges information from the input devices with the history and the discourse model [16,17]...

Title:Understanding RUTH: Creating Believable Behaviors for a Virtual Human Under Uncertainty		Conference:Human-Computer Interaction - HCI		Author:Oh Insuk;Matthew Stone
...Preliminary work suggests that conversational agents will also achieve more natural interaction with users when those agents signal what they have understood and signal what they remain uncertain about [4]...

Title:Predicting Evidence of Understanding by Monitoring User's Task Manipulation in Multimodal Conversations		Conference:Meeting of the Association for Computational Linguistics - ACL		Author:Yukiko Nakano;Kazuyoshi Murata;Mika Enomoto;Yoshiko Arimoto;Yasuhiro Asa;Hirohiko Sagawa
...For user monitoring, Nakano, Reinstein, et al. (2003) used a head tracker to build a conversational agent which can monitor the user‚Äôs eye-gaze and head nods as nonverbal signals in grounding...

Title:When should animated agents give additional instructions to users? - Monitoring user°Øs understanding in multimodal dialogues -		Conference:International Conference on Control, Automation and Systems - ICCAS		Author:Kazuyoshi Murata;Mika Enomoto;Yoshiko Arimoto;Yukiko Nakano
...To build systems which accomplish such multimodal interactions, some studies discussed computational models of multimodal interactions [3, 4]. This model used nonverbal signal as positive evidence of user‚Äôs understanding...

Title:The effect of head-nod recognition in human-robot conversation		Conference:Human-Robot Interaction - HRI		Author:Candace L. Sidner;Christopher Lee;Louis-philippe Morency;Clifton Forlines
...Nakano et al [9] found that gaze at a map and lack of negative feedback were indicative that humans considered the previous utterance grounded and only looked at the interlocutor when they required more information to ground...

Title:Recognizing gaze aversion gestures in embodied conversational discourse		Conference:International Conference on Multimodal Interaction - ICMI		Author:Louis-philippe Morency;Chris Mario Christoudias;Trevor Darrell
...Nakano et al. analyzed eye gaze and head nods in computer‚Äìhuman conversation and found that their subjects were aware of the lack of conversational feedback from the ECA [23]...

Title:Modeling Embodied Feedback with Virtual Humans		Conference:Center for Interdisciplinary Research, Bielefeld University - ZiF		Author:Stefan Kopp;Jens Allwood;Karl Grammer;Elisabeth Ahlsen;Thorsten Stocksmeier
...Finally, gaze as basic turn-taking and grounding cue [16] and emblematic manual gestures like shrug are to be incorporated...

Title:From Annotated Multimodal Corpora to Simulated HumanLike Behaviors		Conference:Center for Interdisciplinary Research, Bielefeld University - ZiF		Author:Matthias Rehm;Elisabeth Andr®¶
...A study by Nakano and colleagues [27] revealed that an ECA with a grounding mechanism seems to encourage more non-verbal feedback from the user than a system without any grounding mechanism...

Title:Perspectives on Dialogue: Introduction to this Special Issue		Conference:		Author:Paul Piwek
...requires further research into the integrated use in dialogue of verbal and non-verbal means (see, e.g., Nakano et al., 2003)...

Title:Contextual recognition of head gestures		Conference:International Conference on Multimodal Interaction - ICMI		Author:Louis-Philippe Morency;Candace L. Sidner;Christopher Lee;Trevor Darrell
...Nakano et al. analyzed eye gaze and head nods in computer‚Äìhuman conversation and found that their subjects were aware of the lack of conversational feedback from the ECA [12]......While some systems [12, 2] have incorporated tracking of fine motion actions or visual gesture, none have included top-down dialogue context as part of the visual recognition process......Figure 2 shows our simplified architecture after analyzing several different systems [12, 13]...

Title:Understanding the effect of life-like interface agents through users' eye movements		Conference:International Conference on Multimodal Interaction - ICMI		Author:Helmut Prendinger;Chunling Ma;Jin Yingzi;Arturo Nakasone;Mitsuru Ishizuka
...In the interactive use, a system responds to the observed eye movements and can thus be seen as an input modality [12, 7, 17]......In the realm of life-like agent based systems, [23] consider a user‚Äôs focus of attention (among others) to decide an appropriate response for an educational software, and [17] investigate attentional focus (among others) for a direction-giving task......IRIs appear to be important interaction patterns in conversation [17], and indicators of the instructor being conceived of as a social actor......[17] designed a life-like agent (Mack) that provides the user with directions on a (shared) physical map, and derives information about the user‚Äôs conversational state from gaze behavior...

Title:Where Do They Look? Gaze Behaviors of Multiple Users Interacting with an Embodied Conversational Agent		Conference:Intelligent Virtual Agents		Author:Matthias Rehm;Elisabeth Andr®¶
...In accordance with Sidner et al. [15] or Nakano et al. [12], they conclude that gaze, or looking at faces, is an excellent predictor of conversational attention in multiparty conversations......Nakano and colleagues [12] developed a model of grounding for the kiosk agent Mack that provides route descriptions for a paper map......Coding of gaze behaviors was adopted from Nakano et al. ([12])...

Title:Gamble v2.0: social interactions with multiple users		Conference:Autonomous Agents & Multiagent Systems/International Conference on Autonomous Agents - AAMAS(Agents)		Author:Matthias Rehm;Elisabeth Andr®¶;Michael Wissner
...And indeed, a number of studies of face to face interaction between an user and an ECA have confirmed that this tendency exists (e.g., [7], [2])...

Title:From Chatterbots to Natural Interaction - Face to Face Communication with Embodied Conversational Agents		Conference:		Author:Matthias Rehm;Elisabeth Andr®¶
...Nakano and colleagues [20] developed a model of grounding for the kiosk agent Mack agent that provides route descriptions for a paper map......In accordance with Sidner et al. [24] or Nakano et al. [20], they conclude that gaze is an excellent predictor of conversational attention in multiparty conversations...

Title:Engaging in a Conversation with Synthetic Characters Along the Virtuality Continuum		Conference:Smart Graphics		Author:Elisabeth Andr®¶;Klaus Dorfm®πller-ulhaas;Matthias Rehm
...Furthermore, Nakano and colleagues [14] observed that shared attention to an object may be interpreted as a sign of common understanding for the task at hand......In accordance with Sidner et al. [3] or Nakano et al. [14], they conclude that gaze, or looking at faces, is an excellent predictor of conversational attention in multiparty conversations......Nakano and colleagues [14] developed a engagement model for the kiosk agent Mack that provides route directions for a paper map...

Title:Does non-verbal behavior of an embodied agent matter?		Conference:Active Media Technology		Author:Helmut Prendinger;Chunling Ma;Junichiro Mori;Mitsuru Ishizuka
...IRIs appear to be important interaction patterns in conversation, including direction-giving tasks [9], and strong i ndicators of the instructor agent being conceived of as a social actor......Here, we refer the interested reader to the work described in [9]...

Title:Look Who's Talking °™ Engaging in Interactions with Multiple Users		Conference:		Author:Matthias Rehm
...Gaze serves a number of functions like feedback, directing attention, showing interest, or turn taking.2 Nakano and colleagues ([15]) have shown how the user‚Äôs engagement can be measured by analyzing his gaze behavior during an interaction with the MIT Information Kiosk agent MACK......Coding of gaze behaviors was adopted from Nakano et al. ([15])......In accordance with Sidner et al. ([19]) or Nakano et al. ([15]), they conclude that gaze, or looking at faces, is an excellent predictor of conversational attention in multiparty conversations...

Title:Where to look: a study of human-robot engagement		Conference:Intelligent User Interfaces - IUI		Author:Candace L. Sidner;Cory D. Kidd;Christopher Lee;Neal Lesh
...We are unaware of studies that have looked at human-robot conversational behavior in any detail (although some preliminary results are reported in [13])...

Title:From Conversational Tooltips to Grounded Discourse: Head Pose Tracking in Interactive Dialog Systems		Conference:		Author:Louis-Philippe Morency;Trevor Darrell
...MACK (Media lab Autonomous Conversational Kiosk) is an embodied conversational agent (ECA) that relies on both verbal and nonverbal signals to establish common ground in computer‚Äì human interactions [19]......As described in [19], a grounding model has been developed based on the verbal and nonverbal signals happening during human‚Äì human interactions......In the final ver-Figure3: MACKwas designedto studyface-to-face grounding [19]...

Title:Interacting with Embodied Conversational Agents		Conference:		Author:Elisabeth Andr®¶;Catherine Pelachaud
...An exception includes the work by Nakano and colleagues [79] who developed a model of grounding for embodied......A study by Nakano and colleagues [79] revealed that an ECA with a grounding mechanism seems to encourage more non-verbal feedback from the user than a system without any grounding mechanism...

Title:Talk is silver, silence is golden: A cross cultural study on the usage of pauses in speech		Conference:		Author:Birgit Endrass;Matthias Rehm;Yukiko I. Nakano
...Nakano and colleagues [14] developed a grounding model for the kiosk agent Mack that provides route descri ptions for a paper map...

Title:Head Gestures for Perceptual Interfaces: The Role of Context in Improving Recognition		Conference:		Author:Louis-Philippe Morency;Candace Sidner;Christopher Lee;Trevor Darrell
...Nakano et al. analyzed eye gaze and head nods in computer-human conversation and found that their subjects were aware of the lack of conversational feedback from the ECA [20]; they incorporated their results in an ECA that updated its dialogue state......While some systems [20, 3] have incorporated tracking of fine motion actions or visual gesture, none have included top-down dialogue context as part of the visual recognition process......Figure 3 shows a simplified architecture which captures aspects common to several different systems [20, 21]......Grounding is also present during interactions with embodied conversational agents, and human participants naturally head nod as a non-verbal feedback for grounding [20]...

