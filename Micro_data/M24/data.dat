Title:Constructing Diverse Classifier Ensembles using Artificial Training Examples		Conference:International Joint Conference on Artificial Intelligence - IJCAI		Author:Prem Melville;Raymond J. Mooney
Ensemble methods like bagging and boosting that combine the decisions of multiple hypotheses are some of the strongest existing machine learning methods. The diversity of the members of an ensemble is known to be an important factor in determining its generalization error. This paper presents a new method for generating ensembles that directly constructs diverse hypotheses using additional artificially-constructed training exam- ples. The technique is a simple, general meta- learner that can use any strong learner as a base classifier to build diverse committees. Experimen- tal results using decision-tree induction as a base learner demonstrate that this approach consistently achieves higher predictive accuracy than both the base classifier and bagging (whereas boosting can occasionally decrease accuracy), and also obtains higher accuracy than boosting early in the learning curve when training data is limited.

Title:Genetic algorithm and Wisdom of Artificial Crowds algorithm applied to Light up		Conference:International Conference on Computer Games - CGAMES		Author:Leif H. Ashby;Roman V. Yampolskiy
...The approach is somewhat related to ensemble learning [15] methods such as boosting or bootstrap aggregation [12, 11] in the context of classifier fusion in which decisions of independent classifiers are combined to produce a superior meta-algorithm...

Title:Combining bagging, boosting, rotation forest and random subspace methods		Conference:		Author:Sotiris B. Kotsiantis
...Melville and Mooney (2003) presented a new meta-learner (DECORATE, Diverse Ensemble Creation by Oppositional Re-labeling of Artificial Training Examples) that uses an existing ‚Äústrong‚Äù learner (one that provides high accuracy on the training data) to construct a diverse committee......The proposed ensemble also use less time for training than Multiboost (Webb 2000) and Decorare (Melville and Mooney 2003) combining methods...

Title:An investigation into the relationship between semantic and content based similarity using LIDC		Conference:Multimedia Information Retrieval		Author:Robert Kim;Grace Dasovich;Runa Bhaumik;Richard Brock;Jacob D. Furst;Daniela Stan Raicu
...Using an ensemble of classifiers from DECORATE[15] and decision trees, they were able to improve the accuracy prediction of semantic ratings by 50 % on average despite the variability in the radiologists‚Äô interpretation...

Title:Adaptation in P300 Brain®CComputer Interfaces: A Two-Classifier Cotraining Approach		Conference:		Author:Rajesh C. Panicker;Sadasivan Puthusserypady;Ying Sun
...Introducing artificial training examples [37] to preserve diversity might reduce the tendency of cotraining algorithms to degenerate to self-training with the addition of more and more unlabeled data...

Title:Hierarchical kernel mixture models for the prediction of AIDS disease progression using HIV structural gp120 profiles		Conference:		Author:Paul D Yoo;Yung Shwen Ho;Jason Ng;Michael Charleston;Nitin K Saksena;Pengyi Yang;Albert Y Zomaya
...The SV-HMM and seven other wellregarded machine learning models, transductive support vector machine (SVMLIB) [21], SVM based decorate model (Decorate SVM) [22], multi-layered perceptron (MLP) [23], radial basis function network (RBFN) [24], logistics [25], and decision trees (J48) [26] ‚Äì were used to analyse the glycosylation profiles...

Title:Large-Scale Customized Models for Advertisers		Conference:IEEE International Conference on Data Mining - ICDM		Author:Abraham Bagherjeiran;Andrew O. Hatch;Adwait Ratnaparkhi;Rajesh Parekh
...For example the DECORATE algorithm trains on artificial data to explore the example space [11]...

Title:Consequences of Variability in Classifier Performance Estimates		Conference:IEEE International Conference on Data Mining - ICDM		Author:Troy Raeder;T. Ryan Hoens;Nitesh V. Chawla
...An approach adopted in prior works (e.g., [17], [18], [19]) is to use a paired t-test across the folds of a single n-by-kfold cross-validation run...

Title:Bagging of Complementary Neural Networks with Double Dynamic Weight Averaging		Conference:Software Engineering, Artificial Intelligence, Networking and Parallel/Distributed Computing - SNPD		Author:Sathit Nakkrasae;Pawalai Kraipeerapun;Somkid Amornsamankul;Chun Che Fung
...Diversity is a measure that defines the disagreement degree in the output of the individual classified machines in the ensemble [11]...

Title:Porosity Prediction Using Bagging of Complementary Neural Networks		Conference:International Symposium on Neural Networks - ISNN		Author:Pawalai Kraipeerapun;Chun Che Fung;Sathit Nakkrasae
...Diversity can be described as ‚Äúdisagreement‚Äù of the classifiers [3]...

Title:Using ensemble of classifiers for predicting HIV protease cleavage sites in proteins		Conference:		Author:Loris Nanni;Alessandra Lumini
... and empirical (Opitz and Maclin 1999; Kittler 1998; Altƒ±ncay and Demirekler 2000; Breiman 1996, 2001) studies have demonstrated that a good ensemble of classifiers can improve the performance of a stand-alone classifier, in particular if the individual classifiers in the ensemble are both accurate and independent (i.e., they make errors on different regions of the feature space) (Whitaker and Kuncheva 2003; Zenobi and Cunningham 2001; Melville ...

Title:Rough Ensemble Classifier: A Comparative Study		Conference:Int. Workshop on Fuzzy Logic and Applications - WILF		Author:Suman Saha;Chivukula A. Murthy;Sankar K. Pal
...These four classifier combination techniques are P-vote [11], SCANN [12], MDT [13] and DECORATE [14]......DECORATE stance for Diverse Ensemble Creation by Oppositional Relabeling of Artificial Training Examples [14]...

Title:Music Emotion Identification from Lyrics		Conference:International Symposium on Multimedia - ISM		Author:Dan Yang;Won-Sook Lee
...The best accuracy was achieved with the DECORATE (Diverse Ensemble Creation by Oppositional Relabeling of Artificial Training Examples) algorithm [14] for generating classifier ensembles...

Title:Local Random Subspace Method for Constructing Multiple Decision Stumps		Conference:International Conference on Information and Financial Engineering - ICIFE		Author:S. B. Kotsiantis
...In [17] another meta-learner (DECORATE, Diverse...

Title:Using closed captions to train activity recognizers that improve video retrieval		Conference:Computer Vision and Pattern Recognition - CVPR		Author:Sonal Gupta;Raymond J. Mooney
...However, we obtained the highest accuracy with DECORATE, an ensemble algorithm that has been shown to perform well with small, noisy training sets [17, 18]...

Title:Machine learning multi-classifiers for peptide classification		Conference:		Author:Loris Nanni;Alessandra Lumini
...To obtain a good system based on multiple classifier the single classifiers that belong to the multiple classifier should have high individual performance and diversity [19, 36, 37]...

Title:Spectrum of Variable-Random Trees		Conference:		Author:Fei Tony Liu;Kai Ming Ting;Yang Yu;Zhi-hua Zhou
...(Breiman, 2000) in which the classes of the training examples are flipped randomly according to a ratio; and (iii) Adding random examples (Melville & Mooney, 2003) in which diverse classifiers are constructed using additional artificial training examp les...

Title:Consensus-Based Ensembles of Soft Clusterings		Conference:		Author:Kunal Punera;Joydeep Ghosh
...Diversity among the classifiers in an ensemble has been shown to improve its accuracy (Hansen and Salamon 1990; Melville and Mooney 2003)...

Title:CCHR: Combination of Classifiers Using Heuristic Retraining		Conference:Networked Computing and Advanced Information Management - NCM		Author:Hamid Parvin;Hosein Alizadeh;Behrouz Minaei-Bidgoli;Morteza Analoui
...One group of these methods obtains diverse individuals by training accurate networks on different training set, such as bagging, boosting, cross validation and using artificial training examples [9,10-12]...

Title:Active Learning with Misclassification Sampling Using Diverse Ensembles Enhanced by Unlabeled Instances		Conference:Pacific-Asia Conference on Knowledge Discovery and Data Mining - PAKDD		Author:Jun Long;Jianping Yin;En Zhu;Wentao Zhao
...We select DECORATE [11] to generate the ensemble...

Title:Combining Classifiers through Triplet-Based Belief Functions		Conference:Principles of Data Mining and Knowledge Discovery - PKDD		Author:Yaxin Bi;Shengli Wu;Xuhui Shen;Pan Xiong
...To compare the classification accuracies between the individual classifiers and the combined classifiers across all the data sets, we employed the ranking statistics in terms of win/draw/loss record [14]......This result is consistent with previous studies conducted in [4] and [20], and different from ones presented in [15] and [14] where their experiments showed that ensemble accuracy increased with ensemble size and the performance levels out with ensemble sizes of 10-25...

Title:An Empirical Study of Combined Classifiers for Knowledge Discovery on Medical Data Bases		Conference:Asia-Pacific Web Conference - APWeb		Author:Lucelene Lopes;Edson Em®™lio Scalabrin;Paulo Fernandes
...In both cases (Figure 3), the stagnation of Bagging method was not expected, because of Bagging robustness [9, 13]...

Title:An Ensemble Classifier Based on Attribute Selection and Diversity Measure		Conference:Fuzzy Systems and Knowledge Discovery		Author:Hongbo Shi;Lv Yali
...Melville and Mooney proposed a data-partitioning-based ensemble method [9], DECORATE, which focuses on reducing the error of the entire ensemble by increasing diversity......We adopt the measure of diversity proposed by [9], and construct the ensemble classifier by using attribute selection and diversity measure of entire ensemble......Therefore, this paper adopted the diversity measure method proposed by Melville and Mooney [9], which focused directly the goal of maximizing diversity...

Title:Cascade Generalization with Classification and Model Trees		Conference:		Author:Sotiris Kotsiantis;Dimitris Kanellopoulos
...Melville and Mooney [11] present a new metalearner (DECORATE, Diverse Ensemble Creation by Oppositional Re-labeling of Artificial Training Examples) that uses an existing ‚Äústrong‚Äù learner (one that provides high accuracy on the training data) to build a diverse committee...

Title:Dual Strategy Active Learning		Conference:The European Conference on Machine Learning and Principles and Practice of Knowledge Discovery in Databases - ECML		Author:Meryem Pinar D?nmez;Jaime G. Carbonell;Paul N. Bennett
...Our future plan is to generalize DUAL to using a relative success weight, and to extend this work to ensemble methods that involve more than two strategies, maximizing ensemble diversity [15,14,10]...

Title:Ensemble Neural Networks Using Interval Neutrosophic Sets and Bagging		Conference:		Author:Pawalai Kraipeerapun;Chun Che Fung;Kok Wai Wong
...Melville and Mooney [6] built a training set for each new classifier by adding artificially constructed samples to the original training data...

Title:Combining Bagging, Boosting and Dagging for Classification Problems		Conference:Knowledge-Based Intelligent Information & Engineering Systems - KES		Author:Sotiris B. Kotsiantis;Dimitris Kanellopoulos
...Melville and Mooney [9] present a new meta-learner (DECORATE, Diverse...

Title:Ensemble Learning with Decision Tree for Remote Sensing Classification		Conference:		Author:Mahesh Pal
...M. Pal is with the National Institute of Technology, Kurukshetra, 136119, Haryana, India (phone: 0091 1744 233356; fax: 0091 1744 238050; e-mail: mpce_pal@yahoo.co.uk). boosting and bagging [9]...

Title:The Dynamics of Negative Correlation Learning		Conference:		Author:Mark Eastwood;Bogdan Gabrys
...Other methods generate classifiers sequentially [5, 12], and the current classifier is actively designed to complement the previous ones......The only method which translates the Fpenalty term_ idea to general base classifiers and zero‚Äêone loss is DECORATE [12], which creates artificial data and labels it probabilistically in opposition to the current ensemble prediction...

Title:Consensus Based Ensembles of Soft Clusterings		Conference:Machine Learning; Models, Technologies and Applications - MLMTA		Author:Kunal Punera;Joydeep Ghosh
...This h as been previously seen in the classifier ensemble literature where increasing the size of the ensemble increases the accuracy until a saturation point is reached [19], [20], [21]...

Title:Quantification of Vagueness in Multiclass Classification Based on Multiple Binary Neural Networks		Conference:		Author:PAWALAI KRAIPEERAPUN;Chun Che Fung;Kok Wai Wong
...Diversity can be described as disagreement of classifiers [4]...

Title:Optimization of the Trade-Off by Artificially Resampling for Ensemble Learning		Conference:		Author:Xiaofei Zhu;Jianmin Zhong;Lixia Zhuo
...There are also some improved methods that aim at providing suitable trade-off, one famous method is Decorate[5] which ensures the trade-off on an arbitrarily large set of additional artificial instances...

Title:Local dagging of decision stumps for regression and classification problems		Conference:Mediterranean Conference on Control and Automation - MED		Author:D. S. Anyfantis;M. G. Karagiannopoulos;S. B. Kotsiantis;P. E. Pintelas
...In [19] another classification meta-learner (DECORATE, Diverse Ensemble Creation by Oppositional Relabeling of Artificial Training Examples) is presented that uses a learner (one that provides high accuracy on the training data) to build a diverse committee...

Title:Machine learning: a review of classification and combining techniques		Conference:		Author:Sotiris B. Kotsiantis;I. D. Zaharakis;Panayiotis E. Pintelas
...Another meta-learner, DECORATE (Diverse Ensemble Creation by Oppositional Relabeling of Artificial Training Examples), was presented by (Melville and Mooney 2003) .T his method uses a learner (one that provides high accuracy on the training data) to build a diverse committee...

Title:Multi-class Ensemble-Based Active Learning		Conference:The European Conference on Machine Learning and Principles and Practice of Knowledge Discovery in Databases - ECML		Author:Christine K?rner;Stefan Wrobel
...The underlying principle, Decorate [16], increases the size of the ensemble iteratively, starting with one classifier based on the original training set...

Title:Model compression		Conference:Knowledge Discovery and Data Mining - KDD		Author:Cristian Bucilu®£;Rich Caruana;Alexandru Niculescu-mizil
...[13, 6]). Usually the nominal attributes are generated from a multinomial distribution whose parameters are estimated from the training data......DECORATE [13] uses articial data to increase diversity so that better ensembles can be trained...

Title:Local Boosting of Decision Stumps for Regression and Classification Problems		Conference:		Author:Sotiris B. Kotsiantis;Dimitris Kanellopoulos;Panayiotis E. Pintelas
...In [20] another classification meta-learner (DECORATE, Diverse Ensemble Creation by Oppositional Relabeling of Artificial Training Examples) is presented that uses a learner to build a diverse committee...

Title:Cultural Evolution of Ensemble Learning for Problem Solving		Conference:IEEE Congress on Evolutionary Computation - CEC		Author:Robert G. Reynolds;Bin Peng;R. S. Alomari
...DECORATE (Diverse Ensemble Creation by Oppositional Re-labeling of Artificial Training Examples) was proposed by [25] which is a meta-learner that uses an existing ‚Äústrong‚Äù learner (one that provides high accuracy on the training data) to build a diverse committee...

Title:An evidential approach in ensembles		Conference:ACM Symposium on Applied Computing - SAC		Author:Yaxin Bi;Werner Dubitzky
...The advances of supervised learning in the past decade have led to various attempts to develop ensemble or committee approaches that learn and retain multiple classifiers and combine their decisions during classification [1]......Let [0,1] be an interval of numeric values......A mapping function m: 2 Œò ‚Üí [0,1] is defined as a mass function if it satisfies:...

Title:Constructing Ensembles for Better Ranking		Conference:IEEE International Conference on Data Mining - ICDM		Author:Jin Huang;Charles X. Ling
...In recent years, a new ensembling algorithm called DECORATE was proposed by Melville and Mooney [10]......Motivated by the idea of the DECORATE algorithm [10], in this paper we propose an algorithm called RankDE (Ranking with Diverse Ensemble) to construct ensembles for better ranking performance......For each dataset we extract varied percentages of data and compare the RankDE with the ensembling algorithms of Bagging [4], Adaboost [7], DECORATE [10] and Rankboost [6] in terms of AUC...

Title:Diversity creation methods: a survey and categorisation		Conference:		Author:Gavin Brown;Jeremy L. Wyatt;Rachel Harris;Xin Yao
...The DECORATE algorithm, by Melville and Mooney [49] utilises the same metric to decide whether to accept or reject predictors to be added to the ensemble...

Title:Combining Bagging and Boosting		Conference:		Author:S. B. Kotsiantis;P. E. Pintelas
...Melville and Mooney [6] present a new meta-learner (DECORATE, Diverse Ensemble Creation by Oppositional Re-labeling of Artificial Training Examples) that uses an existing ‚Äústrong‚Äù learner (one that provides high accuracy on the training data) to build a diverse committee...

Title:Active Learning for Probability Estimation Using Jensen-Shannon Divergence		Conference:The European Conference on Machine Learning and Principles and Practice of Knowledge Discovery in Databases - ECML		Author:Prem Melville;Stewart M. Yang;Maytal Saar-tsechansky;Raymond J. Mooney
...ACTIVEDECORATE is based on DECORATE [10, 11], which is a recently introduced ensemble meta-learner that directly constructs diverse committees of classifiers by empl oying specially-constructed artificial training examples......Having larger ensembles generally increases classification accuracy [10 ] and may improve CPE...

Title:ACE: An Aggressive Classifier Ensemble with Error Detection, Correction, and Cleansing		Conference:International Conference on Tools with Artificial Intelligence - ICTAI		Author:Yan Zhang;Xingquan Zhu;Xindong Wu;Jeffrey P. Bond
...Melville and Mooney proposed an iterative approach, which generates a set of artificial training instances that are in general contradictory with the existing classifier ensemble [13], and the generated artificial instances are used to train the classifier ensemble of the next round...

Title:Network Game and Boosting		Conference:The European Conference on Machine Learning and Principles and Practice of Knowledge Discovery in Databases - ECML		Author:Shijun Wang;Changshui Zhang
...Learning curve analysis provides a powerful tool to inspect the dynamics of an ensemble learning method [25]...

Title:Bagging Model Trees for Classification Problems		Conference:Panhellenic Conference on Informatics - PCI		Author:Sotiris B. Kotsiantis;George E. Tsekouras;Panayiotis E. Pintelas
...Melville and Mooney [12] present a new meta-learner (DECORATE, Diverse Ensemble Creation by Oppositional Re-labeling of Artificial Training Examples) that uses an existing ‚Äústrong‚Äù learner (one that provides high accuracy on the training data) to build a diverse committee...

Title:Bagging Random Trees for Estimation of Tissue Softness		Conference:Machine Learning and Data Mining in Pattern Recognition - MLDM		Author:Sotiris B. Kotsiantis;George E. Tsekouras;Panayiotis E. Pintelas
...able source code for our experiments by the book [12]......Another meta-learner (DECORATE, Diverse Ensemble Creation by Oppositional Relabeling of Artificial Training Examples) is presented in [12] that uses a learner to build a diverse committee...

Title:Improving Classification for Microarray Data Sets by Constructing Synthetic Data		Conference:Computational and Information Science - CIS		Author:Shun Bian;Wenjia Wang
...Although a number of studies [3][4][5][6] have been applied in machine learning and data mining domains in recent decades, a common problem is that new data that are generated from the whole problem domain maybe unuseful and also result in computationally intensive problem......Melville et. al. [4] proposed an algorithm, DECORATE, for labelling...

Title:Experiments on Ensembles with Missing and Noisy Data		Conference:Multiple Classifier Systems - MCS		Author:Prem Melville;Nishit Shah;Lilyana Mihalkova;Raymond J. Mooney
...Decorate [9, 10] is a recently introduced ensemble meta-learner that directly constructs diverse committees by employing specially-constructed artificial 1 An ensemble meta-learner, like Bagging and AdaBoost, takes an arbitary base......This section summarizes the Decorate algorithm; for further details see [9, 10]......As in [9], this maximum limit was set to 50 iterations, and the number of artificially generated examples was equal to the training set size...

Title:Optimal resampling and classifier prototype selection in classifier ensembles using genetic algorithms		Conference:		Author:Hakan Altin?ay
...For instance, in their ensemble design approach named DECORATE, Melville and Mooney [10] minimized the ensemble error by increasing the diversity......Since a diverse set of classifiers is essential for achieving improved accuracies [7, 10], by taking into account the improvements achieved using GeneticBoost, it can be argued that the diversity requirement is achieved up to some extent...

Title:Optimal resampling and classifier prototype selection in classifier ensembles using genetic algorithms		Conference:		Author:Hakan Altin?ay
...The generalization accuracy of an ensemble depends on the diversity of the classifiers, which means that the classifiers in the ensemble should be different from each other, producing different errors on the input samples [6-11]......For instance, in their ensemble design approach named DECORATE, Melville and Mooney [10] minimized the ensemble error by increasing the diversity......Since the generalization accuracy of the ensemble also depends on the diversity of the classifiers, they should be different from each other, producing different errors on the input samples [6-11]......Since a diverse set of classifiers is essential for achieving improved accuracies [7, 10], by taking into account the improvements achieved using GeneticBoost, it can be argued that the diversity requirement is achieved up to some extent...

Title:Creating Diverse Ensemble Classifiers		Conference:		Author:Prem Melville
...In (Melville & Mooney, 2003) we introduced a new meta-learner DECORATE (Di-...

Title:Advances in Fuzzy Clustering and Its Applications		Conference:		Author:J. Valente de Oliveira;W. Pedrycz
...Diversity among the classifiers in an ensemble has been shown to improve its accuracy (Hansen and Salamon 1990; Melville and Mooney 2003)......where increasing the size of the ensemble increases the accuracy until a saturation point is reached (Hansen and Salamon 1990; Melville and Mooney 2003; Opitz and Maclin 1999)...

Title:Semi-supervised Learning Approaches for Predicting Lung Nodules Semantic Characteristics		Conference:		Author:Dmitry Zinovev;Jacob Furst
...DECORATE [5], which iteratively constructs an ensemble of classifiers by learning a classifier at each iteration and adding it to the current ensemble...

Title:Predicting Trait Impressions of Faces Using Classifier Ensembles		Conference:		Author:Sheryl Brahnam;Loris Nanni
...This good performance has been demonstrated both theoretically and empirically [5, 40, 68], especially when ensembles are built using classifiers that are both accurate and independent, i.e., when the classifiers make errors on different regions of the feature space [57, 86, 91]...

Title:with Missing and Noisy Data		Conference:		Author:Prem Melville;Nishit Shah;Lilyana Mihalkova;Raymond J. Mooney
...Decorate [9, 10] is a recently introduced ensemble meta-learner that directly constructs diverse committees by employing specially-constructed artificial 1 An ensemble meta-learner, like Bagging and AdaBoost, takes an arbitary base......This section summarizes the Decorate algorithm; for further details see [9, 10]......As in [9], this maximum limit was set to 50 iterations, and the number of artificially generated examples was equal to the training set size...

Title:Using Music to Elicit Emotion in Robots		Conference:		Author:Ryan Gephart
...In Decorate [30], an ensemble is generated iteratively during each of which a classifier is learned and added to the current ensemble - initialized to contain classifier trained on given training data...

Title:Experimental Investigation of Supervised and Semi-Supervised data mining algorithms for Text Categorization Collection (CSIT521Fall09) Dataset Prediction		Conference:		Author:Chan Ka Yan
...Prem Melville and Raymond J. Mooney[8] concluded that artificial size is related to diversity of generated artificial example...

Title:A Robust Multi-Class Feature Selection Strategy Based on Rotation Forest Ensemble Algorithm for Diagnosis of Erythemato-Squamous Diseases		Conference:		Author:Akin Ozcift;Arif Gulten
...classifiers in Decorate is provided by adding different randomly constructed examples to the training set when building new members of ensemble [15]...

Title:Self-organization of Supervised Models		Conference:		Author:Pavel Kord®™k;Jan ?ern?
...The DECORATE algorithm [47] constructs artificial data samples within estimated data distribution in order to increase diversity in the ensemble...

Title:Rotation of Random Forests for Genomic and Proteomic Classification Problems		Conference:		Author:Gregor Stiglic;Juan J. Rodriguez;Peter Kokol
...One of the recently proposed ensemble building techniques that could also be seen as a somehow alternative approach as it significantly differs from the above described techniques is called DECORATE (Diverse Ensemble Creation by Oppositional Relabeling of Artificial Training Examples) [16]...

Title:A Review of Active Learning and Co-Training in Text Classification		Conference:		Author:Michael Davy
...Diversity is essential for a committee [MM03]...

Title:HeteroClass: A Framework for Effective Classification from Heterogeneous Databases CS512 Project Report		Conference:		Author:Mayssam Sayyadian
...In our work we use the diversity measure used in [22]...

